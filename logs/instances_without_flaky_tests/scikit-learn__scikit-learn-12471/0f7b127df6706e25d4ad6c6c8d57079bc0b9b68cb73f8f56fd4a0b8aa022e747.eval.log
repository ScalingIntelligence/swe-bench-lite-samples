2024-07-03 04:25:31,901 - INFO - Environment image sweb.env.x86_64.aa92880033da20ca313928:latest found for scikit-learn__scikit-learn-12471
Building instance image sweb.eval.x86_64.scikit-learn__scikit-learn-12471:latest for scikit-learn__scikit-learn-12471
2024-07-03 04:25:31,902 - INFO - Image sweb.eval.x86_64.scikit-learn__scikit-learn-12471:latest already exists, skipping build.
2024-07-03 04:25:31,902 - INFO - Creating container for scikit-learn__scikit-learn-12471...
2024-07-03 04:25:33,446 - INFO - Container for scikit-learn__scikit-learn-12471 created: 688e7b6b8d6d2df8b6283197494d544f6f08e2fd1b88be6e144636fdd0f5bb23
2024-07-03 04:25:33,575 - INFO - Container for scikit-learn__scikit-learn-12471 started: 688e7b6b8d6d2df8b6283197494d544f6f08e2fd1b88be6e144636fdd0f5bb23
2024-07-03 04:25:33,575 - INFO - Intermediate patch for scikit-learn__scikit-learn-12471 written to /scratch/rse-swe-bench/unit_test_logs/evaluation_143913/model_name_managed_by_server/scikit-learn__scikit-learn-12471/patch.diff, now applying to container...
2024-07-03 04:25:33,717 - INFO - >>>>> Applied Patch:
Checking patch sklearn/preprocessing/_encoders.py...
Applied patch sklearn/preprocessing/_encoders.py cleanly.

2024-07-03 04:25:33,957 - INFO - Git diff before:
diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py
index 1e05aba59..7d160f2af 100644
--- a/sklearn/preprocessing/_encoders.py
+++ b/sklearn/preprocessing/_encoders.py
@@ -420,6 +420,43 @@ class OneHotEncoder(_BaseEncoder):
             self._fit(X, handle_unknown=self.handle_unknown)
             return self
 
+    def _transform_new(self, X):
+        """New implementation assuming categorical input"""
+        X_temp = check_array(X, dtype=None)
+        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+            X = check_array(X, dtype=np.object)
+        else:
+            X = X_temp
+
+        n_samples, n_features = X.shape
+
+        # Check if we need to cast to object type to avoid truncation
+        max_category_lengths = [max([len(str(cat)) for cat in cats]) for cats in self.categories_]
+        for i in range(n_features):
+            if max_category_lengths[i] > X.dtype.itemsize:
+                X = X.astype(np.object)
+                break
+
+        X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
+
+        mask = X_mask.ravel()
+        n_values = [cats.shape[0] for cats in self.categories_]
+        n_values = np.array([0] + n_values)
+        feature_indices = np.cumsum(n_values)
+
+        indices = (X_int + feature_indices[:-1]).ravel()[mask]
+        indptr = X_mask.sum(axis=1).cumsum()
+        indptr = np.insert(indptr, 0, 0)
+        data = np.ones(n_samples * n_features)[mask]
+
+        out = sparse.csr_matrix((data, indices, indptr),
+                                shape=(n_samples, feature_indices[-1]),
+                                dtype=self.dtype)
+        if not self.sparse:
+            return out.toarray()
+        else:
+            return out
+
     def _legacy_fit_transform(self, X):
         """Assumes X contains only categorical features."""
         dtype = getattr(X, 'dtype', None)
@@ -508,79 +545,79 @@ class OneHotEncoder(_BaseEncoder):
         else:
             return self.fit(X).transform(X)
 
-    def _legacy_transform(self, X):
-        """Assumes X contains only categorical features."""
-        X = check_array(X, dtype=np.int)
-        if np.any(X < 0):
-            raise ValueError("OneHotEncoder in legacy mode cannot handle "
-                             "categories encoded as negative integers. "
-                             "Please set categories='auto' explicitly to "
-                             "be able to use arbitrary integer values as "
-                             "category identifiers.")
-        n_samples, n_features = X.shape
-
-        indices = self._feature_indices_
-        if n_features != indices.shape[0] - 1:
-            raise ValueError("X has different shape than during fitting."
-                             " Expected %d, got %d."
-                             % (indices.shape[0] - 1, n_features))
-
-        # We use only those categorical features of X that are known using fit.
-        # i.e lesser than n_values_ using mask.
-        # This means, if self.handle_unknown is "ignore", the row_indices and
-        # col_indices corresponding to the unknown categorical feature are
-        # ignored.
-        mask = (X < self._n_values_).ravel()
-        if np.any(~mask):
-            if self.handle_unknown not in ['error', 'ignore']:
-                raise ValueError("handle_unknown should be either error or "
-                                 "unknown got %s" % self.handle_unknown)
-            if self.handle_unknown == 'error':
-                raise ValueError("unknown categorical feature present %s "
-                                 "during transform." % X.ravel()[~mask])
-
-        column_indices = (X + indices[:-1]).ravel()[mask]
-        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),
-                                n_features)[mask]
-        data = np.ones(np.sum(mask))
-        out = sparse.coo_matrix((data, (row_indices, column_indices)),
-                                shape=(n_samples, indices[-1]),
-                                dtype=self.dtype).tocsr()
-        if (isinstance(self._n_values, six.string_types) and
-                self._n_values == 'auto'):
-            out = out[:, self._active_features_]
-
-        return out if self.sparse else out.toarray()
-
-    def _transform_new(self, X):
-        """New implementation assuming categorical input"""
-        X_temp = check_array(X, dtype=None)
-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
-            X = check_array(X, dtype=np.object)
-        else:
-            X = X_temp
-
-        n_samples, n_features = X.shape
-
-        X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
-
-        mask = X_mask.ravel()
-        n_values = [cats.shape[0] for cats in self.categories_]
-        n_values = np.array([0] + n_values)
-        feature_indices = np.cumsum(n_values)
-
-        indices = (X_int + feature_indices[:-1]).ravel()[mask]
-        indptr = X_mask.sum(axis=1).cumsum()
-        indptr = np.insert(indptr, 0, 0)
-        data = np.ones(n_samples * n_features)[mask]
-
-        out = sparse.csr_matrix((data, indices, indptr),
-                                shape=(n_samples, feature_indices[-1]),
-                                dtype=self.dtype)
-        if not self.sparse:
-            return out.toarray()
-        else:
-            return out
+def _transform_new(self, X):
+    """New implementation assuming categorical input"""
+    X_temp = check_array(X, dtype=None)
+    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+        X = check_array(X, dtype=np.object)
+    else:
+        X = X_temp
+
+    n_samples, n_features = X.shape
+
+    # Check if we need to cast to object type to avoid truncation
+    max_category_lengths = [max([len(str(cat)) for cat in cats]) for cats in self.categories_]
+    for i in range(n_features):
+        if max_category_lengths[i] > X.dtype.itemsize:
+            X = X.astype(np.object)
+            break
+
+    X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
+
+    mask = X_mask.ravel()
+    n_values = [cats.shape[0] for cats in self.categories_]
+    n_values = np.array([0] + n_values)
+    feature_indices = np.cumsum(n_values)
+
+    indices = (X_int + feature_indices[:-1]).ravel()[mask]
+    indptr = X_mask.sum(axis=1).cumsum()
+    indptr = np.insert(indptr, 0, 0)
+    data = np.ones(n_samples * n_features)[mask]
+
+    out = sparse.csr_matrix((data, indices, indptr),
+                            shape=(n_samples, feature_indices[-1]),
+                            dtype=self.dtype)
+    if not self.sparse:
+        return out.toarray()
+    else:
+        return out
+
+def _transform_new(self, X):
+    """New implementation assuming categorical input"""
+    X_temp = check_array(X, dtype=None)
+    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+        X = check_array(X, dtype=np.object)
+    else:
+        X = X_temp
+
+    n_samples, n_features = X.shape
+
+    # Check if we need to cast to object type to avoid truncation
+    max_category_lengths = [max([len(str(cat)) for cat in cats]) for cats in self.categories_]
+    for i in range(n_features):
+        if max_category_lengths[i] > X.dtype.itemsize:
+            X = X.astype(np.object)
+            break
+
+    X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
+
+    mask = X_mask.ravel()
+    n_values = [cats.shape[0] for cats in self.categories_]
+    n_values = np.array([0] + n_values)
+    feature_indices = np.cumsum(n_values)
+
+    indices = (X_int + feature_indices[:-1]).ravel()[mask]
+    indptr = X_mask.sum(axis=1).cumsum()
+    indptr = np.insert(indptr, 0, 0)
+    data = np.ones(n_samples * n_features)[mask]
+
+    out = sparse.csr_matrix((data, indices, indptr),
+                            shape=(n_samples, feature_indices[-1]),
+                            dtype=self.dtype)
+    if not self.sparse:
+        return out.toarray()
+    else:
+        return out
 
     def transform(self, X):
         """Transform X using one-hot encoding.
2024-07-03 04:25:33,958 - INFO - Eval script for scikit-learn__scikit-learn-12471 written to /scratch/rse-swe-bench/unit_test_logs/evaluation_143913/model_name_managed_by_server/scikit-learn__scikit-learn-12471/patch.diff, now applying to container...
2024-07-03 04:25:37,536 - INFO - Test output for scikit-learn__scikit-learn-12471 written to /scratch/rse-swe-bench/unit_test_logs/evaluation_143913/model_name_managed_by_server/scikit-learn__scikit-learn-12471/test_output.txt
2024-07-03 04:25:37,582 - INFO - Git diff after:
diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py
index 1e05aba59..7d160f2af 100644
--- a/sklearn/preprocessing/_encoders.py
+++ b/sklearn/preprocessing/_encoders.py
@@ -420,6 +420,43 @@ class OneHotEncoder(_BaseEncoder):
             self._fit(X, handle_unknown=self.handle_unknown)
             return self
 
+    def _transform_new(self, X):
+        """New implementation assuming categorical input"""
+        X_temp = check_array(X, dtype=None)
+        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+            X = check_array(X, dtype=np.object)
+        else:
+            X = X_temp
+
+        n_samples, n_features = X.shape
+
+        # Check if we need to cast to object type to avoid truncation
+        max_category_lengths = [max([len(str(cat)) for cat in cats]) for cats in self.categories_]
+        for i in range(n_features):
+            if max_category_lengths[i] > X.dtype.itemsize:
+                X = X.astype(np.object)
+                break
+
+        X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
+
+        mask = X_mask.ravel()
+        n_values = [cats.shape[0] for cats in self.categories_]
+        n_values = np.array([0] + n_values)
+        feature_indices = np.cumsum(n_values)
+
+        indices = (X_int + feature_indices[:-1]).ravel()[mask]
+        indptr = X_mask.sum(axis=1).cumsum()
+        indptr = np.insert(indptr, 0, 0)
+        data = np.ones(n_samples * n_features)[mask]
+
+        out = sparse.csr_matrix((data, indices, indptr),
+                                shape=(n_samples, feature_indices[-1]),
+                                dtype=self.dtype)
+        if not self.sparse:
+            return out.toarray()
+        else:
+            return out
+
     def _legacy_fit_transform(self, X):
         """Assumes X contains only categorical features."""
         dtype = getattr(X, 'dtype', None)
@@ -508,79 +545,79 @@ class OneHotEncoder(_BaseEncoder):
         else:
             return self.fit(X).transform(X)
 
-    def _legacy_transform(self, X):
-        """Assumes X contains only categorical features."""
-        X = check_array(X, dtype=np.int)
-        if np.any(X < 0):
-            raise ValueError("OneHotEncoder in legacy mode cannot handle "
-                             "categories encoded as negative integers. "
-                             "Please set categories='auto' explicitly to "
-                             "be able to use arbitrary integer values as "
-                             "category identifiers.")
-        n_samples, n_features = X.shape
-
-        indices = self._feature_indices_
-        if n_features != indices.shape[0] - 1:
-            raise ValueError("X has different shape than during fitting."
-                             " Expected %d, got %d."
-                             % (indices.shape[0] - 1, n_features))
-
-        # We use only those categorical features of X that are known using fit.
-        # i.e lesser than n_values_ using mask.
-        # This means, if self.handle_unknown is "ignore", the row_indices and
-        # col_indices corresponding to the unknown categorical feature are
-        # ignored.
-        mask = (X < self._n_values_).ravel()
-        if np.any(~mask):
-            if self.handle_unknown not in ['error', 'ignore']:
-                raise ValueError("handle_unknown should be either error or "
-                                 "unknown got %s" % self.handle_unknown)
-            if self.handle_unknown == 'error':
-                raise ValueError("unknown categorical feature present %s "
-                                 "during transform." % X.ravel()[~mask])
-
-        column_indices = (X + indices[:-1]).ravel()[mask]
-        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),
-                                n_features)[mask]
-        data = np.ones(np.sum(mask))
-        out = sparse.coo_matrix((data, (row_indices, column_indices)),
-                                shape=(n_samples, indices[-1]),
-                                dtype=self.dtype).tocsr()
-        if (isinstance(self._n_values, six.string_types) and
-                self._n_values == 'auto'):
-            out = out[:, self._active_features_]
-
-        return out if self.sparse else out.toarray()
-
-    def _transform_new(self, X):
-        """New implementation assuming categorical input"""
-        X_temp = check_array(X, dtype=None)
-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
-            X = check_array(X, dtype=np.object)
-        else:
-            X = X_temp
-
-        n_samples, n_features = X.shape
-
-        X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
-
-        mask = X_mask.ravel()
-        n_values = [cats.shape[0] for cats in self.categories_]
-        n_values = np.array([0] + n_values)
-        feature_indices = np.cumsum(n_values)
-
-        indices = (X_int + feature_indices[:-1]).ravel()[mask]
-        indptr = X_mask.sum(axis=1).cumsum()
-        indptr = np.insert(indptr, 0, 0)
-        data = np.ones(n_samples * n_features)[mask]
-
-        out = sparse.csr_matrix((data, indices, indptr),
-                                shape=(n_samples, feature_indices[-1]),
-                                dtype=self.dtype)
-        if not self.sparse:
-            return out.toarray()
-        else:
-            return out
+def _transform_new(self, X):
+    """New implementation assuming categorical input"""
+    X_temp = check_array(X, dtype=None)
+    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+        X = check_array(X, dtype=np.object)
+    else:
+        X = X_temp
+
+    n_samples, n_features = X.shape
+
+    # Check if we need to cast to object type to avoid truncation
+    max_category_lengths = [max([len(str(cat)) for cat in cats]) for cats in self.categories_]
+    for i in range(n_features):
+        if max_category_lengths[i] > X.dtype.itemsize:
+            X = X.astype(np.object)
+            break
+
+    X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
+
+    mask = X_mask.ravel()
+    n_values = [cats.shape[0] for cats in self.categories_]
+    n_values = np.array([0] + n_values)
+    feature_indices = np.cumsum(n_values)
+
+    indices = (X_int + feature_indices[:-1]).ravel()[mask]
+    indptr = X_mask.sum(axis=1).cumsum()
+    indptr = np.insert(indptr, 0, 0)
+    data = np.ones(n_samples * n_features)[mask]
+
+    out = sparse.csr_matrix((data, indices, indptr),
+                            shape=(n_samples, feature_indices[-1]),
+                            dtype=self.dtype)
+    if not self.sparse:
+        return out.toarray()
+    else:
+        return out
+
+def _transform_new(self, X):
+    """New implementation assuming categorical input"""
+    X_temp = check_array(X, dtype=None)
+    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+        X = check_array(X, dtype=np.object)
+    else:
+        X = X_temp
+
+    n_samples, n_features = X.shape
+
+    # Check if we need to cast to object type to avoid truncation
+    max_category_lengths = [max([len(str(cat)) for cat in cats]) for cats in self.categories_]
+    for i in range(n_features):
+        if max_category_lengths[i] > X.dtype.itemsize:
+            X = X.astype(np.object)
+            break
+
+    X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
+
+    mask = X_mask.ravel()
+    n_values = [cats.shape[0] for cats in self.categories_]
+    n_values = np.array([0] + n_values)
+    feature_indices = np.cumsum(n_values)
+
+    indices = (X_int + feature_indices[:-1]).ravel()[mask]
+    indptr = X_mask.sum(axis=1).cumsum()
+    indptr = np.insert(indptr, 0, 0)
+    data = np.ones(n_samples * n_features)[mask]
+
+    out = sparse.csr_matrix((data, indices, indptr),
+                            shape=(n_samples, feature_indices[-1]),
+                            dtype=self.dtype)
+    if not self.sparse:
+        return out.toarray()
+    else:
+        return out
 
     def transform(self, X):
         """Transform X using one-hot encoding.
2024-07-03 04:25:37,582 - INFO - Grading answer for scikit-learn__scikit-learn-12471...
2024-07-03 04:25:37,586 - INFO - report: {'scikit-learn__scikit-learn-12471': {'patch_is_None': False, 'patch_exists': True, 'patch_successfully_applied': True, 'resolved': False, 'tests_status': {'FAIL_TO_PASS': {'success': [], 'failure': ['sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown_strings']}, 'PASS_TO_PASS': {'success': ['sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dense', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[mixed]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[numeric]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[object]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[string]', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[mixed]', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[numeric]', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[object]', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[object]', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[numeric]', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[object-string-cat]', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_inverse', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_raise_missing[numeric]', 'sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_raise_missing[object]'], 'failure': ['sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_sparse', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_deprecationwarnings', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_force_new_behaviour', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categorical_features', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_not_fitted', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_no_categorical_features', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-int32]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-float32]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-float64]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-int32]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-float32]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-float64]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-int32]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-float32]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-float64]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[int32]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[float32]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[float64]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_set_params', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[numeric]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[object]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[numeric]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-cat]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_unsorted_categories', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories_mixed_columns', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_pandas', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_unicode', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[error-numeric]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[error-object]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[ignore-numeric]', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[ignore-object]', 'sklearn/preprocessing/tests/test_encoders.py::test_encoder_dtypes', 'sklearn/preprocessing/tests/test_encoders.py::test_encoder_dtypes_pandas', 'sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_warning']}, 'FAIL_TO_FAIL': {'success': [], 'failure': []}, 'PASS_TO_FAIL': {'success': [], 'failure': []}}}}
Result for scikit-learn__scikit-learn-12471: resolved: False
2024-07-03 04:25:37,586 - INFO - Attempting to stop container sweb.eval.scikit-learn__scikit-learn-12471.evaluation_143913...
2024-07-03 04:25:39,638 - INFO - Attempting to remove container sweb.eval.scikit-learn__scikit-learn-12471.evaluation_143913...
2024-07-03 04:25:39,659 - INFO - Container sweb.eval.scikit-learn__scikit-learn-12471.evaluation_143913 removed.
