2024-07-03 02:13:10,366 - INFO - Environment image sweb.env.x86_64.aa92880033da20ca313928:latest found for scikit-learn__scikit-learn-10949
Building instance image sweb.eval.x86_64.scikit-learn__scikit-learn-10949:latest for scikit-learn__scikit-learn-10949
2024-07-03 02:13:10,369 - INFO - Image sweb.eval.x86_64.scikit-learn__scikit-learn-10949:latest already exists, skipping build.
2024-07-03 02:13:10,369 - INFO - Creating container for scikit-learn__scikit-learn-10949...
2024-07-03 02:13:11,111 - INFO - Container for scikit-learn__scikit-learn-10949 created: 90b4285f5a5d18b625d4d1f7f23eeb5163f915b1e80405f25513d676bf2113a0
2024-07-03 02:13:11,266 - INFO - Container for scikit-learn__scikit-learn-10949 started: 90b4285f5a5d18b625d4d1f7f23eeb5163f915b1e80405f25513d676bf2113a0
2024-07-03 02:13:11,267 - INFO - Intermediate patch for scikit-learn__scikit-learn-10949 written to /scratch/rse-swe-bench/unit_test_logs/evaluation_135285/model_name_managed_by_server/scikit-learn__scikit-learn-10949/patch.diff, now applying to container...
2024-07-03 02:13:11,417 - INFO - >>>>> Applied Patch:
Checking patch sklearn/utils/validation.py...
Applied patch sklearn/utils/validation.py cleanly.

2024-07-03 02:13:11,643 - INFO - Git diff before:
diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py
index fe1f7236e..348778c82 100644
--- a/sklearn/utils/validation.py
+++ b/sklearn/utils/validation.py
@@ -428,13 +428,15 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,
     ensure_min_features : int (default=1)
         Make sure that the 2D array has some minimum number of features
         (columns). The default value of 1 rejects empty datasets.
-        This check is only enforced when the input data has effectively 2
-        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0
-        disables this check.
+    This check is only enforced when the input data has effectively 2
+    dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0
+    disables this check.
 
     warn_on_dtype : boolean (default=False)
         Raise DataConversionWarning if the dtype of the input data structure
-        does not match the requested dtype, causing a memory copy.
+        does not match the requested dtype, causing a memory copy. The warning
+        will also be issued if the dtype of a pandas DataFrame changes during
+        conversion.
 
     estimator : str or estimator instance (default=None)
         If passed, include the name of the estimator in warning messages.
@@ -574,9 +576,12 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,
                                 context))
 
     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:
-        msg = ("Data with input dtype %s was converted to %s%s."
-               % (dtype_orig, array.dtype, context))
-        warnings.warn(msg, DataConversionWarning)
+        if isinstance(array_orig, pd.DataFrame) and dtype_orig == object and array.dtype == np.float64:
+            warnings.warn("Data with input dtype object was converted to float64.", DataConversionWarning)
+        else:
+            msg = ("Data with input dtype %s was converted to %s%s."
+                   % (dtype_orig, array.dtype, context))
+            warnings.warn(msg, DataConversionWarning)
 
     if copy and np.may_share_memory(array, array_orig):
         array = np.array(array, dtype=dtype, order=order)
@@ -584,27 +589,13 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,
     return array
 
 
-def _check_large_sparse(X, accept_large_sparse=False):
-    """Raise a ValueError if X has 64bit indices and accept_large_sparse=False
-    """
-    if not (accept_large_sparse and LARGE_SPARSE_SUPPORTED):
-        supported_indices = ["int32"]
-        if X.getformat() == "coo":
-            index_keys = ['col', 'row']
-        elif X.getformat() in ["csr", "csc", "bsr"]:
-            index_keys = ['indices', 'indptr']
-        else:
-            return
-        for key in index_keys:
-            indices_datatype = getattr(X, key).dtype
-            if (indices_datatype not in supported_indices):
-                if not LARGE_SPARSE_SUPPORTED:
-                    raise ValueError("Scipy version %s does not support large"
-                                     " indices, please upgrade your scipy"
-                                     " to 0.14.0 or above" % scipy_version)
-                raise ValueError("Only sparse matrices with 32-bit integer"
-                                 " indices are accepted. Got %s indices."
-                                 % indices_datatype)
+if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:
+    if isinstance(array_orig, pd.DataFrame) and dtype_orig == object and array.dtype == np.float64:
+        warnings.warn("Data with input dtype object was converted to float64.", DataConversionWarning)
+    else:
+        msg = ("Data with input dtype %s was converted to %s%s."
+               % (dtype_orig, array.dtype, context))
+        warnings.warn(msg, DataConversionWarning)
 
 
 def check_X_y(X, y, accept_sparse=False, accept_large_sparse=True,
2024-07-03 02:13:11,643 - INFO - Eval script for scikit-learn__scikit-learn-10949 written to /scratch/rse-swe-bench/unit_test_logs/evaluation_135285/model_name_managed_by_server/scikit-learn__scikit-learn-10949/patch.diff, now applying to container...
2024-07-03 02:13:14,617 - INFO - Test output for scikit-learn__scikit-learn-10949 written to /scratch/rse-swe-bench/unit_test_logs/evaluation_135285/model_name_managed_by_server/scikit-learn__scikit-learn-10949/test_output.txt
2024-07-03 02:13:14,654 - INFO - Git diff after:
diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py
index fe1f7236e..348778c82 100644
--- a/sklearn/utils/validation.py
+++ b/sklearn/utils/validation.py
@@ -428,13 +428,15 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,
     ensure_min_features : int (default=1)
         Make sure that the 2D array has some minimum number of features
         (columns). The default value of 1 rejects empty datasets.
-        This check is only enforced when the input data has effectively 2
-        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0
-        disables this check.
+    This check is only enforced when the input data has effectively 2
+    dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0
+    disables this check.
 
     warn_on_dtype : boolean (default=False)
         Raise DataConversionWarning if the dtype of the input data structure
-        does not match the requested dtype, causing a memory copy.
+        does not match the requested dtype, causing a memory copy. The warning
+        will also be issued if the dtype of a pandas DataFrame changes during
+        conversion.
 
     estimator : str or estimator instance (default=None)
         If passed, include the name of the estimator in warning messages.
@@ -574,9 +576,12 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,
                                 context))
 
     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:
-        msg = ("Data with input dtype %s was converted to %s%s."
-               % (dtype_orig, array.dtype, context))
-        warnings.warn(msg, DataConversionWarning)
+        if isinstance(array_orig, pd.DataFrame) and dtype_orig == object and array.dtype == np.float64:
+            warnings.warn("Data with input dtype object was converted to float64.", DataConversionWarning)
+        else:
+            msg = ("Data with input dtype %s was converted to %s%s."
+                   % (dtype_orig, array.dtype, context))
+            warnings.warn(msg, DataConversionWarning)
 
     if copy and np.may_share_memory(array, array_orig):
         array = np.array(array, dtype=dtype, order=order)
@@ -584,27 +589,13 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,
     return array
 
 
-def _check_large_sparse(X, accept_large_sparse=False):
-    """Raise a ValueError if X has 64bit indices and accept_large_sparse=False
-    """
-    if not (accept_large_sparse and LARGE_SPARSE_SUPPORTED):
-        supported_indices = ["int32"]
-        if X.getformat() == "coo":
-            index_keys = ['col', 'row']
-        elif X.getformat() in ["csr", "csc", "bsr"]:
-            index_keys = ['indices', 'indptr']
-        else:
-            return
-        for key in index_keys:
-            indices_datatype = getattr(X, key).dtype
-            if (indices_datatype not in supported_indices):
-                if not LARGE_SPARSE_SUPPORTED:
-                    raise ValueError("Scipy version %s does not support large"
-                                     " indices, please upgrade your scipy"
-                                     " to 0.14.0 or above" % scipy_version)
-                raise ValueError("Only sparse matrices with 32-bit integer"
-                                 " indices are accepted. Got %s indices."
-                                 % indices_datatype)
+if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:
+    if isinstance(array_orig, pd.DataFrame) and dtype_orig == object and array.dtype == np.float64:
+        warnings.warn("Data with input dtype object was converted to float64.", DataConversionWarning)
+    else:
+        msg = ("Data with input dtype %s was converted to %s%s."
+               % (dtype_orig, array.dtype, context))
+        warnings.warn(msg, DataConversionWarning)
 
 
 def check_X_y(X, y, accept_sparse=False, accept_large_sparse=True,
2024-07-03 02:13:14,654 - INFO - Grading answer for scikit-learn__scikit-learn-10949...
2024-07-03 02:13:14,657 - INFO - report: {'scikit-learn__scikit-learn-10949': {'patch_is_None': False, 'patch_exists': True, 'patch_successfully_applied': True, 'resolved': False, 'tests_status': {'FAIL_TO_PASS': {'success': [], 'failure': ['sklearn/utils/tests/test_validation.py::test_check_dataframe_warns_on_dtype']}, 'PASS_TO_PASS': {'success': [], 'failure': ['sklearn/utils/tests/test_validation.py::test_as_float_array', 'sklearn/utils/tests/test_validation.py::test_as_float_array_nan[X0]', 'sklearn/utils/tests/test_validation.py::test_as_float_array_nan[X1]', 'sklearn/utils/tests/test_validation.py::test_np_matrix', 'sklearn/utils/tests/test_validation.py::test_memmap', 'sklearn/utils/tests/test_validation.py::test_ordering', 'sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-inf-False]', 'sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-nan-allow-nan]', 'sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-nan-False]', 'sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-inf-False]', 'sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-nan-allow-nan]', 'sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-nan-False]', 'sklearn/utils/tests/test_validation.py::test_check_array', 'sklearn/utils/tests/test_validation.py::test_check_array_pandas_dtype_object_conversion', 'sklearn/utils/tests/test_validation.py::test_check_array_on_mock_dataframe', 'sklearn/utils/tests/test_validation.py::test_check_array_dtype_stability', 'sklearn/utils/tests/test_validation.py::test_check_array_dtype_warning', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_sparse_type_exception', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_sparse_no_exception', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[csr]', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[csc]', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[coo]', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[bsr]', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[csr]', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[csc]', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[coo]', 'sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[bsr]', 'sklearn/utils/tests/test_validation.py::test_check_array_large_indices_non_supported_scipy_version[csr]', 'sklearn/utils/tests/test_validation.py::test_check_array_large_indices_non_supported_scipy_version[csc]', 'sklearn/utils/tests/test_validation.py::test_check_array_large_indices_non_supported_scipy_version[coo]', 'sklearn/utils/tests/test_validation.py::test_check_array_large_indices_non_supported_scipy_version[bsr]', 'sklearn/utils/tests/test_validation.py::test_check_array_min_samples_and_features_messages', 'sklearn/utils/tests/test_validation.py::test_check_array_complex_data_error', 'sklearn/utils/tests/test_validation.py::test_has_fit_parameter', 'sklearn/utils/tests/test_validation.py::test_check_symmetric', 'sklearn/utils/tests/test_validation.py::test_check_is_fitted', 'sklearn/utils/tests/test_validation.py::test_check_consistent_length', 'sklearn/utils/tests/test_validation.py::test_check_dataframe_fit_attribute', 'sklearn/utils/tests/test_validation.py::test_suppress_validation', 'sklearn/utils/tests/test_validation.py::test_check_memory', 'sklearn/utils/tests/test_validation.py::test_check_array_memmap[True]', 'sklearn/utils/tests/test_validation.py::test_check_array_memmap[False]']}, 'FAIL_TO_FAIL': {'success': [], 'failure': []}, 'PASS_TO_FAIL': {'success': [], 'failure': []}}}}
Result for scikit-learn__scikit-learn-10949: resolved: False
2024-07-03 02:13:14,657 - INFO - Attempting to stop container sweb.eval.scikit-learn__scikit-learn-10949.evaluation_135285...
2024-07-03 02:13:15,085 - INFO - Attempting to remove container sweb.eval.scikit-learn__scikit-learn-10949.evaluation_135285...
2024-07-03 02:13:15,107 - INFO - Container sweb.eval.scikit-learn__scikit-learn-10949.evaluation_135285 removed.
