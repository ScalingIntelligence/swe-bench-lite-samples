{
  "info": {
    "duration": 453.5459089279175,
    "submission": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..dbd5dc852 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -601,6 +601,12 @@ class OneHotEncoder(_BaseEncoder):\n                                        self._categorical_features,\n                                        copy=True)\n         else:\n+            X = check_array(X, dtype=None, force_all_finite=False)\n+            for i in range(X.shape[1]):\n+                if X[:, i].dtype.kind == 'U' or X[:, i].dtype.kind == 'S':\n+                    max_len = max(len(str(category)) for category in self.categories_[i])\n+                    if any(len(str(x)) < max_len for x in X[:, i]):\n+                        X[:, i] = X[:, i].astype(object)\n             return self._transform_new(X)\n \n     def inverse_transform(self, X):\n",
    "total_cost": 0.20689799999999997,
    "instance_id": "scikit-learn__scikit-learn-12471",
    "evaluation_name": "temperature_sweep_250_samples_50_problems_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue is related to the OneHotEncoder class when handling unknown entries with string categories. The problem arises when the first category in the sorted list is a long string and it cannot fit into the array entries, leading to a ValueError. It's necessary to investigate the transform method of the OneHotEncoder class to understand how it handles unknown strings and ensure memory safety for arrays with different string sizes.",
            "search_requests": [
              {
                "query": null,
                "class_names": [
                  "OneHotEncoder"
                ],
                "code_snippet": null,
                "file_pattern": "**/preprocessing/**/*.py",
                "function_names": [
                  "transform"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 116,
                "span_id": "OneHotEncoder.transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [
                  "OneHotEncoder"
                ],
                "code_snippet": null,
                "file_pattern": "**/preprocessing/**/*.py",
                "function_names": [
                  "transform"
                ]
              }
            ]
          },
          "input_tokens": 3838,
          "output_tokens": 156,
          "retry_message": null,
          "completion_cost": 0.013854
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 116,
            "span_id": "OneHotEncoder.transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue is about handling unknown categories in the OneHotEncoder when the categories are strings and the memory of the arrays is not handled safely, leading to a ValueError. The provided search results contain relevant code spans within the 'sklearn/preprocessing/_encoders.py' file, specifically the '__init__' and 'transform' methods of the 'OneHotEncoder' class. These methods deal with initializing the encoder and transforming the input data, respectively, which are directly related to the steps that lead to the error described in the issue. The '__init__' method includes parameters like 'handle_unknown' which is relevant to the issue, and the 'transform' method deals with the transformation logic that needs to safely handle unknown categories. Therefore, these code spans are relevant for addressing the issue.",
            "identified_spans": [
              {
                "span_ids": [
                  "OneHotEncoder.__init__",
                  "OneHotEncoder.transform"
                ],
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 2103,
          "output_tokens": 245,
          "retry_message": null,
          "completion_cost": 0.009984
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The file context provided includes the OneHotEncoder class and its transform method. This is relevant to the issue as the problem described involves the handling of unknown entries in the transform method when categories are strings. Although the specific fix mentioned in the issue notes is not present ('where I check the size of the elements in the array before, and I cast them into objects if necessary'), the relevant method requiring modification is identified. This suggests that additional logic needs to be added to this method to handle the memory safety for arrays with different string sizes.",
            "search_suggestions": "Look for any additional methods or utilities in the codebase related to handling array memory and string size checks, which might be needed to implement the fix described in the issue notes."
          },
          "output": {
            "message": "Look for any additional methods or utilities in the codebase related to handling array memory and string size checks, which might be needed to implement the fix described in the issue notes."
          },
          "input_tokens": 1987,
          "output_tokens": 181,
          "retry_message": null,
          "completion_cost": 0.008676
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Look for any additional methods or utilities in the codebase related to handling array memory and string size checks, which might be needed to implement the fix described in the issue notes.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The search for additional methods or utilities related to handling array memory and string size checks revealed that the codebase already imports utilities from the `sklearn.utils` module, which might contain useful methods for implementing the fix. Specifically, `check_array` and `_object_dtype_isnan` are imported, which suggests that the codebase might already have some utilities for array validation and handling NaN values. Further investigation into these utilities might provide the necessary functions to perform the string size checks and ensure memory safety.",
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/utils/**/*.py",
                "function_names": [
                  "check_array",
                  "_object_dtype_isnan"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 2325,
                "span_id": "check_array",
                "file_path": "sklearn/utils/validation.py"
              },
              {
                "rank": 1,
                "tokens": 301,
                "span_id": "impl:41",
                "file_path": "sklearn/utils/fixes.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/utils/**/*.py",
                "function_names": [
                  "check_array",
                  "_object_dtype_isnan"
                ]
              }
            ]
          },
          "input_tokens": 4452,
          "output_tokens": 209,
          "retry_message": null,
          "completion_cost": 0.016491
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 2325,
            "span_id": "check_array",
            "file_path": "sklearn/utils/validation.py"
          },
          {
            "rank": 1,
            "tokens": 301,
            "span_id": "impl:41",
            "file_path": "sklearn/utils/fixes.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue involves the OneHotEncoder's handling of unknown categories when the categories are strings. Specifically, when the 'handle_unknown' parameter is set to 'ignore' and the categories are strings, a ValueError can occur if there is a mismatch in string lengths. This issue points to a potential problem in the transform method of the OneHotEncoder class. The provided file context already identifies relevant code spans in the OneHotEncoder class, including the __init__ and transform methods. The new search results include the check_array function from sklearn/utils/validation.py, which is likely relevant because it validates the input array before transformation in the OneHotEncoder. This function ensures the array is in the correct format, which is crucial for the OneHotEncoder's transformation process, especially given the nature of the reported issue involving string categories. Additionally, the check_X_y function is also found, which could be related to ensuring the compatibility of X and y datasets in a supervised learning context, which might also be relevant in the context of the OneHotEncoder's fit and transform methods. Given these findings, the relevant code spans identified are in the OneHotEncoder class, the check_array function, and possibly the check_X_y function, as they all pertain to data validation and transformation, which are central to the reported issue.",
            "identified_spans": [
              {
                "span_ids": [
                  "OneHotEncoder.__init__",
                  "OneHotEncoder.transform"
                ],
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "span_ids": [
                  "check_array"
                ],
                "file_path": "sklearn/utils/validation.py"
              },
              {
                "span_ids": [
                  "check_X_y"
                ],
                "file_path": "sklearn/utils/validation.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 5093,
          "output_tokens": 423,
          "retry_message": null,
          "completion_cost": 0.021624
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The file context includes the relevant class `OneHotEncoder` and its `transform` method, which is directly related to the issue described. Additionally, several utilities from `sklearn.utils` are imported, such as `check_array` and `_object_dtype_isnan`, which could be used for implementing the fix to handle array memory and string size checks. The codebase appears to already have some mechanisms for array validation and handling NaN values, which suggests that the necessary functions to perform the string size checks and ensure memory safety might be present. Further investigation into these utilities might provide the needed context to complete the implementation.",
            "search_suggestions": "Explore the usage and functionality of `check_array` and `_object_dtype_isnan` in the `sklearn.utils` module to identify if they contain the necessary methods for performing string size checks and ensuring memory safety. Additionally, consider looking into the specific implementation details of how `OneHotEncoder` handles unknown categories and how this interacts with array memory management."
          },
          "output": {
            "message": "Explore the usage and functionality of `check_array` and `_object_dtype_isnan` in the `sklearn.utils` module to identify if they contain the necessary methods for performing string size checks and ensuring memory safety. Additionally, consider looking into the specific implementation details of how `OneHotEncoder` handles unknown categories and how this interacts with array memory management."
          },
          "input_tokens": 4159,
          "output_tokens": 243,
          "retry_message": null,
          "completion_cost": 0.016122
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Explore the usage and functionality of `check_array` and `_object_dtype_isnan` in the `sklearn.utils` module to identify if they contain the necessary methods for performing string size checks and ensuring memory safety. Additionally, consider looking into the specific implementation details of how `OneHotEncoder` handles unknown categories and how this interacts with array memory management.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "After exploring the `sklearn.utils` module, the `check_array` function is identified as a candidate for ensuring memory safety and validating arrays. However, it lacks specific string size checks. The `_object_dtype_isnan` function is relevant for handling NaN values in object dtype arrays but does not address string size issues directly. The `OneHotEncoder` class's `transform` method is key, especially where it uses `check_is_fitted` to validate that the encoder is fitted and `check_array` from `sklearn.utils.validation` to check and potentially transform the input array. Further refinement in the `transform` method or the introduction of new checks within the class may be necessary to manage string sizes and avoid the described ValueError.",
            "search_requests": [
              {
                "query": null,
                "class_names": [
                  "OneHotEncoder"
                ],
                "code_snippet": null,
                "file_pattern": "**/preprocessing/_encoders.py",
                "function_names": [
                  "transform"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 116,
                "span_id": "OneHotEncoder.transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [
                  "OneHotEncoder"
                ],
                "code_snippet": null,
                "file_pattern": "**/preprocessing/_encoders.py",
                "function_names": [
                  "transform"
                ]
              }
            ]
          },
          "input_tokens": 6892,
          "output_tokens": 264,
          "retry_message": null,
          "completion_cost": 0.024635999999999998
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 116,
            "span_id": "OneHotEncoder.transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue is about handling memory safely when using OneHotEncoder with string categories and 'ignore unknown' parameter, which leads to a ValueError due to truncation of string categories. The current file context already identified relevant code spans in `sklearn/preprocessing/_encoders.py` and `sklearn/utils/validation.py`. The new search results re-introduce the same code spans from `sklearn/preprocessing/_encoders.py`, confirming the relevance of the identified spans in the context. However, the search results lack the specific implementation details or checks related to handling large strings or potential for truncation, which might be in other parts of the codebase. Given the current context and this repeated relevant file, the search task seems almost complete but could benefit from further checks in other parts of the codebase or implementation details as suggested by the reported issue.",
            "identified_spans": [
              {
                "span_ids": [
                  "docstring",
                  "OneHotEncoder",
                  "OneHotEncoder.__init__",
                  "OneHotEncoder.transform"
                ],
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 4710,
          "output_tokens": 271,
          "retry_message": null,
          "completion_cost": 0.018195
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The `OneHotEncoder` class's `transform` method uses `check_is_fitted` to ensure it is fitted and `check_array` from `sklearn.utils.validation` to validate and potentially transform the input array. However, `check_array` does not currently include specific checks for string size, which could lead to memory issues and the described `ValueError`. Relevant parts of the code for addressing the issue are present, but additional specific checks or modifications may still be required within the `transform` method or the `OneHotEncoder` class to handle string sizes and prevent the error.",
            "search_suggestions": "Look for additional utility functions in `sklearn.utils` that can handle string size checks, or consider enhancing `check_array` to include such checks if no suitable existing function is found."
          },
          "output": {},
          "input_tokens": 4213,
          "output_tokens": 203,
          "retry_message": null,
          "completion_cost": 0.015684
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "OneHotEncoder.transform",
            "file_path": "sklearn/preprocessing/_encoders.py",
            "scratch_pad": "The reported issue is about handling unknown strings in OneHotEncoder with the 'handle_unknown' parameter set to 'ignore'. The problem arises when the categories are strings and one of the categories is a long string, causing a ValueError during the transform method. To fix this, we need to check the size of the elements in the array before transforming and cast them into objects if necessary.",
            "instructions": "Modify the transform method in OneHotEncoder to check the size of the elements in the array and cast them into objects if necessary to avoid truncation and the resulting ValueError."
          },
          "output": {
            "span_id": "OneHotEncoder.transform",
            "end_line": 604,
            "file_path": "sklearn/preprocessing/_encoders.py",
            "start_line": 585,
            "instructions": "Modify the transform method in OneHotEncoder to check the size of the elements in the array and cast them into objects if necessary to avoid truncation and the resulting ValueError."
          },
          "input_tokens": 4380,
          "output_tokens": 173,
          "retry_message": null,
          "completion_cost": 0.015735
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "OneHotEncoder.transform",
        "end_line": 604,
        "file_path": "sklearn/preprocessing/_encoders.py",
        "max_tokens": 1000,
        "start_line": 585,
        "temperature": 1.6,
        "instructions": "Modify the transform method in OneHotEncoder to check the size of the elements in the array and cast them into objects if necessary to avoid truncation and the resulting ValueError.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "```json\n\"<replace>\n    def transform(self, X):\n        \"\"\"Transform X using one-hot encoding.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_features]\n            The data to encode.\n\n        Returns\n        -------\n        X_out : sparse matrix if sparse=True else a 2-d array\n            Transformed input.\n        \"\"\"\n        check_is_fitted(self, 'categories_')\n        if self._legacy_mode:\n            return _transform_selected(X, self._legacy_transform, self.dtype,\n                                       self._categorical_features,\n                                       copy=True)\n        else:\n            X = check_array(X, dtype=None, force_all_finite=False)\n            for i in range(X.shape[1]):\n                if X[:, i].dtype.kind == 'U' or X[:, i].dtype.kind == 'S':\n                    max_len = max(len(str(category)) for category in self.categories_[i])\n                    if any(len(str(x)) < max_len for x in X[:, i]):\n                        X[:, i] = X[:, i].astype(object)\n            return self._transform_new(X)\n</replace>\""
          },
          "output": {
            "diff": "--- sklearn/preprocessing/_encoders.py\n+++ sklearn/preprocessing/_encoders.py\n@@ -601,6 +601,12 @@\n                                        self._categorical_features,\n                                        copy=True)\n         else:\n+            X = check_array(X, dtype=None, force_all_finite=False)\n+            for i in range(X.shape[1]):\n+                if X[:, i].dtype.kind == 'U' or X[:, i].dtype.kind == 'S':\n+                    max_len = max(len(str(category)) for category in self.categories_[i])\n+                    if any(len(str(x)) < max_len for x in X[:, i]):\n+                        X[:, i] = X[:, i].astype(object)\n             return self._transform_new(X)\n \n     def inverse_transform(self, X):\n",
            "message": "Applied the change to sklearn/preprocessing/_encoders.py.\n\n<scratch_pad>\n```json\n\"</scratch_pad>",
            "verification_errors": []
          },
          "input_tokens": 8142,
          "output_tokens": 292,
          "retry_message": null,
          "completion_cost": 0.028806
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": "--- sklearn/preprocessing/_encoders.py\n+++ sklearn/preprocessing/_encoders.py\n@@ -601,6 +601,12 @@\n                                        self._categorical_features,\n                                        copy=True)\n         else:\n+            X = check_array(X, dtype=None, force_all_finite=False)\n+            for i in range(X.shape[1]):\n+                if X[:, i].dtype.kind == 'U' or X[:, i].dtype.kind == 'S':\n+                    max_len = max(len(str(category)) for category in self.categories_[i])\n+                    if any(len(str(x)) < max_len for x in X[:, i]):\n+                        X[:, i] = X[:, i].astype(object)\n             return self._transform_new(X)\n \n     def inverse_transform(self, X):\n",
        "model": "deepseek-coder",
        "message": "Applied the change to sklearn/preprocessing/_encoders.py.\n\n<scratch_pad>\n```json\n\"</scratch_pad>",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": [],
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "finish",
            "finish": "The change has been applied successfully in the transform method of OneHotEncoder, ensuring that string elements in the array are properly handled to prevent truncation and the resulting ValueError.",
            "reject": null,
            "span_id": null,
            "file_path": null,
            "scratch_pad": "The applied change ensures that if any element in the array to be transformed is a string and is shorter than the longest string category found in the fitted OneHotEncoder, the element is cast to an object dtype to avoid truncation and potential ValueError. This addresses the specific issue reported.",
            "instructions": null
          },
          "output": {
            "message": "The change has been applied successfully in the transform method of OneHotEncoder, ensuring that string elements in the array are properly handled to prevent truncation and the resulting ValueError."
          },
          "input_tokens": 4947,
          "output_tokens": 150,
          "retry_message": null,
          "completion_cost": 0.017091000000000002
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "model": "gpt-4o",
        "output": {
          "model": "deepseek-coder",
          "temperature": 1.6
        },
        "message": "The change has been applied successfully in the transform method of OneHotEncoder, ensuring that string elements in the array are properly handled to prevent truncation and the resulting ValueError.",
        "max_tokens": 1000,
        "temperature": 0.0,
        "max_iterations": null,
        "include_message_history": false
      },
      "actions": []
    }
  ],
  "initial_message": "OneHotEncoder ignore unknown error when categories are strings \n#### Description\r\n\r\nThis bug is very specific, but it happens when you set OneHotEncoder to ignore unknown entries.\r\nand your labels are strings. The memory of the arrays is not handled safely and it can lead to a ValueError\r\n\r\nBasically, when you call the transform method it will sets all the unknown strings on your array to OneHotEncoder.categories_[i][0] which is the first category alphabetically sorted given for fit\r\nIf this OneHotEncoder.categories_[i][0] is a long string, and the array that you want to transform has small strings, then it is impossible to fit the whole  OneHotEncoder.categories_[i][0] into the entries of the array we want to transform. So  OneHotEncoder.categories_[i][0]  is truncated and this raise the ValueError.\r\n\r\n\r\n\r\n#### Steps/Code to Reproduce\r\n```\r\n\r\nimport numpy as np\r\nfrom sklearn.preprocessing import OneHotEncoder\r\n\r\n\r\n# It needs to be numpy arrays, the error does not appear \r\n# is you have lists of lists because it gets treated like an array of objects.\r\ntrain  = np.array([ '22','333','4444','11111111' ]).reshape((-1,1))\r\ntest   = np.array([ '55555',  '22' ]).reshape((-1,1))\r\n\r\nohe = OneHotEncoder(dtype=bool,handle_unknown='ignore')\r\n\r\nohe.fit( train )\r\nenc_test = ohe.transform( test )\r\n\r\n```\r\n\r\n\r\n#### Expected Results\r\nHere we should get an sparse matrix 2x4 false everywhere except at (1,1) the '22' that is known\r\n\r\n#### Actual Results\r\n\r\n> ValueError: y contains previously unseen labels: ['111111']\r\n\r\n\r\n#### Versions\r\nSystem:\r\n    python: 2.7.12 (default, Dec  4 2017, 14:50:18)  [GCC 5.4.0 20160609]\r\n   machine: Linux-4.4.0-138-generic-x86_64-with-Ubuntu-16.04-xenial\r\nexecutable: /usr/bin/python\r\n\r\nBLAS:\r\n    macros: HAVE_CBLAS=None\r\ncblas_libs: openblas, openblas\r\n  lib_dirs: /usr/lib\r\n\r\nPython deps:\r\n    Cython: 0.25.2\r\n     scipy: 0.18.1\r\nsetuptools: 36.7.0\r\n       pip: 9.0.1\r\n     numpy: 1.15.2\r\n    pandas: 0.19.1\r\n   sklearn: 0.21.dev0\r\n\r\n\r\n\r\n#### Comments\r\n\r\nI already implemented a fix for this issue, where I check the size of the elements in the array before, and I cast them into objects if necessary.\n"
}