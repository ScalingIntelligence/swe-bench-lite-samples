{
  "info": {
    "duration": 442.8113558292389,
    "submission": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..5ab3d5dc9 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -106,6 +106,12 @@ class _BaseEncoder(BaseEstimator, TransformerMixin):\n                            \" during transform\".format(diff, i))\n                     raise ValueError(msg)\n                 else:\n+                    # Check the length of the strings in the categories and promote the array to an object type if necessary\n+                    max_length_category = max(len(str(category)) for category in self.categories_[i])\n+                    if max_length_category > len(str(Xi[0])):\n+                        X = X.astype(np.object)\n+                        Xi = X[:, i]\n+\n                     # Set the problematic rows to an acceptable value and\n                     # continue `The rows are marked `X_mask` and will be\n                     # removed later.\n",
    "total_cost": 0.19072200000000003,
    "instance_id": "scikit-learn__scikit-learn-12471",
    "evaluation_name": "temperature_sweep_250_samples_50_problems_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue pertains to the OneHotEncoder class in scikit-learn, specifically when using the `handle_unknown='ignore'` parameter with string categories. The error occurs during the transform method because of memory handling issues with string lengths. Given the specific error and context, the OneHotEncoder class and its transform method need to be investigated for the root cause and potential fixes.",
            "search_requests": [
              {
                "query": null,
                "class_names": [
                  "OneHotEncoder"
                ],
                "code_snippet": null,
                "file_pattern": null,
                "function_names": [
                  "transform"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 116,
                "span_id": "OneHotEncoder.transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [
                  "OneHotEncoder"
                ],
                "code_snippet": null,
                "file_pattern": null,
                "function_names": [
                  "transform"
                ]
              }
            ]
          },
          "input_tokens": 3838,
          "output_tokens": 137,
          "retry_message": null,
          "completion_cost": 0.013569
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 116,
            "span_id": "OneHotEncoder.transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue seems to be related to the handling of unknown categories in the OneHotEncoder while dealing with string labels. The specific scenario involves the truncation of long strings due to their length when fitting them into arrays with smaller string entries, leading to a ValueError. The provided search results contain the OneHotEncoder class definition, which includes the __init__ method for initial configuration and the transform method where the error might be occurring due to improper handling of unknown labels. These segments are directly relevant as they deal with the settings and main processing of the OneHotEncoder. Since the issue described is very specific, ensuring that the solution addresses the mismatch in string lengths is crucial.",
            "identified_spans": [
              {
                "span_ids": [
                  "OneHotEncoder",
                  "OneHotEncoder.__init__",
                  "OneHotEncoder.transform"
                ],
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 2103,
          "output_tokens": 223,
          "retry_message": null,
          "completion_cost": 0.009654
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The issue pertains to the OneHotEncoder class in scikit-learn, specifically when using the `handle_unknown='ignore'` parameter with string categories. The error occurs during the transform method because of memory handling issues with string lengths. Given the specific error and context, the OneHotEncoder class and its transform method need to be investigated for the root cause and potential fixes.",
            "search_suggestions": "Look into the _transform_selected and _transform_new methods within the OneHotEncoder class to see how the transformation of the data is handled with respect to the handle_unknown parameter and string categories."
          },
          "output": {
            "message": "Look into the _transform_selected and _transform_new methods within the OneHotEncoder class to see how the transformation of the data is handled with respect to the handle_unknown parameter and string categories."
          },
          "input_tokens": 1999,
          "output_tokens": 156,
          "retry_message": null,
          "completion_cost": 0.008337
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Look into the _transform_selected and _transform_new methods within the OneHotEncoder class to see how the transformation of the data is handled with respect to the handle_unknown parameter and string categories.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The provided file context shows the initialization of the OneHotEncoder class and its transform method. However, the details of the _transform_selected and _transform_new methods are not fully provided. To understand how the transformation of the data is handled with respect to the handle_unknown parameter and string categories, a deeper investigation into these methods is required. Specifically, examining the internal logic within _transform_new and how the _transform_selected entry point is utilized in the context of string categories and handle_unknown='ignore'.",
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/preprocessing/_encoders.py",
                "function_names": [
                  "_transform_selected",
                  "_transform_new"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 228,
                "span_id": "OneHotEncoder._transform_new",
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/preprocessing/_encoders.py",
                "function_names": [
                  "_transform_selected",
                  "_transform_new"
                ]
              }
            ]
          },
          "input_tokens": 4464,
          "output_tokens": 213,
          "retry_message": null,
          "completion_cost": 0.016587
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 228,
            "span_id": "OneHotEncoder._transform_new",
            "file_path": "sklearn/preprocessing/_encoders.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue involves the handling of unknown strings in the OneHotEncoder when categories are strings. Specifically, it highlights a memory management problem leading to a ValueError when transforming arrays with small strings that encounter a long unknown category. This error is related to the transform method of the OneHotEncoder class. Based on the provided search results and existing file context, the relevant code spans are where the transform method and its internal logic are defined, especially focusing on how unknown categories are handled and the array sizes are managed. The _transform_new method in the search results seems particularly relevant as it deals with the actual transformation process and could be where adjustments are needed to address the memory issue when handling unknown strings.",
            "identified_spans": [
              {
                "span_ids": [
                  "OneHotEncoder.transform",
                  "OneHotEncoder._transform_new"
                ],
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 2813,
          "output_tokens": 223,
          "retry_message": null,
          "completion_cost": 0.011784
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The provided file context shows the initialization of the OneHotEncoder class and its transform method. However, the details of the _transform_selected and _transform_new methods are not fully provided. To understand how the transformation of the data is handled with respect to the handle_unknown parameter and string categories, a deeper investigation into these methods is required. Specifically, examining the internal logic within _transform_new and how the _transform_selected entry point is utilized in the context of string categories and handle_unknown='ignore'.",
            "search_suggestions": "Look into the _transform_selected and _transform_new methods in the OneHotEncoder class to understand how the transformation of data is handled with respect to the handle_unknown parameter and string categories."
          },
          "output": {
            "message": "Look into the _transform_selected and _transform_new methods in the OneHotEncoder class to understand how the transformation of data is handled with respect to the handle_unknown parameter and string categories."
          },
          "input_tokens": 3838,
          "output_tokens": 185,
          "retry_message": null,
          "completion_cost": 0.014289
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Look into the _transform_selected and _transform_new methods in the OneHotEncoder class to understand how the transformation of data is handled with respect to the handle_unknown parameter and string categories.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The provided code excerpt of the OneHotEncoder class shows the methods related to data transformation. The _transform_new method is used for transforming data under the new API conditions. This method calls the _transform method internally, which likely contains the logic for handling unknown categories based on the handle_unknown parameter. The _handle_deprecations method is also relevant as it sets up the mode (legacy or new) and handles the transition from old to new API parameters. To fully understand the handling of string categories and the handle_unknown parameter, we should investigate the _transform method and its interaction with these settings.",
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/preprocessing/_encoders.py",
                "function_names": [
                  "_transform"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 218,
                "span_id": "_BaseEncoder._transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/preprocessing/_encoders.py",
                "function_names": [
                  "_transform"
                ]
              }
            ]
          },
          "input_tokens": 6534,
          "output_tokens": 220,
          "retry_message": null,
          "completion_cost": 0.022902000000000002
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 218,
            "span_id": "_BaseEncoder._transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue pertains to a specific error encountered when using the OneHotEncoder with 'handle_unknown' set to 'ignore' and input labels being strings. The error arises due to the truncation of long strings during the transformation process, leading to a ValueError. Given the context and the search results, it is crucial to identify the sections of code that handle the transformation of input data and the management of unknown categories. The provided file context includes several key sections such as the `OneHotEncoder` class, its `transform` method, and the `_transform_new` method which is responsible for the actual transformation logic when not in legacy mode. The search results provide additional insights into the `_transform` method within the `_BaseEncoder` class, specifically how it processes each feature column and manages unknown categories. This method is crucial as it deals directly with encoding and handling unknown values, which is central to the issue described. Thus, both the `OneHotEncoder.transform` method and the `_BaseEncoder._transform` method are identified as relevant, as they are integral to the transformation process and the handling of unknown values.",
            "identified_spans": [
              {
                "span_ids": [
                  "OneHotEncoder.transform",
                  "_BaseEncoder._transform"
                ],
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 4415,
          "output_tokens": 310,
          "retry_message": null,
          "completion_cost": 0.017895
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The provided code excerpt of the OneHotEncoder class shows the methods related to data transformation. The _transform_new method is used for transforming data under the new API conditions. This method calls the _transform method internally, which likely contains the logic for handling unknown categories based on the handle_unknown parameter. The _handle_deprecations method is also relevant as it sets up the mode (legacy or new) and handles the transition from old to new API parameters. To fully understand the handling of string categories and the handle_unknown parameter, we should investigate the _transform method and its interaction with these settings.",
            "search_suggestions": "Investigate the _transform method within the OneHotEncoder class to fully understand how it handles string categories and the handle_unknown parameter. Also, look for any methods or logic related to resizing or handling the memory of arrays during transformation to address the specific error reported."
          },
          "output": {},
          "input_tokens": 4197,
          "output_tokens": 214,
          "retry_message": null,
          "completion_cost": 0.015801
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "_BaseEncoder._transform",
            "file_path": "sklearn/preprocessing/_encoders.py",
            "scratch_pad": "The issue arises when transforming arrays with unknown string labels that are longer than the known categories. This can lead to truncation and raises a ValueError. To fix this, we need to ensure that the array can handle the longer strings by promoting the array to an object type if necessary.",
            "instructions": "Modify the `_transform` method in the `_BaseEncoder` class to check the length of the strings in the categories and promote the array to an object type if the strings in the array to transform are shorter than the strings in the categories."
          },
          "output": {
            "span_id": "_BaseEncoder._transform",
            "end_line": 118,
            "file_path": "sklearn/preprocessing/_encoders.py",
            "start_line": 91,
            "instructions": "Modify the `_transform` method in the `_BaseEncoder` class to check the length of the strings in the categories and promote the array to an object type if the strings in the array to transform are shorter than the strings in the categories."
          },
          "input_tokens": 4515,
          "output_tokens": 167,
          "retry_message": null,
          "completion_cost": 0.01605
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "_BaseEncoder._transform",
        "end_line": 118,
        "file_path": "sklearn/preprocessing/_encoders.py",
        "max_tokens": 1000,
        "start_line": 91,
        "temperature": 1.6,
        "instructions": "Modify the `_transform` method in the `_BaseEncoder` class to check the length of the strings in the categories and promote the array to an object type if the strings in the array to transform are shorter than the strings in the categories.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "```python\n\n<replace>\n    def _transform(self, X, handle_unknown='error'):\n        X = self._check_X(X)\n\n        _, n_features = X.shape\n        X_int = np.zeros_like(X, dtype=np.int)\n        X_mask = np.ones_like(X, dtype=np.bool)\n\n        for i in range(n_features):\n            Xi = X[:, i]\n            diff, valid_mask = _encode_check_unknown(Xi, self.categories_[i],\n                                                     return_mask=True)\n\n            if not np.all(valid_mask):\n                if handle_unknown == 'error':\n                    msg = (\"Found unknown categories {0} in column {1}\"\n                           \" during transform\".format(diff, i))\n                    raise ValueError(msg)\n                else:\n                    # Check the length of the strings in the categories and promote the array to an object type if necessary\n                    max_length_category = max(len(str(category)) for category in self.categories_[i])\n                    if max_length_category > len(str(Xi[0])):\n                        X = X.astype(np.object)\n                        Xi = X[:, i]\n\n                    # Set the problematic rows to an acceptable value and\n                    # continue `The rows are marked `X_mask` and will be\n                    # removed later.\n                    X_mask[:, i] = valid_mask\n                    Xi = Xi.copy()\n                    Xi[~valid_mask] = self.categories_[i][0]\n            _, encoded = _encode(Xi, self.categories_[i], encode=True)\n            X_int[:, i] = encoded\n\n        return X_int, X_mask\n</replace>"
          },
          "output": {
            "diff": "--- sklearn/preprocessing/_encoders.py\n+++ sklearn/preprocessing/_encoders.py\n@@ -106,6 +106,12 @@\n                            \" during transform\".format(diff, i))\n                     raise ValueError(msg)\n                 else:\n+                    # Check the length of the strings in the categories and promote the array to an object type if necessary\n+                    max_length_category = max(len(str(category)) for category in self.categories_[i])\n+                    if max_length_category > len(str(Xi[0])):\n+                        X = X.astype(np.object)\n+                        Xi = X[:, i]\n+\n                     # Set the problematic rows to an acceptable value and\n                     # continue `The rows are marked `X_mask` and will be\n                     # removed later.\n",
            "message": "Applied the change to sklearn/preprocessing/_encoders.py.\n\n<scratch_pad>\n```python\n\n</scratch_pad>",
            "verification_errors": []
          },
          "input_tokens": 6897,
          "output_tokens": 404,
          "retry_message": null,
          "completion_cost": 0.026751
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": "--- sklearn/preprocessing/_encoders.py\n+++ sklearn/preprocessing/_encoders.py\n@@ -106,6 +106,12 @@\n                            \" during transform\".format(diff, i))\n                     raise ValueError(msg)\n                 else:\n+                    # Check the length of the strings in the categories and promote the array to an object type if necessary\n+                    max_length_category = max(len(str(category)) for category in self.categories_[i])\n+                    if max_length_category > len(str(Xi[0])):\n+                        X = X.astype(np.object)\n+                        Xi = X[:, i]\n+\n                     # Set the problematic rows to an acceptable value and\n                     # continue `The rows are marked `X_mask` and will be\n                     # removed later.\n",
        "model": "deepseek-coder",
        "message": "Applied the change to sklearn/preprocessing/_encoders.py.\n\n<scratch_pad>\n```python\n\n</scratch_pad>",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": [],
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "finish",
            "finish": "The issue has been resolved by promoting the array to an object type when necessary to avoid truncation of strings, ensuring that the transformation can proceed without raising a ValueError.",
            "reject": null,
            "span_id": null,
            "file_path": null,
            "scratch_pad": "The applied change ensures that if the length of the strings in the categories is greater than the length of the strings in the array to transform, the array is promoted to an object type. This avoids truncation of the strings and thus prevents the ValueError.",
            "instructions": null
          },
          "output": {
            "message": "The issue has been resolved by promoting the array to an object type when necessary to avoid truncation of strings, ensuring that the transformation can proceed without raising a ValueError."
          },
          "input_tokens": 4986,
          "output_tokens": 143,
          "retry_message": null,
          "completion_cost": 0.017103
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "model": "gpt-4o",
        "output": {
          "model": "deepseek-coder",
          "temperature": 1.6
        },
        "message": "The issue has been resolved by promoting the array to an object type when necessary to avoid truncation of strings, ensuring that the transformation can proceed without raising a ValueError.",
        "max_tokens": 1000,
        "temperature": 0.0,
        "max_iterations": null,
        "include_message_history": false
      },
      "actions": []
    }
  ],
  "initial_message": "OneHotEncoder ignore unknown error when categories are strings \n#### Description\r\n\r\nThis bug is very specific, but it happens when you set OneHotEncoder to ignore unknown entries.\r\nand your labels are strings. The memory of the arrays is not handled safely and it can lead to a ValueError\r\n\r\nBasically, when you call the transform method it will sets all the unknown strings on your array to OneHotEncoder.categories_[i][0] which is the first category alphabetically sorted given for fit\r\nIf this OneHotEncoder.categories_[i][0] is a long string, and the array that you want to transform has small strings, then it is impossible to fit the whole  OneHotEncoder.categories_[i][0] into the entries of the array we want to transform. So  OneHotEncoder.categories_[i][0]  is truncated and this raise the ValueError.\r\n\r\n\r\n\r\n#### Steps/Code to Reproduce\r\n```\r\n\r\nimport numpy as np\r\nfrom sklearn.preprocessing import OneHotEncoder\r\n\r\n\r\n# It needs to be numpy arrays, the error does not appear \r\n# is you have lists of lists because it gets treated like an array of objects.\r\ntrain  = np.array([ '22','333','4444','11111111' ]).reshape((-1,1))\r\ntest   = np.array([ '55555',  '22' ]).reshape((-1,1))\r\n\r\nohe = OneHotEncoder(dtype=bool,handle_unknown='ignore')\r\n\r\nohe.fit( train )\r\nenc_test = ohe.transform( test )\r\n\r\n```\r\n\r\n\r\n#### Expected Results\r\nHere we should get an sparse matrix 2x4 false everywhere except at (1,1) the '22' that is known\r\n\r\n#### Actual Results\r\n\r\n> ValueError: y contains previously unseen labels: ['111111']\r\n\r\n\r\n#### Versions\r\nSystem:\r\n    python: 2.7.12 (default, Dec  4 2017, 14:50:18)  [GCC 5.4.0 20160609]\r\n   machine: Linux-4.4.0-138-generic-x86_64-with-Ubuntu-16.04-xenial\r\nexecutable: /usr/bin/python\r\n\r\nBLAS:\r\n    macros: HAVE_CBLAS=None\r\ncblas_libs: openblas, openblas\r\n  lib_dirs: /usr/lib\r\n\r\nPython deps:\r\n    Cython: 0.25.2\r\n     scipy: 0.18.1\r\nsetuptools: 36.7.0\r\n       pip: 9.0.1\r\n     numpy: 1.15.2\r\n    pandas: 0.19.1\r\n   sklearn: 0.21.dev0\r\n\r\n\r\n\r\n#### Comments\r\n\r\nI already implemented a fix for this issue, where I check the size of the elements in the array before, and I cast them into objects if necessary.\n"
}