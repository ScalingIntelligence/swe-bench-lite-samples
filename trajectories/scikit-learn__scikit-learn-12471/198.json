{
  "info": {
    "duration": 292.9111316204071,
    "submission": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..0b47e359d 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -97,6 +97,11 @@ class _BaseEncoder(BaseEstimator, TransformerMixin):\n \n         for i in range(n_features):\n             Xi = X[:, i]\n+            category_lengths = [len(cat) for cat in self.categories_[i]]\n+            max_category_length = max(category_lengths)\n+            if (Xi.dtype.kind != 'O' and max_category_length > Xi.dtype.itemsize) or (Xi.dtype.kind == 'O' and max_category_length > np.max([len(x) for x in Xi])):\n+                Xi = Xi.astype('object')\n+\n             diff, valid_mask = _encode_check_unknown(Xi, self.categories_[i],\n                                                      return_mask=True)\n \n",
    "total_cost": 0.112182,
    "instance_id": "scikit-learn__scikit-learn-12471",
    "evaluation_name": "temperature_sweep_250_samples_50_problems_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue describes a specific bug in the `OneHotEncoder` class where a `ValueError` is raised due to the handling of unknown string categories. The `OneHotEncoder` class and its methods, especially `fit`, `transform`, and `_transform`, are likely places to start investigating. The issue involves string categories and the handling of unknown entries, so focusing on these aspects in the `OneHotEncoder` class should be fruitful.",
            "search_requests": [
              {
                "query": "OneHotEncoder ignore unknown error when categories are strings",
                "class_names": [
                  "OneHotEncoder"
                ],
                "code_snippet": null,
                "file_pattern": "**/preprocessing/**/*.py",
                "function_names": [
                  "fit",
                  "transform",
                  "_transform"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 1,
                "tokens": 156,
                "span_id": "OneHotEncoder.fit",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 2,
                "tokens": 1480,
                "span_id": "OneHotEncoder",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 3,
                "tokens": 228,
                "span_id": "OneHotEncoder._transform_new",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 4,
                "tokens": 789,
                "span_id": "OneHotEncoder._handle_deprecations",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 5,
                "tokens": 554,
                "span_id": "OneHotEncoder._legacy_fit_transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 6,
                "tokens": 182,
                "span_id": "OneHotEncoder.fit_transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 7,
                "tokens": 407,
                "span_id": "OneHotEncoder._legacy_transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 9,
                "tokens": 218,
                "span_id": "_BaseEncoder._transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 10,
                "tokens": 55,
                "span_id": "OneHotEncoder.active_features_",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 10,
                "tokens": 55,
                "span_id": "OneHotEncoder.n_values_",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 10,
                "tokens": 55,
                "span_id": "OneHotEncoder.feature_indices_",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 11,
                "tokens": 458,
                "span_id": "OneHotEncoder.inverse_transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 14,
                "tokens": 116,
                "span_id": "OneHotEncoder.transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 15,
                "tokens": 83,
                "span_id": "OrdinalEncoder.transform",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 15,
                "tokens": 99,
                "span_id": "OrdinalEncoder.fit",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 20,
                "tokens": 219,
                "span_id": "OneHotEncoder.get_feature_names",
                "file_path": "sklearn/preprocessing/_encoders.py"
              },
              {
                "rank": 18,
                "tokens": 68,
                "span_id": "LabelEncoder.fit",
                "file_path": "sklearn/preprocessing/label.py"
              },
              {
                "rank": 22,
                "tokens": 113,
                "span_id": "LabelEncoder.transform",
                "file_path": "sklearn/preprocessing/label.py"
              },
              {
                "rank": 37,
                "tokens": 206,
                "span_id": "MultiLabelBinarizer._transform",
                "file_path": "sklearn/preprocessing/label.py"
              },
              {
                "rank": 42,
                "tokens": 163,
                "span_id": "LabelBinarizer.fit",
                "file_path": "sklearn/preprocessing/label.py"
              },
              {
                "rank": 21,
                "tokens": 616,
                "span_id": "KBinsDiscretizer.fit",
                "file_path": "sklearn/preprocessing/_discretization.py"
              },
              {
                "rank": 30,
                "tokens": 312,
                "span_id": "Imputer.fit",
                "file_path": "sklearn/preprocessing/imputation.py"
              },
              {
                "rank": 33,
                "tokens": 545,
                "span_id": "Imputer.transform",
                "file_path": "sklearn/preprocessing/imputation.py"
              },
              {
                "rank": 40,
                "tokens": 61,
                "span_id": "Normalizer.fit",
                "file_path": "sklearn/preprocessing/data.py"
              },
              {
                "rank": 41,
                "tokens": 84,
                "span_id": "MinMaxScaler.fit",
                "file_path": "sklearn/preprocessing/data.py"
              },
              {
                "rank": 35,
                "tokens": 103,
                "span_id": "FunctionTransformer.fit",
                "file_path": "sklearn/preprocessing/_function_transformer.py"
              }
            ],
            "search_requests": [
              {
                "query": "OneHotEncoder ignore unknown error when categories are strings",
                "class_names": [
                  "OneHotEncoder"
                ],
                "code_snippet": null,
                "file_pattern": "**/preprocessing/**/*.py",
                "function_names": [
                  "fit",
                  "transform",
                  "_transform"
                ]
              }
            ]
          },
          "input_tokens": 3838,
          "output_tokens": 188,
          "retry_message": null,
          "completion_cost": 0.014334
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 1,
            "tokens": 156,
            "span_id": "OneHotEncoder.fit",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 2,
            "tokens": 1480,
            "span_id": "OneHotEncoder",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 3,
            "tokens": 228,
            "span_id": "OneHotEncoder._transform_new",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 4,
            "tokens": 789,
            "span_id": "OneHotEncoder._handle_deprecations",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 5,
            "tokens": 554,
            "span_id": "OneHotEncoder._legacy_fit_transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 6,
            "tokens": 182,
            "span_id": "OneHotEncoder.fit_transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 7,
            "tokens": 407,
            "span_id": "OneHotEncoder._legacy_transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 9,
            "tokens": 218,
            "span_id": "_BaseEncoder._transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 10,
            "tokens": 55,
            "span_id": "OneHotEncoder.active_features_",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 10,
            "tokens": 55,
            "span_id": "OneHotEncoder.n_values_",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 10,
            "tokens": 55,
            "span_id": "OneHotEncoder.feature_indices_",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 11,
            "tokens": 458,
            "span_id": "OneHotEncoder.inverse_transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 14,
            "tokens": 116,
            "span_id": "OneHotEncoder.transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 15,
            "tokens": 83,
            "span_id": "OrdinalEncoder.transform",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 15,
            "tokens": 99,
            "span_id": "OrdinalEncoder.fit",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 18,
            "tokens": 68,
            "span_id": "LabelEncoder.fit",
            "file_path": "sklearn/preprocessing/label.py"
          },
          {
            "rank": 20,
            "tokens": 219,
            "span_id": "OneHotEncoder.get_feature_names",
            "file_path": "sklearn/preprocessing/_encoders.py"
          },
          {
            "rank": 21,
            "tokens": 616,
            "span_id": "KBinsDiscretizer.fit",
            "file_path": "sklearn/preprocessing/_discretization.py"
          },
          {
            "rank": 22,
            "tokens": 113,
            "span_id": "LabelEncoder.transform",
            "file_path": "sklearn/preprocessing/label.py"
          },
          {
            "rank": 30,
            "tokens": 312,
            "span_id": "Imputer.fit",
            "file_path": "sklearn/preprocessing/imputation.py"
          },
          {
            "rank": 33,
            "tokens": 545,
            "span_id": "Imputer.transform",
            "file_path": "sklearn/preprocessing/imputation.py"
          },
          {
            "rank": 35,
            "tokens": 103,
            "span_id": "FunctionTransformer.fit",
            "file_path": "sklearn/preprocessing/_function_transformer.py"
          },
          {
            "rank": 37,
            "tokens": 206,
            "span_id": "MultiLabelBinarizer._transform",
            "file_path": "sklearn/preprocessing/label.py"
          },
          {
            "rank": 40,
            "tokens": 61,
            "span_id": "Normalizer.fit",
            "file_path": "sklearn/preprocessing/data.py"
          },
          {
            "rank": 41,
            "tokens": 84,
            "span_id": "MinMaxScaler.fit",
            "file_path": "sklearn/preprocessing/data.py"
          },
          {
            "rank": 42,
            "tokens": 163,
            "span_id": "LabelBinarizer.fit",
            "file_path": "sklearn/preprocessing/label.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue is about handling 'unknown' categories in OneHotEncoder when categories are strings. Specifically, it involves handling the situation where the first category alphabetically (represented by OneHotEncoder.categories_[i][0]) is a long string and the array to be transformed contains smaller strings, leading to truncation and a ValueError. The search results contain several spans from sklearn/preprocessing/_encoders.py that are relevant to this issue. For instance, the `OneHotEncoder` class and its methods like `__init__`, `fit`, `transform`, and `_transform` are directly involved in how the OneHotEncoder handles categories and transformations. The `_BaseEncoder._transform` method is particularly interesting as it processes the data and handles unknown categories according to the `handle_unknown` parameter. Additionally, the `OneHotEncoder._transform_new` and `OneHotEncoder.fit_transform` methods show how the encoder deals with handling unknown entries and fitting the data, respectively. Based on these findings, it is clear that the relevant code spans are in the sklearn/preprocessing/_encoders.py file, specifically in the `OneHotEncoder` class and its associated methods. These spans are directly related to the functionality of encoding and handling categories, which is central to the reported issue.",
            "identified_spans": [
              {
                "span_ids": [
                  "OneHotEncoder",
                  "OneHotEncoder.__init__",
                  "OneHotEncoder.fit",
                  "OneHotEncoder.transform",
                  "OneHotEncoder._transform_new",
                  "OneHotEncoder.fit_transform",
                  "_BaseEncoder._transform"
                ],
                "file_path": "sklearn/preprocessing/_encoders.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 5826,
          "output_tokens": 397,
          "retry_message": null,
          "completion_cost": 0.023433000000000002
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": true,
            "relevant": true,
            "scratch_pad": "The file context includes the `OneHotEncoder` class and its methods such as `fit`, `transform`, and `_transform`. The `_transform` method contains the logic for handling unknown categories, which is relevant to the reported issue. The issue suggests that a fix involves checking the size of elements in the array before casting them into objects if necessary. While the specific implementation of this fix is not present, the relevant part of the code where the modification would likely occur (handling unknown categories in `_transform`) is provided. Therefore, while the exact fix is not detailed, the relevant code context is present.",
            "search_suggestions": null
          },
          "output": {},
          "input_tokens": 2974,
          "output_tokens": 163,
          "retry_message": null,
          "completion_cost": 0.011366999999999999
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "_BaseEncoder._transform",
            "file_path": "sklearn/preprocessing/_encoders.py",
            "scratch_pad": "The issue requires handling the case when the OneHotEncoder is set to ignore unknown entries and the labels are strings. Specifically, when unknown strings are encountered, they are set to the first category alphabetically, which can lead to a ValueError if the first category string is longer than the strings in the input array. The fix involves ensuring that the array is cast to objects if necessary to avoid truncation. I'll focus on modifying the `_transform` method to include this check.",
            "instructions": "Modify the `_transform` method to include a check that casts the array to objects if the lengths of the strings in the categories do not fit within the current array dtype."
          },
          "output": {
            "span_id": "_BaseEncoder._transform",
            "end_line": 118,
            "file_path": "sklearn/preprocessing/_encoders.py",
            "start_line": 91,
            "instructions": "Modify the `_transform` method to include a check that casts the array to objects if the lengths of the strings in the categories do not fit within the current array dtype."
          },
          "input_tokens": 4813,
          "output_tokens": 193,
          "retry_message": null,
          "completion_cost": 0.017334000000000002
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "_BaseEncoder._transform",
        "end_line": 118,
        "file_path": "sklearn/preprocessing/_encoders.py",
        "max_tokens": 1000,
        "start_line": 91,
        "temperature": 1.6,
        "instructions": "Modify the `_transform` method to include a check that casts the array to objects if the lengths of the strings in the categories do not fit within the current array dtype.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "```python\n<replace>\n    def _transform(self, X, handle_unknown='error'):\n        X = self._check_X(X)\n\n        _, n_features = X.shape\n        X_int = np.zeros_like(X, dtype=np.int)\n        X_mask = np.ones_like(X, dtype=np.bool)\n\n        for i in range(n_features):\n            Xi = X[:, i]\n            category_lengths = [len(cat) for cat in self.categories_[i]]\n            max_category_length = max(category_lengths)\n            if (Xi.dtype.kind != 'O' and max_category_length > Xi.dtype.itemsize) or (Xi.dtype.kind == 'O' and max_category_length > np.max([len(x) for x in Xi])):\n                Xi = Xi.astype('object')\n\n            diff, valid_mask = _encode_check_unknown(Xi, self.categories_[i],\n                                                     return_mask=True)\n\n            if not np.all(valid_mask):\n                if handle_unknown == 'error':\n                    msg = (\"Found unknown categories {0} in column {1}\"\n                           \" during transform\".format(diff, i))\n                    raise ValueError(msg)\n                else:\n                    # Set the problematic rows to an acceptable value and\n                    # continue `The rows are marked `X_mask` and will be\n                    # removed later.\n                    X_mask[:, i] = valid_mask\n                    Xi = Xi.copy()\n                    Xi[~valid_mask] = self.categories_[i][0]\n            _, encoded = _encode(Xi, self.categories_[i], encode=True)\n            X_int[:, i] = encoded\n\n        return X_int, X_mask\n</replace>"
          },
          "output": {
            "diff": "--- sklearn/preprocessing/_encoders.py\n+++ sklearn/preprocessing/_encoders.py\n@@ -97,6 +97,11 @@\n \n         for i in range(n_features):\n             Xi = X[:, i]\n+            category_lengths = [len(cat) for cat in self.categories_[i]]\n+            max_category_length = max(category_lengths)\n+            if (Xi.dtype.kind != 'O' and max_category_length > Xi.dtype.itemsize) or (Xi.dtype.kind == 'O' and max_category_length > np.max([len(x) for x in Xi])):\n+                Xi = Xi.astype('object')\n+\n             diff, valid_mask = _encode_check_unknown(Xi, self.categories_[i],\n                                                      return_mask=True)\n \n",
            "message": "Applied the change to sklearn/preprocessing/_encoders.py.\n\n<scratch_pad>\n```python\n</scratch_pad>",
            "verification_errors": []
          },
          "input_tokens": 6735,
          "output_tokens": 423,
          "retry_message": null,
          "completion_cost": 0.02655
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": "--- sklearn/preprocessing/_encoders.py\n+++ sklearn/preprocessing/_encoders.py\n@@ -97,6 +97,11 @@\n \n         for i in range(n_features):\n             Xi = X[:, i]\n+            category_lengths = [len(cat) for cat in self.categories_[i]]\n+            max_category_length = max(category_lengths)\n+            if (Xi.dtype.kind != 'O' and max_category_length > Xi.dtype.itemsize) or (Xi.dtype.kind == 'O' and max_category_length > np.max([len(x) for x in Xi])):\n+                Xi = Xi.astype('object')\n+\n             diff, valid_mask = _encode_check_unknown(Xi, self.categories_[i],\n                                                      return_mask=True)\n \n",
        "model": "deepseek-coder",
        "message": "Applied the change to sklearn/preprocessing/_encoders.py.\n\n<scratch_pad>\n```python\n</scratch_pad>",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": [],
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "finish",
            "finish": "The issue has been addressed by checking the size of the elements in the array before transformation and casting them to objects if necessary. This ensures that long strings in the categories do not cause a ValueError due to truncation. The relevant part of the code has been updated accordingly.",
            "reject": null,
            "span_id": null,
            "file_path": null,
            "scratch_pad": "The change has been applied to the `_transform` method to ensure that the array is cast to objects if necessary to avoid truncation. This should address the specific issue of long strings causing a ValueError when using the OneHotEncoder with the 'ignore' option for unknown entries. The change checks the lengths of the strings in the categories and casts the array to object type if the maximum category length exceeds the current array's dtype length.",
            "instructions": null
          },
          "output": {
            "message": "The issue has been addressed by checking the size of the elements in the array before transformation and casting them to objects if necessary. This ensures that long strings in the categories do not cause a ValueError due to truncation. The relevant part of the code has been updated accordingly."
          },
          "input_tokens": 5378,
          "output_tokens": 202,
          "retry_message": null,
          "completion_cost": 0.019164
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "model": "gpt-4o",
        "output": {
          "model": "deepseek-coder",
          "temperature": 1.6
        },
        "message": "The issue has been addressed by checking the size of the elements in the array before transformation and casting them to objects if necessary. This ensures that long strings in the categories do not cause a ValueError due to truncation. The relevant part of the code has been updated accordingly.",
        "max_tokens": 1000,
        "temperature": 0.0,
        "max_iterations": null,
        "include_message_history": false
      },
      "actions": []
    }
  ],
  "initial_message": "OneHotEncoder ignore unknown error when categories are strings \n#### Description\r\n\r\nThis bug is very specific, but it happens when you set OneHotEncoder to ignore unknown entries.\r\nand your labels are strings. The memory of the arrays is not handled safely and it can lead to a ValueError\r\n\r\nBasically, when you call the transform method it will sets all the unknown strings on your array to OneHotEncoder.categories_[i][0] which is the first category alphabetically sorted given for fit\r\nIf this OneHotEncoder.categories_[i][0] is a long string, and the array that you want to transform has small strings, then it is impossible to fit the whole  OneHotEncoder.categories_[i][0] into the entries of the array we want to transform. So  OneHotEncoder.categories_[i][0]  is truncated and this raise the ValueError.\r\n\r\n\r\n\r\n#### Steps/Code to Reproduce\r\n```\r\n\r\nimport numpy as np\r\nfrom sklearn.preprocessing import OneHotEncoder\r\n\r\n\r\n# It needs to be numpy arrays, the error does not appear \r\n# is you have lists of lists because it gets treated like an array of objects.\r\ntrain  = np.array([ '22','333','4444','11111111' ]).reshape((-1,1))\r\ntest   = np.array([ '55555',  '22' ]).reshape((-1,1))\r\n\r\nohe = OneHotEncoder(dtype=bool,handle_unknown='ignore')\r\n\r\nohe.fit( train )\r\nenc_test = ohe.transform( test )\r\n\r\n```\r\n\r\n\r\n#### Expected Results\r\nHere we should get an sparse matrix 2x4 false everywhere except at (1,1) the '22' that is known\r\n\r\n#### Actual Results\r\n\r\n> ValueError: y contains previously unseen labels: ['111111']\r\n\r\n\r\n#### Versions\r\nSystem:\r\n    python: 2.7.12 (default, Dec  4 2017, 14:50:18)  [GCC 5.4.0 20160609]\r\n   machine: Linux-4.4.0-138-generic-x86_64-with-Ubuntu-16.04-xenial\r\nexecutable: /usr/bin/python\r\n\r\nBLAS:\r\n    macros: HAVE_CBLAS=None\r\ncblas_libs: openblas, openblas\r\n  lib_dirs: /usr/lib\r\n\r\nPython deps:\r\n    Cython: 0.25.2\r\n     scipy: 0.18.1\r\nsetuptools: 36.7.0\r\n       pip: 9.0.1\r\n     numpy: 1.15.2\r\n    pandas: 0.19.1\r\n   sklearn: 0.21.dev0\r\n\r\n\r\n\r\n#### Comments\r\n\r\nI already implemented a fix for this issue, where I check the size of the elements in the array before, and I cast them into objects if necessary.\n"
}