{
  "info": {
    "duration": 181.44386458396912,
    "submission": "",
    "total_cost": 0.092121,
    "instance_id": "scikit-learn__scikit-learn-14092",
    "evaluation_name": "run_on_remaining_250_for_july_4_t_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "To address the issue of overly strict parameter checks causing failures in GridSearch, it's necessary to identify where these checks are performed and how they interact with the GridSearchCV class. The focus should be on validation functions and parameter check methods across different modules, especially those related to estimators like NeighborhoodComponentsAnalysis, base classes, and utilities for parameter validation. Additionally, looking into the GridSearchCV class itself will provide insight into how parameter grids are processed and how errors arise from mismatched types.",
            "search_requests": [
              {
                "query": "parameter validation GridSearchCV",
                "class_names": [
                  "NeighborhoodComponentsAnalysis",
                  "GridSearchCV"
                ],
                "code_snippet": null,
                "file_pattern": "**/sklearn/**/*.py",
                "function_names": [
                  "_validate_params",
                  "fit",
                  "_run_search"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 3074,
                "span_id": "GridSearchCV",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 0,
                "tokens": 25,
                "span_id": "GridSearchCV._run_search",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 5,
                "tokens": 1118,
                "span_id": "BaseSearchCV.fit",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 8,
                "tokens": 41,
                "span_id": "RandomizedSearchCV._run_search",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 54,
                "tokens": 291,
                "span_id": "BaseSearchCV._run_search",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 2,
                "tokens": 849,
                "span_id": "NeighborhoodComponentsAnalysis._validate_params",
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "rank": 19,
                "tokens": 1233,
                "span_id": "NeighborhoodComponentsAnalysis",
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "rank": 19,
                "tokens": 437,
                "span_id": "NeighborhoodComponentsAnalysis.fit",
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "rank": 29,
                "tokens": 425,
                "span_id": "NeighborhoodComponentsAnalysis._initialize",
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "rank": 29,
                "tokens": 70,
                "span_id": "NeighborhoodComponentsAnalysis._callback",
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "rank": 7,
                "tokens": 1124,
                "span_id": "GraphicalLassoCV.fit",
                "file_path": "sklearn/covariance/graph_lasso_.py"
              },
              {
                "rank": 16,
                "tokens": 1501,
                "span_id": "LinearModelCV.fit",
                "file_path": "sklearn/linear_model/coordinate_descent.py"
              },
              {
                "rank": 116,
                "tokens": 934,
                "span_id": "ElasticNet.fit",
                "file_path": "sklearn/linear_model/coordinate_descent.py"
              },
              {
                "rank": 23,
                "tokens": 371,
                "span_id": "BaseSGD._validate_params",
                "file_path": "sklearn/linear_model/stochastic_gradient.py"
              },
              {
                "rank": 31,
                "tokens": 707,
                "span_id": "LarsCV.fit",
                "file_path": "sklearn/linear_model/least_angle.py"
              },
              {
                "rank": 37,
                "tokens": 2558,
                "span_id": "LogisticRegressionCV.fit",
                "file_path": "sklearn/linear_model/logistic.py"
              },
              {
                "rank": 117,
                "tokens": 189,
                "span_id": "AdditiveChi2Sampler.fit",
                "file_path": "sklearn/kernel_approximation.py"
              },
              {
                "rank": 56,
                "tokens": 419,
                "span_id": "_BaseRidgeCV.fit",
                "file_path": "sklearn/linear_model/ridge.py"
              },
              {
                "rank": 67,
                "tokens": 827,
                "span_id": "_RidgeGCV.fit",
                "file_path": "sklearn/linear_model/ridge.py"
              },
              {
                "rank": 85,
                "tokens": 115,
                "span_id": "TSNE.fit",
                "file_path": "sklearn/manifold/t_sne.py"
              },
              {
                "rank": 80,
                "tokens": 64,
                "span_id": "VectorizerMixin._validate_params",
                "file_path": "sklearn/feature_extraction/text.py"
              },
              {
                "rank": 106,
                "tokens": 264,
                "span_id": "KernelDensity.fit",
                "file_path": "sklearn/neighbors/kde.py"
              },
              {
                "rank": 95,
                "tokens": 1659,
                "span_id": "RANSACRegressor.fit",
                "file_path": "sklearn/linear_model/ransac.py"
              },
              {
                "rank": 118,
                "tokens": 945,
                "span_id": "BayesianRidge.fit",
                "file_path": "sklearn/linear_model/bayes.py"
              },
              {
                "rank": 105,
                "tokens": 295,
                "span_id": "SpectralEmbedding.fit",
                "file_path": "sklearn/manifold/spectral_embedding_.py"
              },
              {
                "rank": 121,
                "tokens": 723,
                "span_id": "RFECV.fit",
                "file_path": "sklearn/feature_selection/rfe.py"
              }
            ],
            "search_requests": [
              {
                "query": "parameter validation GridSearchCV",
                "class_names": [
                  "NeighborhoodComponentsAnalysis",
                  "GridSearchCV"
                ],
                "code_snippet": null,
                "file_pattern": "**/sklearn/**/*.py",
                "function_names": [
                  "_validate_params",
                  "fit",
                  "_run_search"
                ]
              }
            ]
          },
          "input_tokens": 4301,
          "output_tokens": 204,
          "retry_message": null,
          "completion_cost": 0.015962999999999998
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 3074,
            "span_id": "GridSearchCV",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 0,
            "tokens": 25,
            "span_id": "GridSearchCV._run_search",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 2,
            "tokens": 849,
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py"
          },
          {
            "rank": 5,
            "tokens": 1118,
            "span_id": "BaseSearchCV.fit",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 7,
            "tokens": 1124,
            "span_id": "GraphicalLassoCV.fit",
            "file_path": "sklearn/covariance/graph_lasso_.py"
          },
          {
            "rank": 8,
            "tokens": 41,
            "span_id": "RandomizedSearchCV._run_search",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 16,
            "tokens": 1501,
            "span_id": "LinearModelCV.fit",
            "file_path": "sklearn/linear_model/coordinate_descent.py"
          },
          {
            "rank": 19,
            "tokens": 1233,
            "span_id": "NeighborhoodComponentsAnalysis",
            "file_path": "sklearn/neighbors/nca.py"
          },
          {
            "rank": 19,
            "tokens": 437,
            "span_id": "NeighborhoodComponentsAnalysis.fit",
            "file_path": "sklearn/neighbors/nca.py"
          },
          {
            "rank": 23,
            "tokens": 371,
            "span_id": "BaseSGD._validate_params",
            "file_path": "sklearn/linear_model/stochastic_gradient.py"
          },
          {
            "rank": 29,
            "tokens": 425,
            "span_id": "NeighborhoodComponentsAnalysis._initialize",
            "file_path": "sklearn/neighbors/nca.py"
          },
          {
            "rank": 29,
            "tokens": 70,
            "span_id": "NeighborhoodComponentsAnalysis._callback",
            "file_path": "sklearn/neighbors/nca.py"
          },
          {
            "rank": 31,
            "tokens": 707,
            "span_id": "LarsCV.fit",
            "file_path": "sklearn/linear_model/least_angle.py"
          },
          {
            "rank": 37,
            "tokens": 2558,
            "span_id": "LogisticRegressionCV.fit",
            "file_path": "sklearn/linear_model/logistic.py"
          },
          {
            "rank": 54,
            "tokens": 291,
            "span_id": "BaseSearchCV._run_search",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 56,
            "tokens": 419,
            "span_id": "_BaseRidgeCV.fit",
            "file_path": "sklearn/linear_model/ridge.py"
          },
          {
            "rank": 67,
            "tokens": 827,
            "span_id": "_RidgeGCV.fit",
            "file_path": "sklearn/linear_model/ridge.py"
          },
          {
            "rank": 80,
            "tokens": 64,
            "span_id": "VectorizerMixin._validate_params",
            "file_path": "sklearn/feature_extraction/text.py"
          },
          {
            "rank": 85,
            "tokens": 115,
            "span_id": "TSNE.fit",
            "file_path": "sklearn/manifold/t_sne.py"
          },
          {
            "rank": 95,
            "tokens": 1659,
            "span_id": "RANSACRegressor.fit",
            "file_path": "sklearn/linear_model/ransac.py"
          },
          {
            "rank": 105,
            "tokens": 295,
            "span_id": "SpectralEmbedding.fit",
            "file_path": "sklearn/manifold/spectral_embedding_.py"
          },
          {
            "rank": 106,
            "tokens": 264,
            "span_id": "KernelDensity.fit",
            "file_path": "sklearn/neighbors/kde.py"
          },
          {
            "rank": 116,
            "tokens": 934,
            "span_id": "ElasticNet.fit",
            "file_path": "sklearn/linear_model/coordinate_descent.py"
          },
          {
            "rank": 117,
            "tokens": 189,
            "span_id": "AdditiveChi2Sampler.fit",
            "file_path": "sklearn/kernel_approximation.py"
          },
          {
            "rank": 118,
            "tokens": 945,
            "span_id": "BayesianRidge.fit",
            "file_path": "sklearn/linear_model/bayes.py"
          },
          {
            "rank": 121,
            "tokens": 723,
            "span_id": "RFECV.fit",
            "file_path": "sklearn/feature_selection/rfe.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue is about parameter checks being too strict in the Neighborhood Components Analysis (NCA) during GridSearch, which causes failures due to the types of parameters. The issue is primarily with the `tol` and `n_components` parameters not accepting certain types like integers for `tol` and numpy int64 for `n_components`. The issue report also suggests a need for a more generalized parameter checking tool that can handle different types and constraints, potentially reducing redundancy and improving flexibility across the codebase, specifically for new or recent estimators.\n\nAnalyzing the provided search results, several relevant files and code spans are found that are directly or indirectly related to the handling and checking of parameters, especially in the context of GridSearchCV and NCA.\n\n- **sklearn/model_selection/_search.py**: Contains the implementation of `GridSearchCV` and its base class `BaseSearchCV`. Key methods like `fit` and `_run_search` are found here, which are crucial for understanding how GridSearchCV operates and how it might interact with parameter grids.\n\n- **sklearn/neighbors/nca.py**: This file contains the `NeighborhoodComponentsAnalysis` class with methods like `fit`, `_validate_params`, and `__init__`, all of which are relevant for understanding how the NCA class initializes, validates, and processes its parameters.\n\n- **Other files** across the codebase (like `sklearn/linear_model/coordinate_descent.py`, `sklearn/linear_model/stochastic_gradient.py`, etc.) provide insights into how other estimators manage and validate their parameters, indicating a potential pattern or inconsistency in parameter checking across different parts of the library.\n\nGiven these findings, the search results provide a mix of direct context (for NCA and GridSearchCV) and broader context (showing parameter handling in other estimators), which collectively are quite relevant to the reported issue and provide a comprehensive view for further analysis or action.",
            "identified_spans": [
              {
                "span_ids": [
                  "BaseSearchCV",
                  "BaseSearchCV._run_search",
                  "BaseSearchCV.fit",
                  "GridSearchCV",
                  "GridSearchCV.__init__",
                  "GridSearchCV._run_search"
                ],
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "span_ids": [
                  "NeighborhoodComponentsAnalysis",
                  "NeighborhoodComponentsAnalysis.__init__",
                  "NeighborhoodComponentsAnalysis.fit",
                  "NeighborhoodComponentsAnalysis._validate_params",
                  "NeighborhoodComponentsAnalysis._initialize"
                ],
                "file_path": "sklearn/neighbors/nca.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 6891,
          "output_tokens": 624,
          "retry_message": null,
          "completion_cost": 0.030033
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": true,
            "relevant": true,
            "scratch_pad": "Both the GridSearchCV class and the NeighborhoodComponentsAnalysis class are relevant to the issue. The GridSearchCV class is responsible for handling parameter grids and fitting the estimator with different parameters. The NeighborhoodComponentsAnalysis class includes parameter validation methods that could be causing the issue due to strict type checks. The _validate_params method in NeighborhoodComponentsAnalysis checks the types of the parameters and raises errors if they don't match expected types, which can cause issues when these parameters are passed through GridSearchCV during hyperparameter tuning. The provided file context includes these classes and methods, indicating that most of the relevant code is present.",
            "search_suggestions": null
          },
          "output": {},
          "input_tokens": 5354,
          "output_tokens": 162,
          "retry_message": null,
          "completion_cost": 0.018492
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py",
            "scratch_pad": "The issue arises due to strict type checking in the `NeighborhoodComponentsAnalysis` class, which can cause GridSearchCV to fail when parameters like `tol` and `n_components` are provided with non-standard types (e.g., 1 as int instead of float, np.int64 instead of int). To resolve this, we should modify the `NeighborhoodComponentsAnalysis._validate_params` method to allow for more flexible type handling.",
            "instructions": "Update the `NeighborhoodComponentsAnalysis._validate_params` method to handle non-standard types more gracefully, allowing ints to be coerced into floats where necessary and ensuring that np.int64 is accepted as a valid int."
          },
          "output": {
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py",
            "instructions": "Update the `NeighborhoodComponentsAnalysis._validate_params` method to handle non-standard types more gracefully, allowing ints to be coerced into floats where necessary and ensuring that np.int64 is accepted as a valid int."
          },
          "input_tokens": 5672,
          "output_tokens": 208,
          "retry_message": null,
          "completion_cost": 0.020136
        }
      ]
    },
    {
      "name": "ClarifyCodeChange",
      "state": {
        "model": "deepseek-coder",
        "span_id": "NeighborhoodComponentsAnalysis._validate_params",
        "end_line": null,
        "file_path": "sklearn/neighbors/nca.py",
        "max_tokens": 1000,
        "start_line": null,
        "temperature": 1.6,
        "instructions": "Update the `NeighborhoodComponentsAnalysis._validate_params` method to handle non-standard types more gracefully, allowing ints to be coerced into floats where necessary and ensuring that np.int64 is accepted as a valid int.\n\nThe code needs to be updated to handle non-standard types like np.int64 and to allow for ints to be coerced into floats where necessary. This involves modifying the checks for `n_components`, `max_iter`, `tol`, and `verbose` to accommodate these changes.",
        "max_iterations": null,
        "include_message_history": false,
        "max_tokens_in_edit_prompt": 500
      },
      "actions": [
        {
          "action": {
            "reject": null,
            "end_line": 323,
            "start_line": 302,
            "scratch_pad": "The code needs to be updated to handle non-standard types like np.int64 and to allow for ints to be coerced into floats where necessary. This involves modifying the checks for `n_components`, `max_iter`, `tol`, and `verbose` to accommodate these changes."
          },
          "output": {
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "end_line": 323,
            "file_path": "sklearn/neighbors/nca.py",
            "start_line": 302,
            "instructions": "Update the `NeighborhoodComponentsAnalysis._validate_params` method to handle non-standard types more gracefully, allowing ints to be coerced into floats where necessary and ensuring that np.int64 is accepted as a valid int.\n\nThe code needs to be updated to handle non-standard types like np.int64 and to allow for ints to be coerced into floats where necessary. This involves modifying the checks for `n_components`, `max_iter`, `tol`, and `verbose` to accommodate these changes."
          },
          "input_tokens": 1959,
          "output_tokens": 108,
          "retry_message": null,
          "completion_cost": 0.007497
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "NeighborhoodComponentsAnalysis._validate_params",
        "end_line": 323,
        "file_path": "sklearn/neighbors/nca.py",
        "max_tokens": 1000,
        "start_line": 302,
        "temperature": 1.6,
        "instructions": "Update the `NeighborhoodComponentsAnalysis._validate_params` method to handle non-standard types more gracefully, allowing ints to be coerced into floats where necessary and ensuring that np.int64 is accepted as a valid int.\n\nThe code needs to be updated to handle non-standard types like np.int64 and to allow for ints to be coerced into floats where necessary. This involves modifying the checks for `n_components`, `max_iter`, `tol`, and `verbose` to accommodate these changes.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "```json\n{\n  \"replace\": \"check_scalar(self.n_components, 'n_components', int, 1, True)\n\nif self.n_components is not None and self.n_components > X.shape[1]:\n    raise ValueError('The preferred dimensionality of the '\n                     'projected space `n_components` ({}) cannot '\n                     'be greater than the given data '\n                     'dimensionality ({})!'\n                     .format(self.n_components, X.shape[1]))\n\n# If warm_start is enabled, check that the inputs are consistent\ncheck_scalar(self.warm_start, 'warm_start', bool)\nif self.warm_start and hasattr(self, 'components_'):\n    if self.components_.shape[1] != X.shape[1]:\n        raise ValueError('The new inputs dimensionality ({}) does not '\n                         'match the input dimensionality of the '\n                         'previously learned transformation ({}).'\n                         .format(X.shape[1],\n                                 self.components_.shape[1]))\n\ncheck_scalar(self.max_iter, 'max_iter', int, 1)\ncheck_scalar(self.tol, 'tol', float, 0.)\ncheck_scalar(self.verbose, 'verbose', int, 0)\"\n}\n```"
          },
          "output": null,
          "input_tokens": 11573,
          "output_tokens": 298,
          "retry_message": "You did not provide any code in the replace tag. If you want to reject the instructions, use the reject function.",
          "completion_cost": 0.039189
        },
        {
          "action": {
            "content": "```json\n{\n  \"reject\": \"The provided context does not include the definition or usage of the `check_scalar` function, which is crucial for modifying the parameter checking behavior as instructed.\"\n}\n```"
          },
          "output": null,
          "input_tokens": 11902,
          "output_tokens": 45,
          "retry_message": "You did not provide any code in the replace tag. If you want to reject the instructions, use the reject function.",
          "completion_cost": 0.036381000000000004
        },
        {
          "action": {
            "content": "```json\n{\n  \"replace\": \"check_scalar(self.n_components, 'n_components', int, 1, True)\n\nif self.n_components is not None and self.n_components > X.shape[1]:\n    raise ValueError('The preferred dimensionality of the '\n                     'projected space `n_components` ({}) cannot '\n                     'be greater than the given data '\n                     'dimensionality ({})!'\n                     .format(self.n_components, X.shape[1]))\n\n# If warm_start is enabled, check that the inputs are consistent\ncheck_scalar(self.warm_start, 'warm_start', bool)\nif self.warm_start and hasattr(self, 'components_'):\n    if self.components_.shape[1] != X.shape[1]:\n        raise ValueError('The new inputs dimensionality ({}) does not '\n                         'match the input dimensionality of the '\n                         'previously learned transformation ({}).'\n                         .format(X.shape[1],\n                                 self.components_.shape[1]))\n\ncheck_scalar(self.max_iter, 'max_iter', int, 1)\ncheck_scalar(self.tol, 'tol', float, 0.)\ncheck_scalar(self.verbose, 'verbose', int, 0)\"\n}\n```"
          },
          "output": null,
          "input_tokens": 11978,
          "output_tokens": 298,
          "retry_message": "You did not provide any code in the replace tag. If you want to reject the instructions, use the reject function.",
          "completion_cost": 0.040404
        }
      ]
    }
  ],
  "initial_message": "NCA fails in GridSearch due to too strict parameter checks\nNCA checks its parameters to have a specific type, which can easily fail in a GridSearch due to how param grid is made.\r\n\r\nHere is an example:\r\n```python\r\nimport numpy as np\r\n\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.model_selection import GridSearchCV\r\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\n\r\nX = np.random.random_sample((100, 10))\r\ny = np.random.randint(2, size=100)\r\n\r\nnca = NeighborhoodComponentsAnalysis()\r\nknn = KNeighborsClassifier()\r\n\r\npipe = Pipeline([('nca', nca),\r\n                 ('knn', knn)])\r\n                \r\nparams = {'nca__tol': [0.1, 0.5, 1],\r\n          'nca__n_components': np.arange(1, 10)}\r\n          \r\ngs = GridSearchCV(estimator=pipe, param_grid=params, error_score='raise')\r\ngs.fit(X,y)\r\n```\r\n\r\nThe issue is that for `tol`: 1 is not a float, and for  `n_components`: np.int64 is not int\r\n\r\nBefore proposing a fix for this specific situation, I'd like to have your general opinion about parameter checking.  \r\nI like this idea of common parameter checking tool introduced with the NCA PR. What do you think about extending it across the code-base (or at least for new or recent estimators) ?\r\n\r\nCurrently parameter checking is not always done or often partially done, and is quite redundant. For instance, here is the input validation of lda:\r\n```python\r\ndef _check_params(self):\r\n        \"\"\"Check model parameters.\"\"\"\r\n        if self.n_components <= 0:\r\n            raise ValueError(\"Invalid 'n_components' parameter: %r\"\r\n                             % self.n_components)\r\n\r\n        if self.total_samples <= 0:\r\n            raise ValueError(\"Invalid 'total_samples' parameter: %r\"\r\n                             % self.total_samples)\r\n\r\n        if self.learning_offset < 0:\r\n            raise ValueError(\"Invalid 'learning_offset' parameter: %r\"\r\n                             % self.learning_offset)\r\n\r\n        if self.learning_method not in (\"batch\", \"online\"):\r\n            raise ValueError(\"Invalid 'learning_method' parameter: %r\"\r\n                             % self.learning_method)\r\n```\r\nmost params aren't checked and for those who are there's a lot of duplicated code.\r\n\r\nA propose to be upgrade the new tool to be able to check open/closed intervals (currently only closed) and list membership.\r\n\r\nThe api would be something like that:\r\n```\r\ncheck_param(param, name, valid_options)\r\n```\r\nwhere valid_options would be a dict of `type: constraint`. e.g for the `beta_loss` param of `NMF`, it can be either a float or a string in a list, which would give\r\n```\r\nvalid_options = {numbers.Real: None,  # None for no constraint\r\n                 str: ['frobenius', 'kullback-leibler', 'itakura-saito']}\r\n```\r\nSometimes a parameter can only be positive or within a given interval, e.g. `l1_ratio` of `LogisticRegression` must be between 0 and 1, which would give\r\n```\r\nvalid_options = {numbers.Real: Interval(0, 1, closed='both')}\r\n```\r\npositivity of e.g. `max_iter` would be `numbers.Integral: Interval(left=1)`.\n"
}