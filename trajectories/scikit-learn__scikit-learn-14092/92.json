{
  "info": {
    "duration": 285.25876545906067,
    "submission": "",
    "total_cost": 0.137322,
    "instance_id": "scikit-learn__scikit-learn-14092",
    "evaluation_name": "run_on_remaining_250_for_july_4_t_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue describes a problem with parameter checks in the NeighborhoodComponentsAnalysis (NCA) class during GridSearch. The checks are too strict, causing failures due to mismatched types (e.g., np.int64 vs int, and 1 vs float). This issue is likely linked to how parameter grids are constructed and how NCA validates its parameters. To identify relevant code, focus on files related to GridSearchCV, NCA, and parameter validation utilities. Specifically, look for implementations of parameter validation in NCA and any common utilities used for parameter checking across different estimators.",
            "search_requests": [
              {
                "query": "NeighborhoodComponentsAnalysis parameter validation",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/neighbors/nca.py",
                "function_names": [
                  "_validate_params",
                  "fit"
                ]
              },
              {
                "query": "GridSearchCV parameter grid handling",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/model_selection/_search.py",
                "function_names": [
                  "_check_param_grid",
                  "_run_search"
                ]
              },
              {
                "query": "common parameter checking tool",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/utils/estimator_checks.py",
                "function_names": [
                  "set_checking_parameters"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 849,
                "span_id": "NeighborhoodComponentsAnalysis._validate_params",
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "rank": 3,
                "tokens": 437,
                "span_id": "NeighborhoodComponentsAnalysis.fit",
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "rank": 0,
                "tokens": 148,
                "span_id": "_check_param_grid",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 1,
                "tokens": 25,
                "span_id": "GridSearchCV._run_search",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 7,
                "tokens": 41,
                "span_id": "RandomizedSearchCV._run_search",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 18,
                "tokens": 291,
                "span_id": "BaseSearchCV._run_search",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 0,
                "tokens": 660,
                "span_id": "set_checking_parameters",
                "file_path": "sklearn/utils/estimator_checks.py"
              }
            ],
            "search_requests": [
              {
                "query": "NeighborhoodComponentsAnalysis parameter validation",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/neighbors/nca.py",
                "function_names": [
                  "_validate_params",
                  "fit"
                ]
              },
              {
                "query": "GridSearchCV parameter grid handling",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/model_selection/_search.py",
                "function_names": [
                  "_check_param_grid",
                  "_run_search"
                ]
              },
              {
                "query": "common parameter checking tool",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/utils/estimator_checks.py",
                "function_names": [
                  "set_checking_parameters"
                ]
              }
            ]
          },
          "input_tokens": 4301,
          "output_tokens": 312,
          "retry_message": null,
          "completion_cost": 0.017583
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 849,
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py"
          },
          {
            "rank": 3,
            "tokens": 437,
            "span_id": "NeighborhoodComponentsAnalysis.fit",
            "file_path": "sklearn/neighbors/nca.py"
          },
          {
            "rank": 0,
            "tokens": 148,
            "span_id": "_check_param_grid",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 1,
            "tokens": 25,
            "span_id": "GridSearchCV._run_search",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 7,
            "tokens": 41,
            "span_id": "RandomizedSearchCV._run_search",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 18,
            "tokens": 291,
            "span_id": "BaseSearchCV._run_search",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 0,
            "tokens": 660,
            "span_id": "set_checking_parameters",
            "file_path": "sklearn/utils/estimator_checks.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue is about the strict parameter checks in NeighborhoodComponentsAnalysis (NCA) leading to failures in GridSearch due to the way parameter grids are constructed. Specifically, the issue mentions that 'tol' should be a float and 'n_components' should be an integer, but these strict checks can cause GridSearch to fail because of how parameter grids are often created with varied data types. The provided search results show the parameter validation in NCA's _validate_params method, which includes checks for 'n_components' and 'tol' parameters. Additionally, there is a _check_param_grid function in the model_selection module that validates the structure of the parameter grid. These code spans are directly relevant to the reported issue because they involve the parameter checking and grid validation that are central to the problem. The proposed solution to extend a common parameter checking tool across the codebase, at least for new or recent estimators, and to upgrade the tool to handle more complex constraints, also seems relevant. The existing parameter checking in NCA could potentially be refactored or expanded upon with a more flexible tool, as suggested in the issue.",
            "identified_spans": [
              {
                "span_ids": [
                  "NeighborhoodComponentsAnalysis._validate_params"
                ],
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "span_ids": [
                  "_check_param_grid"
                ],
                "file_path": "sklearn/model_selection/_search.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 5150,
          "output_tokens": 352,
          "retry_message": null,
          "completion_cost": 0.02073
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The provided file context includes the relevant code related to the NeighborhoodComponentsAnalysis class and its parameter validation checks, as well as the GridSearchCV class with its parameter grid checks. In the NeighborhoodComponentsAnalysis class, the method `_validate_params` is responsible for validating parameters including n_components, max_iter, tol, and others. This method uses `check_scalar` extensively, which likely enforces strict type checking. The GridSearchCV class uses `_check_param_grid` to ensure that the parameter grid is correctly structured, but it does not handle type compatibility with the estimator's parameter checks. Given this context, it's clear that the specific issue of strict type checks in NCA is touched upon, but the broader proposal of a common parameter checking tool across the codebase is not addressed here. There is room to explore more about how such a tool could be integrated.",
            "search_suggestions": "Look for common utilities or base classes where parameter checking functions are implemented or could be integrated. Specifically, identify any existing framework or utility that could serve as a basis for a robust parameter checking system applicable across different estimators. Additionally, review recent and new estimators to understand how parameter checking is currently implemented, if there is a variety of approaches that could benefit from standardization, or if there are consistent gaps in current parameter validation practices that a new tool could address."
          },
          "output": {
            "message": "Look for common utilities or base classes where parameter checking functions are implemented or could be integrated. Specifically, identify any existing framework or utility that could serve as a basis for a robust parameter checking system applicable across different estimators. Additionally, review recent and new estimators to understand how parameter checking is currently implemented, if there is a variety of approaches that could benefit from standardization, or if there are consistent gaps in current parameter validation practices that a new tool could address."
          },
          "input_tokens": 3297,
          "output_tokens": 314,
          "retry_message": null,
          "completion_cost": 0.014601
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Look for common utilities or base classes where parameter checking functions are implemented or could be integrated. Specifically, identify any existing framework or utility that could serve as a basis for a robust parameter checking system applicable across different estimators. Additionally, review recent and new estimators to understand how parameter checking is currently implemented, if there is a variety of approaches that could benefit from standardization, or if there are consistent gaps in current parameter validation practices that a new tool could address.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The provided context suggests that parameter validation in NeighborhoodComponentsAnalysis (NCA) is handled through a customized method `_validate_params`. This method incorporates various checks specific to NCA's parameters. For example, it checks if `n_components` is an integer and greater than 1, validates that `max_iter` and `tol` are numeric, and ensures `init` matches specific conditions if it's a numpy array. This custom validation approach indicates a need for a more robust and standardized utility to handle parameter checks that can be applied across different estimators. GridSearchCV's `_check_param_grid` function enforces basic checks on the structure of the parameter grid but does not delve into specific data type or value constraints applicable to each parameter across different estimators. Given the variety of parameter types and conditions across estimators in the scikit-learn library, a new, versatile parameter validation tool would be beneficial. This tool could standardize how parameters are checked according to their specific constraints (e.g., type, range, allowed values) and be applied consistently to new and existing estimators, potentially integrating with or enhancing existing utilities like in `sklearn.utils.validation`.",
            "search_requests": [
              {
                "query": "general parameter validation utilities",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/utils/validation.py",
                "function_names": [
                  "check_array",
                  "check_scalar"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 2301,
                "span_id": "check_array",
                "file_path": "sklearn/utils/validation.py"
              }
            ],
            "search_requests": [
              {
                "query": "general parameter validation utilities",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "sklearn/utils/validation.py",
                "function_names": [
                  "check_array",
                  "check_scalar"
                ]
              }
            ]
          },
          "input_tokens": 6293,
          "output_tokens": 352,
          "retry_message": null,
          "completion_cost": 0.024159
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 2301,
            "span_id": "check_array",
            "file_path": "sklearn/utils/validation.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "In order to address the reported issue regarding too strict parameter checks in NeighborhoodComponentsAnalysis (NCA) during GridSearch, it is crucial to identify the code spans that handle parameter validation and grid search functionality. The search results provide relevant code spans in two files: `nca.py` and `_search.py`. The `nca.py` file includes the `NeighborhoodComponentsAnalysis` class with its `__init__` method and the `_validate_params` method, which specifically address parameter validation for NCA. The `_search.py` file contains the `GridSearchCV` class with its `__init__` method and a private method `_check_param_grid` that is relevant for validating the parameter grid used in grid search operations. Additionally, the `_search.py` file includes utility functions for parameter grid checking which are directly related to the issue described. Therefore, these code spans are highly relevant to the reported issue and should be inspected and potentially modified to address the stringent parameter type checks.",
            "identified_spans": [
              {
                "span_ids": [
                  "NeighborhoodComponentsAnalysis",
                  "NeighborhoodComponentsAnalysis.__init__",
                  "NeighborhoodComponentsAnalysis._validate_params"
                ],
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "span_ids": [
                  "GridSearchCV",
                  "GridSearchCV.__init__",
                  "_check_param_grid"
                ],
                "file_path": "sklearn/model_selection/_search.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 6447,
          "output_tokens": 368,
          "retry_message": null,
          "completion_cost": 0.024861
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": true,
            "relevant": true,
            "scratch_pad": "The provided context suggests that parameter validation in NeighborhoodComponentsAnalysis (NCA) is handled through a customized method `_validate_params`. This method incorporates various checks specific to NCA's parameters. For example, it checks if `n_components` is an integer and greater than 1, validates that `max_iter` and `tol` are numeric, and ensures `init` matches specific conditions if it's a numpy array. This custom validation approach indicates a need for a more robust and standardized utility to handle parameter checks that can be applied across different estimators. GridSearchCV's `_check_param_grid` function enforces basic checks on the structure of the parameter grid but does not delve into specific data type or value constraints applicable to each parameter across different estimators. Given the variety of parameter types and conditions across estimators in the scikit-learn library, a new, versatile parameter validation tool would be beneficial. This tool could standardize how parameters are checked according to their specific constraints (e.g., type, range, allowed values) and be applied consistently to new and existing estimators, potentially integrating with or enhancing existing utilities like in `sklearn.utils.validation`.",
            "search_suggestions": null
          },
          "output": {},
          "input_tokens": 3428,
          "output_tokens": 282,
          "retry_message": null,
          "completion_cost": 0.014513999999999999
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py",
            "scratch_pad": "The issue described pertains to type checking in the NeighborhoodComponentsAnalysis class during GridSearchCV operations. Specifically, the type checking is too strict, causing the grid search to fail when parameter values do not strictly adhere to the expected types, such as int for n_components and float for tol. To resolve this, we should adjust the type checking in the _validate_params method to be more flexible, allowing for numpy integer and float types. This change should be made in the sklearn/neighbors/nca.py file.",
            "instructions": "Modify the _validate_params method in the NeighborhoodComponentsAnalysis class to allow numpy integer and float types for the parameters 'n_components' and 'tol'."
          },
          "output": {
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py",
            "instructions": "Modify the _validate_params method in the NeighborhoodComponentsAnalysis class to allow numpy integer and float types for the parameters 'n_components' and 'tol'."
          },
          "input_tokens": 3531,
          "output_tokens": 205,
          "retry_message": null,
          "completion_cost": 0.013668
        }
      ]
    },
    {
      "name": "ClarifyCodeChange",
      "state": {
        "model": "deepseek-coder",
        "span_id": "NeighborhoodComponentsAnalysis._validate_params",
        "end_line": null,
        "file_path": "sklearn/neighbors/nca.py",
        "max_tokens": 1000,
        "start_line": null,
        "temperature": 1.6,
        "instructions": "Modify the _validate_params method in the NeighborhoodComponentsAnalysis class to allow numpy integer and float types for the parameters 'n_components' and 'tol'.\n\nThe parameters needing modification are 'n_components' and 'tol'. These are validated using the `check_scalar` function. The relevant lines that need to be modified to allow numpy integer and float types are lines 302 and 322.",
        "max_iterations": null,
        "include_message_history": false,
        "max_tokens_in_edit_prompt": 500
      },
      "actions": [
        {
          "action": {
            "reject": null,
            "end_line": 322,
            "start_line": 302,
            "scratch_pad": "The parameters needing modification are 'n_components' and 'tol'. These are validated using the `check_scalar` function. The relevant lines that need to be modified to allow numpy integer and float types are lines 302 and 322."
          },
          "output": {
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "end_line": 322,
            "file_path": "sklearn/neighbors/nca.py",
            "start_line": 302,
            "instructions": "Modify the _validate_params method in the NeighborhoodComponentsAnalysis class to allow numpy integer and float types for the parameters 'n_components' and 'tol'.\n\nThe parameters needing modification are 'n_components' and 'tol'. These are validated using the `check_scalar` function. The relevant lines that need to be modified to allow numpy integer and float types are lines 302 and 322."
          },
          "input_tokens": 1942,
          "output_tokens": 92,
          "retry_message": null,
          "completion_cost": 0.007206000000000001
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "NeighborhoodComponentsAnalysis._validate_params",
        "end_line": 322,
        "file_path": "sklearn/neighbors/nca.py",
        "max_tokens": 1000,
        "start_line": 302,
        "temperature": 1.6,
        "instructions": "Modify the _validate_params method in the NeighborhoodComponentsAnalysis class to allow numpy integer and float types for the parameters 'n_components' and 'tol'.\n\nThe parameters needing modification are 'n_components' and 'tol'. These are validated using the `check_scalar` function. The relevant lines that need to be modified to allow numpy integer and float types are lines 302 and 322.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "```json\n{\n  \"replace\": \"check_scalar(self.n_components, 'n_components', (int, np.integer), 1)\\n\\n            if self.n_components > X.shape[1]:\\n                raise ValueError('The preferred dimensionality of the '\\n                                 'projected space `n_components` ({}) cannot '\\n                                 'be greater than the given data '\\n                                 'dimensionality ({})!'\\n                                 .format(self.n_components, X.shape[1]))\\n\\n        # If warm_start is enabled, check that the inputs are consistent\\n        check_scalar(self.warm_start, 'warm_start', bool)\\n        if self.warm_start and hasattr(self, 'components_'):\\n            if self.components_.shape[1] != X.shape[1]:\\n                raise ValueError('The new inputs dimensionality ({}) does not '\\n                                 'match the input dimensionality of the '\\n                                 'previously learned transformation ({}).'\\n                                 .format(X.shape[1],\\n                                         self.components_.shape[1]))\\n\\n        check_scalar(self.max_iter, 'max_iter', int, 1)\\n        check_scalar(self.tol, 'tol', (float, np.floating), 0.)\"\n}\n```"
          },
          "output": null,
          "input_tokens": 8604,
          "output_tokens": 297,
          "retry_message": "You did not provide any code in the replace tag. If you want to reject the instructions, use the reject function.",
          "completion_cost": 0.030267000000000002
        },
        {
          "action": {
            "content": "```json\n{\n  \"reject\": \"The instructions ask to modify the `_validate_params` method to allow numpy integer and float types for the parameters 'n_components' and 'tol'. However, the provided context and search snippet do not include the necessary details to make these specific modifications. The context does not show how `n_components` and `tol` are defined or used, nor does it provide the `check_scalar` function's implementation to adjust typing. Therefore, without more comprehensive context or a different approach to tackle the task, fulfilling the request is unfeasible.\"\n}\n```"
          },
          "output": null,
          "input_tokens": 8932,
          "output_tokens": 127,
          "retry_message": "You did not provide any code in the replace tag. If you want to reject the instructions, use the reject function.",
          "completion_cost": 0.028701
        },
        {
          "action": {
            "content": "```json\n{\n  \"replace\": \"check_scalar(self.n_components, 'n_components', (int, np.integer), 1)\\n\\n            if self.n_components > X.shape[1]:\\n                raise ValueError('The preferred dimensionality of the '\\n                                 'projected space `n_components` ({}) cannot '\\n                                 'be greater than the given data '\\n                                 'dimensionality ({})!'\\n                                 .format(self.n_components, X.shape[1]))\\n\\n        # If warm_start is enabled, check that the inputs are consistent\\n        check_scalar(self.warm_start, 'warm_start', bool)\\n        if self.warm_start and hasattr(self, 'components_'):\\n            if self.components_.shape[1] != X.shape[1]:\\n                raise ValueError('The new inputs dimensionality ({}) does not '\\n                                 'match the input dimensionality of the '\\n                                 'previously learned transformation ({}).'\\n                                 .format(X.shape[1],\\n                                         self.components_.shape[1]))\\n\\n        check_scalar(self.max_iter, 'max_iter', int, 1)\\n        check_scalar(self.tol, 'tol', (float, np.floating), 0.)\"\n}\n```"
          },
          "output": null,
          "input_tokens": 9090,
          "output_tokens": 297,
          "retry_message": "You did not provide any code in the replace tag. If you want to reject the instructions, use the reject function.",
          "completion_cost": 0.031724999999999996
        }
      ]
    }
  ],
  "initial_message": "NCA fails in GridSearch due to too strict parameter checks\nNCA checks its parameters to have a specific type, which can easily fail in a GridSearch due to how param grid is made.\r\n\r\nHere is an example:\r\n```python\r\nimport numpy as np\r\n\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.model_selection import GridSearchCV\r\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\n\r\nX = np.random.random_sample((100, 10))\r\ny = np.random.randint(2, size=100)\r\n\r\nnca = NeighborhoodComponentsAnalysis()\r\nknn = KNeighborsClassifier()\r\n\r\npipe = Pipeline([('nca', nca),\r\n                 ('knn', knn)])\r\n                \r\nparams = {'nca__tol': [0.1, 0.5, 1],\r\n          'nca__n_components': np.arange(1, 10)}\r\n          \r\ngs = GridSearchCV(estimator=pipe, param_grid=params, error_score='raise')\r\ngs.fit(X,y)\r\n```\r\n\r\nThe issue is that for `tol`: 1 is not a float, and for  `n_components`: np.int64 is not int\r\n\r\nBefore proposing a fix for this specific situation, I'd like to have your general opinion about parameter checking.  \r\nI like this idea of common parameter checking tool introduced with the NCA PR. What do you think about extending it across the code-base (or at least for new or recent estimators) ?\r\n\r\nCurrently parameter checking is not always done or often partially done, and is quite redundant. For instance, here is the input validation of lda:\r\n```python\r\ndef _check_params(self):\r\n        \"\"\"Check model parameters.\"\"\"\r\n        if self.n_components <= 0:\r\n            raise ValueError(\"Invalid 'n_components' parameter: %r\"\r\n                             % self.n_components)\r\n\r\n        if self.total_samples <= 0:\r\n            raise ValueError(\"Invalid 'total_samples' parameter: %r\"\r\n                             % self.total_samples)\r\n\r\n        if self.learning_offset < 0:\r\n            raise ValueError(\"Invalid 'learning_offset' parameter: %r\"\r\n                             % self.learning_offset)\r\n\r\n        if self.learning_method not in (\"batch\", \"online\"):\r\n            raise ValueError(\"Invalid 'learning_method' parameter: %r\"\r\n                             % self.learning_method)\r\n```\r\nmost params aren't checked and for those who are there's a lot of duplicated code.\r\n\r\nA propose to be upgrade the new tool to be able to check open/closed intervals (currently only closed) and list membership.\r\n\r\nThe api would be something like that:\r\n```\r\ncheck_param(param, name, valid_options)\r\n```\r\nwhere valid_options would be a dict of `type: constraint`. e.g for the `beta_loss` param of `NMF`, it can be either a float or a string in a list, which would give\r\n```\r\nvalid_options = {numbers.Real: None,  # None for no constraint\r\n                 str: ['frobenius', 'kullback-leibler', 'itakura-saito']}\r\n```\r\nSometimes a parameter can only be positive or within a given interval, e.g. `l1_ratio` of `LogisticRegression` must be between 0 and 1, which would give\r\n```\r\nvalid_options = {numbers.Real: Interval(0, 1, closed='both')}\r\n```\r\npositivity of e.g. `max_iter` would be `numbers.Integral: Interval(left=1)`.\n"
}