{
  "info": {
    "duration": 165.20512437820435,
    "submission": "diff --git a/sklearn/neighbors/nca.py b/sklearn/neighbors/nca.py\nindex 1d278b6e1..c0203a997 100644\n--- a/sklearn/neighbors/nca.py\n+++ b/sklearn/neighbors/nca.py\n@@ -299,7 +299,10 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n-            check_scalar(self.n_components, 'n_components', int, 1)\n+            n_components = self.n_components\n+            if isinstance(self.n_components, np.integer):\n+                n_components = int(self.n_components)\n+            check_scalar(n_components, 'n_components', int, 1)\n \n             if self.n_components > X.shape[1]:\n                 raise ValueError('The preferred dimensionality of the '\n@@ -319,7 +322,12 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n                                          self.components_.shape[1]))\n \n         check_scalar(self.max_iter, 'max_iter', int, 1)\n-        check_scalar(self.tol, 'tol', float, 0.)\n+\n+        tol = self.tol\n+        if isinstance(self.tol, np.floating):\n+            tol = float(self.tol)\n+        check_scalar(tol, 'tol', float, 0.)\n+\n         check_scalar(self.verbose, 'verbose', int, 0)\n \n         if self.callback is not None:\n",
    "total_cost": 0.11429700000000001,
    "instance_id": "scikit-learn__scikit-learn-14092",
    "evaluation_name": "run_on_remaining_250_for_july_4_t_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue revolves around parameter checks in the NeighborhoodComponentsAnalysis (NCA) class, which are too strict and cause failures during GridSearch due to the variability of parameter types. To address this, it's suggested to extend a common parameter checking tool across the codebase, which could include checking for open/closed intervals and list membership. Relevant files to investigate are those related to parameter grid validation in GridSearchCV, parameter validation in NCA, and utility functions for parameter checks. Notably, GridSearchCV and NeighborhoodComponentsAnalysis classes are directly involved. Additionally, estimator checks and validation utilities might provide insight into how parameter checks are managed across different estimators.",
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/neighbors/nca.py",
                "function_names": [
                  "_validate_params"
                ]
              },
              {
                "query": null,
                "class_names": [
                  "GridSearchCV"
                ],
                "code_snippet": null,
                "file_pattern": "**/sklearn/model_selection/_search.py",
                "function_names": []
              },
              {
                "query": "parameter checking",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/utils/estimator_checks.py",
                "function_names": []
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 849,
                "span_id": "NeighborhoodComponentsAnalysis._validate_params",
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "rank": 0,
                "tokens": 3074,
                "span_id": "GridSearchCV",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 0,
                "tokens": 124,
                "span_id": "GridSearchCV.__init__",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 0,
                "tokens": 25,
                "span_id": "GridSearchCV._run_search",
                "file_path": "sklearn/model_selection/_search.py"
              },
              {
                "rank": 0,
                "tokens": 660,
                "span_id": "set_checking_parameters",
                "file_path": "sklearn/utils/estimator_checks.py"
              },
              {
                "rank": 1,
                "tokens": 18,
                "span_id": "is_public_parameter",
                "file_path": "sklearn/utils/estimator_checks.py"
              },
              {
                "rank": 1,
                "tokens": 283,
                "span_id": "check_dict_unchanged",
                "file_path": "sklearn/utils/estimator_checks.py"
              },
              {
                "rank": 1,
                "tokens": 96,
                "span_id": "check_complex_data",
                "file_path": "sklearn/utils/estimator_checks.py"
              },
              {
                "rank": 2,
                "tokens": 403,
                "span_id": "imports",
                "file_path": "sklearn/utils/estimator_checks.py"
              },
              {
                "rank": 3,
                "tokens": 562,
                "span_id": "check_parameters_default_constructible",
                "file_path": "sklearn/utils/estimator_checks.py"
              },
              {
                "rank": 4,
                "tokens": 125,
                "span_id": "check_classifier_data_not_an_array",
                "file_path": "sklearn/utils/estimator_checks.py"
              },
              {
                "rank": 4,
                "tokens": 79,
                "span_id": "check_regressor_data_not_an_array",
                "file_path": "sklearn/utils/estimator_checks.py"
              },
              {
                "rank": 5,
                "tokens": 432,
                "span_id": "check_dont_overwrite_parameters",
                "file_path": "sklearn/utils/estimator_checks.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/neighbors/nca.py",
                "function_names": [
                  "_validate_params"
                ]
              },
              {
                "query": null,
                "class_names": [
                  "GridSearchCV"
                ],
                "code_snippet": null,
                "file_pattern": "**/sklearn/model_selection/_search.py",
                "function_names": []
              },
              {
                "query": "parameter checking",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/utils/estimator_checks.py",
                "function_names": []
              }
            ]
          },
          "input_tokens": 4301,
          "output_tokens": 270,
          "retry_message": null,
          "completion_cost": 0.016953
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 849,
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py"
          },
          {
            "rank": 0,
            "tokens": 3074,
            "span_id": "GridSearchCV",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 0,
            "tokens": 124,
            "span_id": "GridSearchCV.__init__",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 0,
            "tokens": 25,
            "span_id": "GridSearchCV._run_search",
            "file_path": "sklearn/model_selection/_search.py"
          },
          {
            "rank": 0,
            "tokens": 660,
            "span_id": "set_checking_parameters",
            "file_path": "sklearn/utils/estimator_checks.py"
          },
          {
            "rank": 1,
            "tokens": 18,
            "span_id": "is_public_parameter",
            "file_path": "sklearn/utils/estimator_checks.py"
          },
          {
            "rank": 1,
            "tokens": 283,
            "span_id": "check_dict_unchanged",
            "file_path": "sklearn/utils/estimator_checks.py"
          },
          {
            "rank": 1,
            "tokens": 96,
            "span_id": "check_complex_data",
            "file_path": "sklearn/utils/estimator_checks.py"
          },
          {
            "rank": 2,
            "tokens": 403,
            "span_id": "imports",
            "file_path": "sklearn/utils/estimator_checks.py"
          },
          {
            "rank": 3,
            "tokens": 562,
            "span_id": "check_parameters_default_constructible",
            "file_path": "sklearn/utils/estimator_checks.py"
          },
          {
            "rank": 4,
            "tokens": 125,
            "span_id": "check_classifier_data_not_an_array",
            "file_path": "sklearn/utils/estimator_checks.py"
          },
          {
            "rank": 4,
            "tokens": 79,
            "span_id": "check_regressor_data_not_an_array",
            "file_path": "sklearn/utils/estimator_checks.py"
          },
          {
            "rank": 5,
            "tokens": 432,
            "span_id": "check_dont_overwrite_parameters",
            "file_path": "sklearn/utils/estimator_checks.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue pertains to the failure of Neighborhood Components Analysis (NCA) within GridSearch due to strict parameter checks. Specifically, the issue involves the parameter types expected by NCA not aligning with those used in GridSearch, such as integer types for 'n_components' and float types for 'tol' not being handled properly. The search results show relevant code sections within `nca.py` and `_search.py` that validate parameters and initialize GridSearchCV, respectively. These sections are crucial as they involve parameter validation in NCA (`NeighborhoodComponentsAnalysis._validate_params`) and the handling of parameter grids in GridSearch (`GridSearchCV.__init__` and `GridSearchCV._run_search`). Additionally, there are sections in `estimator_checks.py` that set checking parameters and check for complex data, which might be indirectly relevant but are generally related to parameter handling across the codebase. The identified code spans directly address the validation and handling of parameters that are central to the reported issue.",
            "identified_spans": [
              {
                "span_ids": [
                  "NeighborhoodComponentsAnalysis",
                  "NeighborhoodComponentsAnalysis._validate_params"
                ],
                "file_path": "sklearn/neighbors/nca.py"
              },
              {
                "span_ids": [
                  "GridSearchCV",
                  "GridSearchCV.__init__",
                  "GridSearchCV._run_search"
                ],
                "file_path": "sklearn/model_selection/_search.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 5030,
          "output_tokens": 356,
          "retry_message": null,
          "completion_cost": 0.02043
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": true,
            "relevant": true,
            "scratch_pad": "The file context provided includes the relevant code for the NeighborhoodComponentsAnalysis (NCA) class and the GridSearchCV class. The NCA class defines parameter validation specifically for 'n_components', 'warm_start', 'max_iter', 'tol', and 'verbose', which aligns with the parameters mentioned in the issue. The GridSearchCV class initializes with a parameter grid and checks it, which is also relevant to the issue because the problem occurs during GridSearch. The _validate_params method in NCA seems to be the location where the strict parameter checks are implemented. This method checks if parameters are of the expected types and within valid ranges, which may fail during GridSearch due to the inclusion of different types in the parameter grid (e.g., np.int64 for 'n_components' and 1 for 'tol'). It appears that the provided file context directly addresses the issue by showing the exact code that needs to be adjusted to improve parameter checking. Thus, the relevant code has been identified, leading to the conclusion that the file context is complete.",
            "search_suggestions": null
          },
          "output": {},
          "input_tokens": 2997,
          "output_tokens": 258,
          "retry_message": null,
          "completion_cost": 0.012861000000000001
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py",
            "scratch_pad": "The issue arises from the strict type checking in `NeighborhoodComponentsAnalysis` which can cause failures in GridSearch due to the nature of how parameter grids are constructed. Specifically, the `tol` parameter expects a float and `n_components` expects an int, but these can be passed as numpy types which will fail the type check.",
            "instructions": "Update the `_validate_params` method in `NeighborhoodComponentsAnalysis` to allow numpy types for `tol` and `n_components` by converting them to native Python types before performing the type checks."
          },
          "output": {
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "file_path": "sklearn/neighbors/nca.py",
            "instructions": "Update the `_validate_params` method in `NeighborhoodComponentsAnalysis` to allow numpy types for `tol` and `n_components` by converting them to native Python types before performing the type checks."
          },
          "input_tokens": 3201,
          "output_tokens": 176,
          "retry_message": null,
          "completion_cost": 0.012243
        }
      ]
    },
    {
      "name": "ClarifyCodeChange",
      "state": {
        "model": "deepseek-coder",
        "span_id": "NeighborhoodComponentsAnalysis._validate_params",
        "end_line": null,
        "file_path": "sklearn/neighbors/nca.py",
        "max_tokens": 1000,
        "start_line": null,
        "temperature": 1.6,
        "instructions": "Update the `_validate_params` method in `NeighborhoodComponentsAnalysis` to allow numpy types for `tol` and `n_components` by converting them to native Python types before performing the type checks.\n\nThe instructions ask to convert numpy types for `tol` and `n_components` to native Python types before performing the type checks. This involves modifying lines that currently perform these checks to include the conversion step.",
        "max_iterations": null,
        "include_message_history": false,
        "max_tokens_in_edit_prompt": 500
      },
      "actions": [
        {
          "action": {
            "reject": null,
            "end_line": 323,
            "start_line": 301,
            "scratch_pad": "The instructions ask to convert numpy types for `tol` and `n_components` to native Python types before performing the type checks. This involves modifying lines that currently perform these checks to include the conversion step."
          },
          "output": {
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "end_line": 323,
            "file_path": "sklearn/neighbors/nca.py",
            "start_line": 301,
            "instructions": "Update the `_validate_params` method in `NeighborhoodComponentsAnalysis` to allow numpy types for `tol` and `n_components` by converting them to native Python types before performing the type checks.\n\nThe instructions ask to convert numpy types for `tol` and `n_components` to native Python types before performing the type checks. This involves modifying lines that currently perform these checks to include the conversion step."
          },
          "input_tokens": 1953,
          "output_tokens": 88,
          "retry_message": null,
          "completion_cost": 0.0071790000000000005
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "NeighborhoodComponentsAnalysis._validate_params",
        "end_line": 323,
        "file_path": "sklearn/neighbors/nca.py",
        "max_tokens": 1000,
        "start_line": 301,
        "temperature": 1.6,
        "instructions": "Update the `_validate_params` method in `NeighborhoodComponentsAnalysis` to allow numpy types for `tol` and `n_components` by converting them to native Python types before performing the type checks.\n\nThe instructions ask to convert numpy types for `tol` and `n_components` to native Python types before performing the type checks. This involves modifying lines that currently perform these checks to include the conversion step.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "```xml\n<replace>\n        if self.n_components is not None:\n            n_components = self.n_components\n            if isinstance(self.n_components, np.integer):\n                n_components = int(self.n_components)\n            check_scalar(n_components, 'n_components', int, 1)\n\n            if self.n_components > X.shape[1]:\n                raise ValueError('The preferred dimensionality of the '\n                                 'projected space `n_components` ({}) cannot '\n                                 'be greater than the given data '\n                                 'dimensionality ({})!'\n                                 .format(self.n_components, X.shape[1]))\n\n        # If warm_start is enabled, check that the inputs are consistent\n        check_scalar(self.warm_start, 'warm_start', bool)\n        if self.warm_start and hasattr(self, 'components_'):\n            if self.components_.shape[1] != X.shape[1]:\n                raise ValueError('The new inputs dimensionality ({}) does not '\n                                 'match the input dimensionality of the '\n                                 'previously learned transformation ({}).'\n                                 .format(X.shape[1],\n                                         self.components_.shape[1]))\n\n        check_scalar(self.max_iter, 'max_iter', int, 1)\n\n        tol = self.tol\n        if isinstance(self.tol, np.floating):\n            tol = float(self.tol)\n        check_scalar(tol, 'tol', float, 0.)\n\n        check_scalar(self.verbose, 'verbose', int, 0)\n</replace>"
          },
          "output": {
            "diff": "--- sklearn/neighbors/nca.py\n+++ sklearn/neighbors/nca.py\n@@ -299,7 +299,10 @@\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n-            check_scalar(self.n_components, 'n_components', int, 1)\n+            n_components = self.n_components\n+            if isinstance(self.n_components, np.integer):\n+                n_components = int(self.n_components)\n+            check_scalar(n_components, 'n_components', int, 1)\n \n             if self.n_components > X.shape[1]:\n                 raise ValueError('The preferred dimensionality of the '\n@@ -319,7 +322,12 @@\n                                          self.components_.shape[1]))\n \n         check_scalar(self.max_iter, 'max_iter', int, 1)\n-        check_scalar(self.tol, 'tol', float, 0.)\n+\n+        tol = self.tol\n+        if isinstance(self.tol, np.floating):\n+            tol = float(self.tol)\n+        check_scalar(tol, 'tol', float, 0.)\n+\n         check_scalar(self.verbose, 'verbose', int, 0)\n \n         if self.callback is not None:\n",
            "message": "Applied the change to sklearn/neighbors/nca.py.\n\n<scratch_pad>\n```xml\n</scratch_pad>",
            "verification_errors": []
          },
          "input_tokens": 8257,
          "output_tokens": 374,
          "retry_message": null,
          "completion_cost": 0.030381000000000002
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": "--- sklearn/neighbors/nca.py\n+++ sklearn/neighbors/nca.py\n@@ -299,7 +299,10 @@\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n-            check_scalar(self.n_components, 'n_components', int, 1)\n+            n_components = self.n_components\n+            if isinstance(self.n_components, np.integer):\n+                n_components = int(self.n_components)\n+            check_scalar(n_components, 'n_components', int, 1)\n \n             if self.n_components > X.shape[1]:\n                 raise ValueError('The preferred dimensionality of the '\n@@ -319,7 +322,12 @@\n                                          self.components_.shape[1]))\n \n         check_scalar(self.max_iter, 'max_iter', int, 1)\n-        check_scalar(self.tol, 'tol', float, 0.)\n+\n+        tol = self.tol\n+        if isinstance(self.tol, np.floating):\n+            tol = float(self.tol)\n+        check_scalar(tol, 'tol', float, 0.)\n+\n         check_scalar(self.verbose, 'verbose', int, 0)\n \n         if self.callback is not None:\n",
        "model": "deepseek-coder",
        "message": "Applied the change to sklearn/neighbors/nca.py.\n\n<scratch_pad>\n```xml\n</scratch_pad>",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": [],
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "finish",
            "finish": "The changes have been implemented to handle numpy types for the `tol` and `n_components` parameters in `NeighborhoodComponentsAnalysis`, adapting them to native Python types before performing the type checks. This fix should address the issue encountered during GridSearchCV operations.",
            "reject": null,
            "span_id": null,
            "file_path": null,
            "scratch_pad": "The initial change has been applied successfully, allowing numpy types to be accepted for the `tol` and `n_components` parameters by converting them to native Python types before type checks. This should resolve the issue when using GridSearchCV, where the parameters might be passed as numpy types, which previously caused the type checks to fail.",
            "instructions": null
          },
          "output": {
            "message": "The changes have been implemented to handle numpy types for the `tol` and `n_components` parameters in `NeighborhoodComponentsAnalysis`, adapting them to native Python types before performing the type checks. This fix should address the issue encountered during GridSearchCV operations."
          },
          "input_tokens": 3840,
          "output_tokens": 182,
          "retry_message": null,
          "completion_cost": 0.01425
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "model": "gpt-4o",
        "output": {
          "model": "deepseek-coder",
          "temperature": 1.6
        },
        "message": "The changes have been implemented to handle numpy types for the `tol` and `n_components` parameters in `NeighborhoodComponentsAnalysis`, adapting them to native Python types before performing the type checks. This fix should address the issue encountered during GridSearchCV operations.",
        "max_tokens": 1000,
        "temperature": 0.0,
        "max_iterations": null,
        "include_message_history": false
      },
      "actions": []
    }
  ],
  "initial_message": "NCA fails in GridSearch due to too strict parameter checks\nNCA checks its parameters to have a specific type, which can easily fail in a GridSearch due to how param grid is made.\r\n\r\nHere is an example:\r\n```python\r\nimport numpy as np\r\n\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.model_selection import GridSearchCV\r\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\n\r\nX = np.random.random_sample((100, 10))\r\ny = np.random.randint(2, size=100)\r\n\r\nnca = NeighborhoodComponentsAnalysis()\r\nknn = KNeighborsClassifier()\r\n\r\npipe = Pipeline([('nca', nca),\r\n                 ('knn', knn)])\r\n                \r\nparams = {'nca__tol': [0.1, 0.5, 1],\r\n          'nca__n_components': np.arange(1, 10)}\r\n          \r\ngs = GridSearchCV(estimator=pipe, param_grid=params, error_score='raise')\r\ngs.fit(X,y)\r\n```\r\n\r\nThe issue is that for `tol`: 1 is not a float, and for  `n_components`: np.int64 is not int\r\n\r\nBefore proposing a fix for this specific situation, I'd like to have your general opinion about parameter checking.  \r\nI like this idea of common parameter checking tool introduced with the NCA PR. What do you think about extending it across the code-base (or at least for new or recent estimators) ?\r\n\r\nCurrently parameter checking is not always done or often partially done, and is quite redundant. For instance, here is the input validation of lda:\r\n```python\r\ndef _check_params(self):\r\n        \"\"\"Check model parameters.\"\"\"\r\n        if self.n_components <= 0:\r\n            raise ValueError(\"Invalid 'n_components' parameter: %r\"\r\n                             % self.n_components)\r\n\r\n        if self.total_samples <= 0:\r\n            raise ValueError(\"Invalid 'total_samples' parameter: %r\"\r\n                             % self.total_samples)\r\n\r\n        if self.learning_offset < 0:\r\n            raise ValueError(\"Invalid 'learning_offset' parameter: %r\"\r\n                             % self.learning_offset)\r\n\r\n        if self.learning_method not in (\"batch\", \"online\"):\r\n            raise ValueError(\"Invalid 'learning_method' parameter: %r\"\r\n                             % self.learning_method)\r\n```\r\nmost params aren't checked and for those who are there's a lot of duplicated code.\r\n\r\nA propose to be upgrade the new tool to be able to check open/closed intervals (currently only closed) and list membership.\r\n\r\nThe api would be something like that:\r\n```\r\ncheck_param(param, name, valid_options)\r\n```\r\nwhere valid_options would be a dict of `type: constraint`. e.g for the `beta_loss` param of `NMF`, it can be either a float or a string in a list, which would give\r\n```\r\nvalid_options = {numbers.Real: None,  # None for no constraint\r\n                 str: ['frobenius', 'kullback-leibler', 'itakura-saito']}\r\n```\r\nSometimes a parameter can only be positive or within a given interval, e.g. `l1_ratio` of `LogisticRegression` must be between 0 and 1, which would give\r\n```\r\nvalid_options = {numbers.Real: Interval(0, 1, closed='both')}\r\n```\r\npositivity of e.g. `max_iter` would be `numbers.Integral: Interval(left=1)`.\n"
}