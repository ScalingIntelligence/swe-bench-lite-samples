{
  "info": {
    "duration": 171.66109776496887,
    "submission": "diff --git a/seaborn/_stats/regression.py b/seaborn/_stats/regression.py\nindex 7b7ddc8d..2d2a908b 100644\n--- a/seaborn/_stats/regression.py\n+++ b/seaborn/_stats/regression.py\n@@ -23,6 +23,10 @@ class PolyFit(Stat):\n \n         x = data[\"x\"]\n         y = data[\"y\"]\n+        # Filter out rows where x or y are None\n+        valid_data = data[~x.isna() & ~y.isna()]\n+        x = valid_data[\"x\"]\n+        y = valid_data[\"y\"]\n         if x.nunique() <= self.order:\n             # TODO warn?\n             xx = yy = []\n",
    "total_cost": 0.142707,
    "instance_id": "mwaskom__seaborn-3010",
    "evaluation_name": "run_on_remaining_250_for_july_4_t_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue identified is that the PolyFit method in the seaborn package is not handling missing data robustly, leading to a 'LinAlgError' when attempting to fit the data. The traceback indicates that the error originates from the 'polyfit' function in the numpy library, but the immediate context involves the 'seaborn/_stats/regression.py' file, particularly the 'PolyFit' class and its '_fit_predict' method. To address this issue, we need to find the relevant code for the PolyFit class and its interaction with the data to ensure proper handling of missing values. Since the provided files include the 'seaborn/_stats/regression.py' with a 'PolyFit' class, this file is likely central to the solution. Additional search should focus on finding any related utility functions or methods that could assist in improving the robustness of 'PolyFit'.",
            "search_requests": [
              {
                "query": null,
                "class_names": [
                  "PolyFit"
                ],
                "code_snippet": null,
                "file_pattern": "**/seaborn/_stats/**/*.py",
                "function_names": [
                  "_fit_predict"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 120,
                "span_id": "PolyFit._fit_predict",
                "file_path": "seaborn/_stats/regression.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [
                  "PolyFit"
                ],
                "code_snippet": null,
                "file_pattern": "**/seaborn/_stats/**/*.py",
                "function_names": [
                  "_fit_predict"
                ]
              }
            ]
          },
          "input_tokens": 5899,
          "output_tokens": 264,
          "retry_message": null,
          "completion_cost": 0.021657000000000003
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 120,
            "span_id": "PolyFit._fit_predict",
            "file_path": "seaborn/_stats/regression.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue states that 'PolyFit is not robust to missing data'. The user provided a specific example with a dataset containing 'None' values, which leads to a 'LinAlgError'. The traceback indicates that the error originates in the 'PolyFit' class within the 'seaborn/_stats/regression.py' file. Specifically, the error occurs during the call to 'np.polyfit' in the '_fit_predict' method. This method is responsible for fitting the polynomial regression and predicting the values. It is clear that the presence of 'None' values in the 'x' and 'y' data causes the 'LinAlgError' due to the way 'np.polyfit' handles such data. To address this issue, the code should handle missing data before passing it to 'np.polyfit'. This can be done by filtering out or interpolating the missing values. The identified span, PolyFit._fit_predict, is directly relevant to the reported issue as it contains the code where the error occurs.",
            "identified_spans": [
              {
                "span_ids": [
                  "PolyFit._fit_predict"
                ],
                "file_path": "seaborn/_stats/regression.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 2742,
          "output_tokens": 285,
          "retry_message": null,
          "completion_cost": 0.012501000000000002
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The issue identified is that the PolyFit method in the seaborn package is not handling missing data robustly, leading to a 'LinAlgError' when attempting to fit the data. The traceback indicates that the error originates from the 'polyfit' function in the numpy library, but the immediate context involves the 'seaborn/_stats/regression.py' file, particularly the 'PolyFit' class and its '_fit_predict' method. To address this issue, we need to find the relevant code for the PolyFit class and its interaction with the data to ensure proper handling of missing values. Since the provided files include the 'seaborn/_stats/regression.py' with a 'PolyFit' class, this file is likely central to the solution. Additional search should focus on finding any related utility functions or methods that could assist in improving the robustness of 'PolyFit'.",
            "search_suggestions": "Look for additional utility functions or methods in 'seaborn/_core/groupby.py' or other files that interact with the PolyFit class to handle missing data."
          },
          "output": {
            "message": "Look for additional utility functions or methods in 'seaborn/_core/groupby.py' or other files that interact with the PolyFit class to handle missing data."
          },
          "input_tokens": 2741,
          "output_tokens": 257,
          "retry_message": null,
          "completion_cost": 0.012077999999999998
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Look for additional utility functions or methods in 'seaborn/_core/groupby.py' or other files that interact with the PolyFit class to handle missing data.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The provided context from 'seaborn/_stats/regression.py' shows the 'PolyFit' class with its '_fit_predict' method, which is where the handling of the data fitting and prediction occurs. The method currently lacks any specific handling for missing data within the data frames 'x' and 'y'. To enhance the robustness of this method against missing data, we should consider adding a check for missing values and potentially applying a strategy to deal with them, such as interpolation or exclusion with appropriate warnings. We should also examine the '_get_groups' method in 'seaborn/_core/groupby.py' or other related utility functions that might influence how data is processed before it reaches the 'PolyFit' class.",
            "search_requests": [
              {
                "query": "handling missing data",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/seaborn/_core/**/*.py",
                "function_names": [
                  "_get_groups"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 150,
                "span_id": "GroupBy._get_groups",
                "file_path": "seaborn/_core/groupby.py"
              }
            ],
            "search_requests": [
              {
                "query": "handling missing data",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/seaborn/_core/**/*.py",
                "function_names": [
                  "_get_groups"
                ]
              }
            ]
          },
          "input_tokens": 6455,
          "output_tokens": 252,
          "retry_message": null,
          "completion_cost": 0.023145
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 150,
            "span_id": "GroupBy._get_groups",
            "file_path": "seaborn/_core/groupby.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue is about PolyFit not being robust to missing data. The error traceback leads us to the `PolyFit._fit_predict` method in `seaborn/_stats/regression.py`, where the error occurs at the `np.polyfit(x, y, self.order)` call. This indicates that the method should handle missing data before performing the polynomial fitting. The current code does not check for missing data in `x` or `y` before applying `np.polyfit`. To address this issue, we need to modify the `_fit_predict` method to handle missing data. Since the current file context already identifies the relevant part of the `PolyFit` class in `seaborn/_stats/regression.py`, we do not need additional code spans from the search results to solve this issue. However, understanding the `GroupBy` class from `seaborn/_core/groupby.py` might be useful for context on how data grouping is handled before statistical operations like `PolyFit` are applied.",
            "identified_spans": null
          },
          "output": {
            "message": "The search returned 1 results. But unfortunately, I didn\u2019t find any of the search results relevant to the query.\n\nThe reported issue is about PolyFit not being robust to missing data. The error traceback leads us to the `PolyFit._fit_predict` method in `seaborn/_stats/regression.py`, where the error occurs at the `np.polyfit(x, y, self.order)` call. This indicates that the method should handle missing data before performing the polynomial fitting. The current code does not check for missing data in `x` or `y` before applying `np.polyfit`. To address this issue, we need to modify the `_fit_predict` method to handle missing data. Since the current file context already identifies the relevant part of the `PolyFit` class in `seaborn/_stats/regression.py`, we do not need additional code spans from the search results to solve this issue. However, understanding the `GroupBy` class from `seaborn/_core/groupby.py` might be useful for context on how data grouping is handled before statistical operations like `PolyFit` are applied."
          },
          "input_tokens": 3080,
          "output_tokens": 241,
          "retry_message": null,
          "completion_cost": 0.012855
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "The search returned 1 results. But unfortunately, I didn\u2019t find any of the search results relevant to the query.\n\nThe reported issue is about PolyFit not being robust to missing data. The error traceback leads us to the `PolyFit._fit_predict` method in `seaborn/_stats/regression.py`, where the error occurs at the `np.polyfit(x, y, self.order)` call. This indicates that the method should handle missing data before performing the polynomial fitting. The current code does not check for missing data in `x` or `y` before applying `np.polyfit`. To address this issue, we need to modify the `_fit_predict` method to handle missing data. Since the current file context already identifies the relevant part of the `PolyFit` class in `seaborn/_stats/regression.py`, we do not need additional code spans from the search results to solve this issue. However, understanding the `GroupBy` class from `seaborn/_core/groupby.py` might be useful for context on how data grouping is handled before statistical operations like `PolyFit` are applied.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": true,
            "scratch_pad": "The issue identified is that the PolyFit method in the seaborn package is not handling missing data robustly, leading to a 'LinAlgError' when attempting to fit the data. The traceback indicates that the error originates from the 'polyfit' function in the numpy library, but the immediate context involves the 'seaborn/_stats/regression.py' file, particularly the 'PolyFit' class and its '_fit_predict' method. To address this issue, we need to find the relevant code for the PolyFit class and its interaction with the data to ensure proper handling of missing values. Since the provided context already includes the 'seaborn/_stats/regression.py' with a 'PolyFit' class, this file is likely central to the solution. It appears that the current code does not check for missing data in 'x' and 'y' before applying 'np.polyfit'. To make this method robust to missing data, we should modify the '_fit_predict' method to handle missing data appropriately. A straightforward approach could be to remove rows with NaN values in either 'x' or 'y' before proceeding with the polynomial fitting.",
            "search_requests": []
          },
          "output": {
            "message": "The issue identified is that the PolyFit method in the seaborn package is not handling missing data robustly, leading to a 'LinAlgError' when attempting to fit the data. The traceback indicates that the error originates from the 'polyfit' function in the numpy library, but the immediate context involves the 'seaborn/_stats/regression.py' file, particularly the 'PolyFit' class and its '_fit_predict' method. To address this issue, we need to find the relevant code for the PolyFit class and its interaction with the data to ensure proper handling of missing values. Since the provided context already includes the 'seaborn/_stats/regression.py' with a 'PolyFit' class, this file is likely central to the solution. It appears that the current code does not check for missing data in 'x' and 'y' before applying 'np.polyfit'. To make this method robust to missing data, we should modify the '_fit_predict' method to handle missing data appropriately. A straightforward approach could be to remove rows with NaN values in either 'x' or 'y' before proceeding with the polynomial fitting."
          },
          "input_tokens": 6957,
          "output_tokens": 269,
          "retry_message": null,
          "completion_cost": 0.024906
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": "The issue identified is that the PolyFit method in the seaborn package is not handling missing data robustly, leading to a 'LinAlgError' when attempting to fit the data. The traceback indicates that the error originates from the 'polyfit' function in the numpy library, but the immediate context involves the 'seaborn/_stats/regression.py' file, particularly the 'PolyFit' class and its '_fit_predict' method. To address this issue, we need to find the relevant code for the PolyFit class and its interaction with the data to ensure proper handling of missing values. Since the provided context already includes the 'seaborn/_stats/regression.py' with a 'PolyFit' class, this file is likely central to the solution. It appears that the current code does not check for missing data in 'x' and 'y' before applying 'np.polyfit'. To make this method robust to missing data, we should modify the '_fit_predict' method to handle missing data appropriately. A straightforward approach could be to remove rows with NaN values in either 'x' or 'y' before proceeding with the polynomial fitting.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "PolyFit._fit_predict",
            "file_path": "seaborn/_stats/regression.py",
            "scratch_pad": "To address the issue of PolyFit not being robust to missing data, we should modify the `_fit_predict` method in the `PolyFit` class. The current method does not handle missing data, leading to the 'LinAlgError'. The solution is to filter out rows where `x` or `y` are None before calling `np.polyfit`.",
            "instructions": "Modify the `_fit_predict` method to filter out rows where `x` or `y` are None before calling `np.polyfit`."
          },
          "output": {
            "span_id": "PolyFit._fit_predict",
            "end_line": 34,
            "file_path": "seaborn/_stats/regression.py",
            "start_line": 22,
            "instructions": "Modify the `_fit_predict` method to filter out rows where `x` or `y` are None before calling `np.polyfit`."
          },
          "input_tokens": 3086,
          "output_tokens": 184,
          "retry_message": null,
          "completion_cost": 0.012018000000000001
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "PolyFit._fit_predict",
        "end_line": 34,
        "file_path": "seaborn/_stats/regression.py",
        "max_tokens": 1000,
        "start_line": 22,
        "temperature": 1.6,
        "instructions": "Modify the `_fit_predict` method to filter out rows where `x` or `y` are None before calling `np.polyfit`.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "```xml\n<replace>\n    def _fit_predict(self, data):\n\n        x = data[\"x\"]\n        y = data[\"y\"]\n        # Filter out rows where x or y are None\n        valid_data = data[~x.isna() & ~y.isna()]\n        x = valid_data[\"x\"]\n        y = valid_data[\"y\"]\n        if x.nunique() <= self.order:\n            # TODO warn?\n            xx = yy = []\n        else:\n            p = np.polyfit(x, y, self.order)\n            xx = np.linspace(x.min(), x.max(), self.gridsize)\n            yy = np.polyval(p, xx)\n\n        return pd.DataFrame(dict(x=xx, y=yy))\n</replace>"
          },
          "output": {
            "diff": "--- seaborn/_stats/regression.py\n+++ seaborn/_stats/regression.py\n@@ -23,6 +23,10 @@\n \n         x = data[\"x\"]\n         y = data[\"y\"]\n+        # Filter out rows where x or y are None\n+        valid_data = data[~x.isna() & ~y.isna()]\n+        x = valid_data[\"x\"]\n+        y = valid_data[\"y\"]\n         if x.nunique() <= self.order:\n             # TODO warn?\n             xx = yy = []\n",
            "message": "Applied the change to seaborn/_stats/regression.py.\n\n<scratch_pad>\n```xml\n</scratch_pad>",
            "verification_errors": []
          },
          "input_tokens": 2637,
          "output_tokens": 193,
          "retry_message": null,
          "completion_cost": 0.010806
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": "--- seaborn/_stats/regression.py\n+++ seaborn/_stats/regression.py\n@@ -23,6 +23,10 @@\n \n         x = data[\"x\"]\n         y = data[\"y\"]\n+        # Filter out rows where x or y are None\n+        valid_data = data[~x.isna() & ~y.isna()]\n+        x = valid_data[\"x\"]\n+        y = valid_data[\"y\"]\n         if x.nunique() <= self.order:\n             # TODO warn?\n             xx = yy = []\n",
        "model": "deepseek-coder",
        "message": "Applied the change to seaborn/_stats/regression.py.\n\n<scratch_pad>\n```xml\n</scratch_pad>",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": [],
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "finish",
            "finish": "The issue has been resolved by ensuring that missing data is handled appropriately before the polynomial fitting.",
            "reject": null,
            "span_id": null,
            "file_path": null,
            "scratch_pad": "The change has been successfully applied to the `_fit_predict` method in the `PolyFit` class. This modification ensures that rows with `None` values in either `x` or `y` are filtered out before the polynomial fitting. This should prevent the 'LinAlgError' and make the PolyFit method robust to missing data.",
            "instructions": null
          },
          "output": {
            "message": "The issue has been resolved by ensuring that missing data is handled appropriately before the polynomial fitting."
          },
          "input_tokens": 3497,
          "output_tokens": 150,
          "retry_message": null,
          "completion_cost": 0.012741
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "model": "gpt-4o",
        "output": {
          "model": "deepseek-coder",
          "temperature": 1.6
        },
        "message": "The issue has been resolved by ensuring that missing data is handled appropriately before the polynomial fitting.",
        "max_tokens": 1000,
        "temperature": 0.0,
        "max_iterations": null,
        "include_message_history": false
      },
      "actions": []
    }
  ],
  "initial_message": "PolyFit is not robust to missing data\n```python\r\nso.Plot([1, 2, 3, None, 4], [1, 2, 3, 4, 5]).add(so.Line(), so.PolyFit())\r\n```\r\n\r\n<details><summary>Traceback</summary>\r\n\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nLinAlgError                               Traceback (most recent call last)\r\nFile ~/miniconda3/envs/seaborn-py39-latest/lib/python3.9/site-packages/IPython/core/formatters.py:343, in BaseFormatter.__call__(self, obj)\r\n    341     method = get_real_method(obj, self.print_method)\r\n    342     if method is not None:\r\n--> 343         return method()\r\n    344     return None\r\n    345 else:\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:265, in Plot._repr_png_(self)\r\n    263 def _repr_png_(self) -> tuple[bytes, dict[str, float]]:\r\n--> 265     return self.plot()._repr_png_()\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:804, in Plot.plot(self, pyplot)\r\n    800 \"\"\"\r\n    801 Compile the plot spec and return the Plotter object.\r\n    802 \"\"\"\r\n    803 with theme_context(self._theme_with_defaults()):\r\n--> 804     return self._plot(pyplot)\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:822, in Plot._plot(self, pyplot)\r\n    819 plotter._setup_scales(self, common, layers, coord_vars)\r\n    821 # Apply statistical transform(s)\r\n--> 822 plotter._compute_stats(self, layers)\r\n    824 # Process scale spec for semantic variables and coordinates computed by stat\r\n    825 plotter._setup_scales(self, common, layers)\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:1110, in Plotter._compute_stats(self, spec, layers)\r\n   1108     grouper = grouping_vars\r\n   1109 groupby = GroupBy(grouper)\r\n-> 1110 res = stat(df, groupby, orient, scales)\r\n   1112 if pair_vars:\r\n   1113     data.frames[coord_vars] = res\r\n\r\nFile ~/code/seaborn/seaborn/_stats/regression.py:41, in PolyFit.__call__(self, data, groupby, orient, scales)\r\n     39 def __call__(self, data, groupby, orient, scales):\r\n---> 41     return groupby.apply(data, self._fit_predict)\r\n\r\nFile ~/code/seaborn/seaborn/_core/groupby.py:109, in GroupBy.apply(self, data, func, *args, **kwargs)\r\n    106 grouper, groups = self._get_groups(data)\r\n    108 if not grouper:\r\n--> 109     return self._reorder_columns(func(data, *args, **kwargs), data)\r\n    111 parts = {}\r\n    112 for key, part_df in data.groupby(grouper, sort=False):\r\n\r\nFile ~/code/seaborn/seaborn/_stats/regression.py:30, in PolyFit._fit_predict(self, data)\r\n     28     xx = yy = []\r\n     29 else:\r\n---> 30     p = np.polyfit(x, y, self.order)\r\n     31     xx = np.linspace(x.min(), x.max(), self.gridsize)\r\n     32     yy = np.polyval(p, xx)\r\n\r\nFile <__array_function__ internals>:180, in polyfit(*args, **kwargs)\r\n\r\nFile ~/miniconda3/envs/seaborn-py39-latest/lib/python3.9/site-packages/numpy/lib/polynomial.py:668, in polyfit(x, y, deg, rcond, full, w, cov)\r\n    666 scale = NX.sqrt((lhs*lhs).sum(axis=0))\r\n    667 lhs /= scale\r\n--> 668 c, resids, rank, s = lstsq(lhs, rhs, rcond)\r\n    669 c = (c.T/scale).T  # broadcast scale coefficients\r\n    671 # warn on rank reduction, which indicates an ill conditioned matrix\r\n\r\nFile <__array_function__ internals>:180, in lstsq(*args, **kwargs)\r\n\r\nFile ~/miniconda3/envs/seaborn-py39-latest/lib/python3.9/site-packages/numpy/linalg/linalg.py:2300, in lstsq(a, b, rcond)\r\n   2297 if n_rhs == 0:\r\n   2298     # lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\r\n   2299     b = zeros(b.shape[:-2] + (m, n_rhs + 1), dtype=b.dtype)\r\n-> 2300 x, resids, rank, s = gufunc(a, b, rcond, signature=signature, extobj=extobj)\r\n   2301 if m == 0:\r\n   2302     x[...] = 0\r\n\r\nFile ~/miniconda3/envs/seaborn-py39-latest/lib/python3.9/site-packages/numpy/linalg/linalg.py:101, in _raise_linalgerror_lstsq(err, flag)\r\n    100 def _raise_linalgerror_lstsq(err, flag):\r\n--> 101     raise LinAlgError(\"SVD did not converge in Linear Least Squares\")\r\n\r\nLinAlgError: SVD did not converge in Linear Least Squares\r\n\r\n```\r\n\r\n</details>\n"
}