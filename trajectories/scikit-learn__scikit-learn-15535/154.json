{
  "info": {
    "duration": 287.58482098579407,
    "submission": "diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\nindex dad56850f..89276528a 100644\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -459,8 +459,8 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n \n     if dtype_numeric:\n         if dtype_orig is not None and dtype_orig.kind == \"O\":\n-            # if input is object, convert to float.\n-            dtype = np.float64\n+            # if input is object, keep dtype as object to avoid conversion to float.\n+            dtype = None\n         else:\n             dtype = None\n \n",
    "total_cost": 0.226197,
    "instance_id": "scikit-learn__scikit-learn-15535",
    "evaluation_name": "run_on_remaining_250_for_july_4_t_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue pertains to a regression in the input validation of clustering metrics, specifically with `mutual_info_score`. The error occurs when attempting to compute the mutual information score with string data, leading to a `ValueError`. This worked without a warning in a previous version (0.21.1). To address this, I will search for the `mutual_info_score` function and related input validation checks in the `sklearn/metrics/cluster` directory.",
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/metrics/cluster/**/*.py",
                "function_names": [
                  "mutual_info_score"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 813,
                "span_id": "mutual_info_score",
                "file_path": "sklearn/metrics/cluster/_supervised.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/metrics/cluster/**/*.py",
                "function_names": [
                  "mutual_info_score"
                ]
              }
            ]
          },
          "input_tokens": 3652,
          "output_tokens": 170,
          "retry_message": null,
          "completion_cost": 0.013506
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 813,
            "span_id": "mutual_info_score",
            "file_path": "sklearn/metrics/cluster/_supervised.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue pertains to a regression in the input validation of clustering metrics, specifically related to the `mutual_info_score` function handling strings. The issue provides two code snippets that result in different behaviors: one with a ValueError and one with a warning. The key elements to look for in the search results are the handling of inputs, particularly string inputs, and the validation mechanisms employed within the `mutual_info_score` function. The search results include several relevant functions such as `contingency_matrix`, `mutual_info_score`, and `normalized_mutual_info_score`. It appears that `contingency_matrix`, which is used by `mutual_info_score`, handles the construction of a matrix that crosstabulates the frequencies of different combinations of input labels, potentially undermining the previous functionality due to the boolean 'sparse' parameter for creating the contingency matrix. The `mutual_info_score` function itself is also directly relevant, as it validates and processes the inputs to compute the mutual information, specifically converting the parameters to integers for processing. Lastly, the `normalized_mutual_info_score` function also leverages `mutual_info_score` to normalize the score, thus its behavior directly tied to that of `mutual_info_score`'s handling of inputs.",
            "identified_spans": [
              {
                "span_ids": [
                  "contingency_matrix",
                  "mutual_info_score",
                  "normalized_mutual_info_score"
                ],
                "file_path": "sklearn/metrics/cluster/_supervised.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 2523,
          "output_tokens": 371,
          "retry_message": null,
          "completion_cost": 0.013134
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The provided file context includes the `mutual_info_score` function and related utilities such as `contingency_matrix` and `check_clusterings`. The issue specifically mentions a `ValueError` when using string data with `mutual_info_score`, which suggests that the input validation might be failing. The code in the `mutual_info_score` function does not explicitly handle string data errors as described in the issue, but it is clear that the function and its dependencies are present and relevant to the issue. To find the exact spot where validation is breaking or how string handling is done, further inspection within the same file or related validation functions might be necessary.",
            "search_suggestions": "Look for specific input validation checks within the `mutual_info_score` function or in utility functions like `check_clusterings` that could be causing the `ValueError`. Also, check for any changes in string handling or data type checks since version 0.21.1."
          },
          "output": {
            "message": "Look for specific input validation checks within the `mutual_info_score` function or in utility functions like `check_clusterings` that could be causing the `ValueError`. Also, check for any changes in string handling or data type checks since version 0.21.1."
          },
          "input_tokens": 2461,
          "output_tokens": 237,
          "retry_message": null,
          "completion_cost": 0.010938
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Look for specific input validation checks within the `mutual_info_score` function or in utility functions like `check_clusterings` that could be causing the `ValueError`. Also, check for any changes in string handling or data type checks since version 0.21.1.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The provided context does not directly include the input validation checks within the `mutual_info_score` function or related utility functions that could be causing the `ValueError` when handling string data. To address this, I will search for any additional input validation functions or data type checks related to clustering metrics in the `sklearn/metrics/cluster` directory.",
            "search_requests": [
              {
                "query": "input validation checks for string data or data type checks in clustering metrics",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/metrics/cluster/**/*.py",
                "function_names": [
                  "check_clusterings"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 199,
                "span_id": "check_clusterings",
                "file_path": "sklearn/metrics/cluster/_supervised.py"
              }
            ],
            "search_requests": [
              {
                "query": "input validation checks for string data or data type checks in clustering metrics",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/metrics/cluster/**/*.py",
                "function_names": [
                  "check_clusterings"
                ]
              }
            ]
          },
          "input_tokens": 5321,
          "output_tokens": 186,
          "retry_message": null,
          "completion_cost": 0.018753000000000002
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 199,
            "span_id": "check_clusterings",
            "file_path": "sklearn/metrics/cluster/_supervised.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue involves a regression in input validation of clustering metrics, specifically related to `mutual_info_score` function. The provided code snippets show different behaviors when calling `mutual_info_score` with arrays of strings. The error arises when the array is explicitly typed as `object`, whereas the function works with a warning when the typing is implicit. This discrepancy indicates a problem with how input data types are handled within the `mutual_info_score` function or its dependencies.\n\nFrom the file context, it's clear that the `mutual_info_score` function is defined in `sklearn/metrics/cluster/_supervised.py`. This function relies on other functions to process the input data, such as `contingency_matrix` and `check_clusterings`.\n\nThe new search results provide additional context through the `check_clusterings` function, which is responsible for validating the input labels. This function ensures that the labels are 1D arrays and checks their consistency in length. Any issues with data type handling in `mutual_info_score` might be indirectly related to how these input labels are preprocessed by `check_clusterings`.\n\nGiven the issue description, the relevant code spans directly involve the `mutual_info_score` function itself and any functions it directly or indirectly calls to handle input data types. Therefore, the identified relevant spans are those that define or are directly called by `mutual_info_score`, including 'mutual_info_score', 'contingency_matrix', and 'check_clusterings'.",
            "identified_spans": [
              {
                "span_ids": [
                  "mutual_info_score",
                  "contingency_matrix",
                  "check_clusterings"
                ],
                "file_path": "sklearn/metrics/cluster/_supervised.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 2896,
          "output_tokens": 427,
          "retry_message": null,
          "completion_cost": 0.015092999999999999
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The file context provided includes some utility functions such as `check_clusterings`, `contingency_matrix`, and `mutual_info_score`, which are relevant to clustering metrics. However, it does not directly include the detailed input validation handling, particularly for string data, that could lead to the `ValueError` mentioned in the issue. While these functions are relevant, additional detailed checks may be needed. Further investigation into the `check_array` and data type handling might be necessary.",
            "search_suggestions": "Look into the `check_array` function and related data type checks in the `sklearn/utils` directory to find detailed input validation for data types, especially handling strings."
          },
          "output": {
            "message": "Look into the `check_array` function and related data type checks in the `sklearn/utils` directory to find detailed input validation for data types, especially handling strings."
          },
          "input_tokens": 2634,
          "output_tokens": 175,
          "retry_message": null,
          "completion_cost": 0.010527000000000002
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Look into the `check_array` function and related data type checks in the `sklearn/utils` directory to find detailed input validation for data types, especially handling strings.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The provided context includes the `check_clusterings` function which is used within the `mutual_info_score` function to validate input labels. It utilizes the `check_array` function to ensure the labels are 1D arrays. However, there is no direct data type check that would raise a `ValueError` for string data within the displayed snippet of the `check_clusterings` function. To further investigate, I will search for the `check_array` function and related data type checks in the `sklearn/utils` directory to find detailed input validation for data types, especially handling strings.",
            "search_requests": [
              {
                "query": "check_array function and data type checks for handling string data",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/utils/**/*.py",
                "function_names": [
                  "check_array"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 2446,
                "span_id": "check_array",
                "file_path": "sklearn/utils/validation.py"
              }
            ],
            "search_requests": [
              {
                "query": "check_array function and data type checks for handling string data",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/sklearn/utils/**/*.py",
                "function_names": [
                  "check_array"
                ]
              }
            ]
          },
          "input_tokens": 5748,
          "output_tokens": 235,
          "retry_message": null,
          "completion_cost": 0.020769
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 2446,
            "span_id": "check_array",
            "file_path": "sklearn/utils/validation.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue involves a regression in the input validation of clustering metrics, particularly with the `mutual_info_score` function when dealing with string inputs. The error arises when the input is of type `object`, but works with a warning when the input is of a different type. This suggests that the issue lies in how the input is being validated and possibly how it is being converted to a numerical type. The file context provided includes relevant code spans such as `check_clusterings`, `mutual_info_score`, and `check_array`. In the new search results, the function `check_array` in `sklearn/utils/validation.py` is relevant as it handles the validation and conversion of input arrays. The `_assert_all_finite` function is also relevant as it checks for finite values in the input. Additionally, the `as_float_array` function is relevant as it converts arrays to float types, which is a likely step in handling the input validation where the error occurs. These functions are critical in understanding how input validation and conversion are handled within the library, which is essential to address the regression issue reported. Therefore, the identified spans from the search results and the file context are relevant to the reported issue.",
            "identified_spans": [
              {
                "span_ids": [
                  "check_clusterings",
                  "mutual_info_score"
                ],
                "file_path": "sklearn/metrics/cluster/_supervised.py"
              },
              {
                "span_ids": [
                  "_assert_all_finite",
                  "as_float_array",
                  "check_array"
                ],
                "file_path": "sklearn/utils/validation.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 5877,
          "output_tokens": 397,
          "retry_message": null,
          "completion_cost": 0.023586000000000003
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The context includes relevant functions like `check_clusterings` and `mutual_info_score`, which handle input validation. However, the specific data type checks mentioned in the issue (handling strings and preventing ValueError for string data) are not directly addressed in the provided `check_clusterings`. The `check_array` function is used within `check_clusterings`, but there isn't a detailed view of its dtype handling, particularly for strings. Since the issue involves string handling, more context from the `check_array` function or related utility functions in `sklearn/utils/validation.py` would be helpful.",
            "search_suggestions": "Search for the detailed implementation of the `check_array` function within `sklearn/utils/validation.py` to find where string data type is explicitly handled, especially around conversion or error handling for string inputs as indicated in the issue."
          },
          "output": {},
          "input_tokens": 5169,
          "output_tokens": 217,
          "retry_message": null,
          "completion_cost": 0.018762
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "check_array",
            "file_path": "sklearn/utils/validation.py",
            "scratch_pad": "The issue involves the handling of string-based inputs in mutual_info_score, which currently raises a ValueError when the input arrays are explicitly converted to object dtype. This contradicts the behavior in earlier versions where strings were implicitly converted to float. To address this, the check_array function should not convert string arrays to float and should handle them as they are, ensuring that the mutual_info_score function can accept and process string inputs directly.",
            "instructions": "Update the check_array function to ensure it does not convert string arrays to float, thus allowing mutual_info_score to handle string inputs directly without conversion."
          },
          "output": {
            "span_id": "check_array",
            "file_path": "sklearn/utils/validation.py",
            "instructions": "Update the check_array function to ensure it does not convert string arrays to float, thus allowing mutual_info_score to handle string inputs directly without conversion."
          },
          "input_tokens": 5419,
          "output_tokens": 193,
          "retry_message": null,
          "completion_cost": 0.019152000000000002
        }
      ]
    },
    {
      "name": "ClarifyCodeChange",
      "state": {
        "model": "deepseek-coder",
        "span_id": "check_array",
        "end_line": null,
        "file_path": "sklearn/utils/validation.py",
        "max_tokens": 1000,
        "start_line": null,
        "temperature": 1.6,
        "instructions": "Update the check_array function to ensure it does not convert string arrays to float, thus allowing mutual_info_score to handle string inputs directly without conversion.\n\nThe instruction requires that string arrays should not be converted to float. This behavior is triggered when dtype is 'numeric' and dtype_orig is object. The relevant lines to modify are those that handle the conversion of object dtype to float dtype when dtype is 'numeric'.",
        "max_iterations": null,
        "include_message_history": false,
        "max_tokens_in_edit_prompt": 500
      },
      "actions": [
        {
          "action": {
            "reject": null,
            "end_line": 465,
            "start_line": 461,
            "scratch_pad": "The instruction requires that string arrays should not be converted to float. This behavior is triggered when dtype is 'numeric' and dtype_orig is object. The relevant lines to modify are those that handle the conversion of object dtype to float dtype when dtype is 'numeric'."
          },
          "output": {
            "span_id": "check_array",
            "end_line": 465,
            "file_path": "sklearn/utils/validation.py",
            "start_line": 461,
            "instructions": "Update the check_array function to ensure it does not convert string arrays to float, thus allowing mutual_info_score to handle string inputs directly without conversion.\n\nThe instruction requires that string arrays should not be converted to float. This behavior is triggered when dtype is 'numeric' and dtype_orig is object. The relevant lines to modify are those that handle the conversion of object dtype to float dtype when dtype is 'numeric'."
          },
          "input_tokens": 4355,
          "output_tokens": 85,
          "retry_message": null,
          "completion_cost": 0.01434
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "check_array",
        "end_line": 465,
        "file_path": "sklearn/utils/validation.py",
        "max_tokens": 1000,
        "start_line": 461,
        "temperature": 1.6,
        "instructions": "Update the check_array function to ensure it does not convert string arrays to float, thus allowing mutual_info_score to handle string inputs directly without conversion.\n\nThe instruction requires that string arrays should not be converted to float. This behavior is triggered when dtype is 'numeric' and dtype_orig is object. The relevant lines to modify are those that handle the conversion of object dtype to float dtype when dtype is 'numeric'.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "<replace>\n        if dtype_orig is not None and dtype_orig.kind == \"O\":\n            # if input is object, keep dtype as object to avoid conversion to float.\n            dtype = None\n        else:\n            dtype = None\n</replace>"
          },
          "output": {
            "diff": "--- sklearn/utils/validation.py\n+++ sklearn/utils/validation.py\n@@ -459,8 +459,8 @@\n \n     if dtype_numeric:\n         if dtype_orig is not None and dtype_orig.kind == \"O\":\n-            # if input is object, convert to float.\n-            dtype = np.float64\n+            # if input is object, keep dtype as object to avoid conversion to float.\n+            dtype = None\n         else:\n             dtype = None\n \n",
            "message": "Applied the change to sklearn/utils/validation.py.",
            "verification_errors": []
          },
          "input_tokens": 8863,
          "output_tokens": 58,
          "retry_message": null,
          "completion_cost": 0.027459
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": "--- sklearn/utils/validation.py\n+++ sklearn/utils/validation.py\n@@ -459,8 +459,8 @@\n \n     if dtype_numeric:\n         if dtype_orig is not None and dtype_orig.kind == \"O\":\n-            # if input is object, convert to float.\n-            dtype = np.float64\n+            # if input is object, keep dtype as object to avoid conversion to float.\n+            dtype = None\n         else:\n             dtype = None\n \n",
        "model": "deepseek-coder",
        "message": "Applied the change to sklearn/utils/validation.py.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": [],
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "finish",
            "finish": "Given that the necessary change has been applied to `check_array` to handle string inputs appropriately, and there are no further steps to take within the provided file context, the task can be concluded as resolved.",
            "reject": null,
            "span_id": null,
            "file_path": null,
            "scratch_pad": "The initial change in `check_array` has been applied successfully to prevent the conversion of string arrays to float. The updated file context includes the modified `check_array` function that now preserves the dtype of the input array if it is of object type, thus allowing string inputs to be handled directly by metric functions like `mutual_info_score`. This should resolve the reported issue with the regression in input validation of clustering metrics.",
            "instructions": null
          },
          "output": {
            "message": "Given that the necessary change has been applied to `check_array` to handle string inputs appropriately, and there are no further steps to take within the provided file context, the task can be concluded as resolved."
          },
          "input_tokens": 5766,
          "output_tokens": 192,
          "retry_message": null,
          "completion_cost": 0.020178
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "model": "gpt-4o",
        "output": {
          "model": "deepseek-coder",
          "temperature": 1.6
        },
        "message": "Given that the necessary change has been applied to `check_array` to handle string inputs appropriately, and there are no further steps to take within the provided file context, the task can be concluded as resolved.",
        "max_tokens": 1000,
        "temperature": 0.0,
        "max_iterations": null,
        "include_message_history": false
      },
      "actions": []
    }
  ],
  "initial_message": "regression in input validation of clustering metrics\n```python\r\nfrom sklearn.metrics.cluster import mutual_info_score\r\nimport numpy as np\r\n\r\nx = np.random.choice(['a', 'b'], size=20).astype(object)\r\nmutual_info_score(x, x)\r\n```\r\nValueError: could not convert string to float: 'b'\r\n\r\nwhile\r\n```python\r\nx = np.random.choice(['a', 'b'], size=20)\r\nmutual_info_score(x, x)\r\n```\r\nworks with a warning?\r\n\r\nthis worked in 0.21.1 without a warning (as I think it should)\r\n\r\n\r\nEdit by @ogrisel: I removed the `.astype(object)` in the second code snippet.\n"
}