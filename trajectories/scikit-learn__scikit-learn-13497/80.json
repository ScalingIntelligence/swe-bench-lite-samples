{
  "info": {
    "duration": 205.05307292938232,
    "submission": "diff --git a/sklearn/feature_selection/mutual_info_.py b/sklearn/feature_selection/mutual_info_.py\nindex d5d1b7fb5..7a760d175 100644\n--- a/sklearn/feature_selection/mutual_info_.py\n+++ b/sklearn/feature_selection/mutual_info_.py\n@@ -247,7 +247,7 @@ def _estimate_mi(X, y, discrete_features='auto', discrete_target=False,\n     X, y = check_X_y(X, y, accept_sparse='csc', y_numeric=not discrete_target)\n     n_samples, n_features = X.shape\n \n-    if discrete_features == 'auto':\n+    if isinstance(discrete_features, str) and discrete_features == 'auto':\n         discrete_features = issparse(X)\n \n     if isinstance(discrete_features, bool):\n",
    "total_cost": 0.16847099999999998,
    "instance_id": "scikit-learn__scikit-learn-13497",
    "evaluation_name": "run_on_remaining_250_for_july_4_t_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue involves the comparison of a string to an array in the `_estimate_mi` function, specifically with the `discrete_features` parameter which can be 'auto', an array of indices, or a boolean mask. This comparison can cause errors in future versions of numpy. The provided context suggests that the relevant function is located in `sklearn/feature_selection/mutual_info_.py`, which contains the `_estimate_mi` function. It's also noted that this function might not be tested with `discrete_features` not equal to 'auto'. Therefore, the primary focus should be on this specific function and its handling of the `discrete_features` parameter, as well as ensuring tests cover different types of `discrete_features` values.",
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": "discrete_features == 'auto'",
                "file_pattern": "sklearn/feature_selection/mutual_info_.py",
                "function_names": [
                  "_estimate_mi"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 855,
                "span_id": "_estimate_mi",
                "file_path": "sklearn/feature_selection/mutual_info_.py"
              }
            ],
            "search_requests": [
              {
                "query": null,
                "class_names": [],
                "code_snippet": "discrete_features == 'auto'",
                "file_pattern": "sklearn/feature_selection/mutual_info_.py",
                "function_names": [
                  "_estimate_mi"
                ]
              }
            ]
          },
          "input_tokens": 3366,
          "output_tokens": 246,
          "retry_message": null,
          "completion_cost": 0.013788000000000002
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 855,
            "span_id": "_estimate_mi",
            "file_path": "sklearn/feature_selection/mutual_info_.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue is about the comparison of 'discrete_features' in the '_estimate_mi' function, which can be either 'auto', an array of indices, or a boolean mask. The current code handles 'auto' and boolean types but does not explicitly handle array types, which could lead to errors in future versions of numpy. The provided code in the search results contains the '_estimate_mi' function and shows how it handles 'discrete_features'. Initially, it checks if 'discrete_features' is 'auto', then proceeds to handle boolean values. However, there is no explicit handling for when 'discrete_features' is an array of indices. The code does attempt to convert 'discrete_features' to an array and then applies a boolean mask based on whether the features are discrete or continuous. Despite this, there is no direct handling of an array input for 'discrete_features', which could risk errors. Therefore, it is crucial to identify and possibly modify the handling of 'discrete_features' to accommodate array inputs, ensuring compatibility with future numpy versions and adequate testing of the function with 'discrete_features' not equal to 'auto'.",
            "identified_spans": [
              {
                "span_ids": [
                  "_estimate_mi"
                ],
                "file_path": "sklearn/feature_selection/mutual_info_.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 1870,
          "output_tokens": 309,
          "retry_message": null,
          "completion_cost": 0.010245
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The analysis of the `_estimate_mi` function in the provided file context shows that it indeed contains the relevant code where the comparison of `discrete_features` to 'auto' occurs. This is the core functionality identified by the issue. However, the file context does not include test cases or further implementation details that might indicate how `_estimate_mi` is tested with different values of `discrete_features`. This suggests that while the function itself and its handling of `discrete_features` have been identified, the completeness regarding testing scenarios is questionable.",
            "search_suggestions": "Look for test cases related to `_estimate_mi` in the project's test suite, especially those involving `discrete_features` set to values other than 'auto', such as arrays of indices or boolean masks."
          },
          "output": {
            "message": "Look for test cases related to `_estimate_mi` in the project's test suite, especially those involving `discrete_features` set to values other than 'auto', such as arrays of indices or boolean masks."
          },
          "input_tokens": 1828,
          "output_tokens": 196,
          "retry_message": null,
          "completion_cost": 0.008424000000000001
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Look for test cases related to `_estimate_mi` in the project's test suite, especially those involving `discrete_features` set to values other than 'auto', such as arrays of indices or boolean masks.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue is focused on ensuring that the `_estimate_mi` function is properly tested with different types of `discrete_features`, especially those that are not 'auto', such as arrays of indices or boolean masks. Given the context, it's clear that the function is located in `sklearn/feature_selection/mutual_info_.py`. However, this file does not contain the test cases. Therefore, the search should be extended to the project's test suite to find where `_estimate_mi` is being tested with various values of `discrete_features`.",
            "search_requests": [
              {
                "query": "test cases for _estimate_mi with discrete_features not equal to 'auto'",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/test/**/*.py",
                "function_names": [
                  "_estimate_mi"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 855,
                "span_id": "_estimate_mi",
                "file_path": "sklearn/feature_selection/mutual_info_.py"
              }
            ],
            "search_requests": [
              {
                "query": "test cases for _estimate_mi with discrete_features not equal to 'auto'",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/test/**/*.py",
                "function_names": [
                  "_estimate_mi"
                ]
              }
            ]
          },
          "input_tokens": 4513,
          "output_tokens": 231,
          "retry_message": null,
          "completion_cost": 0.017004000000000002
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 855,
            "span_id": "_estimate_mi",
            "file_path": "sklearn/feature_selection/mutual_info_.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue identifies a problem with the comparison of the 'discrete_features' parameter in the '_estimate_mi' function. This parameter can be a string ('auto'), an array of indices, or a boolean mask, but the current logic only accurately handles 'auto' and boolean types. This disparity can lead to errors, especially with future versions of numpy. Additionally, the issue points out that the function might not be tested with 'discrete_features' values other than 'auto'. The provided search results show the function '_estimate_mi' and its related functions 'mutual_info_regression' and 'mutual_info_classif', all of which handle the 'discrete_features' parameter. Notably, the logic inside '_estimate_mi' correctly adjusts for different types of 'discrete_features' (string, boolean, or array), but it could benefit from more explicit type checking and error handling to avoid potential issues. Given the context and the issue, the relevant code spans are those in '_estimate_mi' that handle the 'discrete_features' parameter, as these are directly tied to the reported problem.",
            "identified_spans": [
              {
                "span_ids": [
                  "_estimate_mi"
                ],
                "file_path": "sklearn/feature_selection/mutual_info_.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 2749,
          "output_tokens": 303,
          "retry_message": null,
          "completion_cost": 0.012792000000000001
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The provided file context contains the implementation of the `_estimate_mi` function, but it does not include any test cases for this function. Therefore, while the function code itself is provided and indicates where the `discrete_features` are handled, there is no evidence that any testing involving `discrete_features` with values other than 'auto' exists in the current file context. This suggests a need to search the test suite for relevant tests or create new ones if none are found.",
            "search_suggestions": "Review the test suite files to find where `_estimate_mi` is tested with different values of `discrete_features`, including arrays of indices or boolean masks. If no such tests are found, consider writing new tests specifically for these cases."
          },
          "output": {
            "message": "Review the test suite files to find where `_estimate_mi` is tested with different values of `discrete_features`, including arrays of indices or boolean masks. If no such tests are found, consider writing new tests specifically for these cases."
          },
          "input_tokens": 2627,
          "output_tokens": 186,
          "retry_message": null,
          "completion_cost": 0.010671
        }
      ]
    },
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": "Review the test suite files to find where `_estimate_mi` is tested with different values of `discrete_features`, including arrays of indices or boolean masks. If no such tests are found, consider writing new tests specifically for these cases.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The code snippet provided from `sklearn/feature_selection/mutual_info_.py` includes the `_estimate_mi` function and its dependencies. This function is responsible for estimating mutual information, utilizing parameters such as `discrete_features`. The parameter `discrete_features` can be set to 'auto', a boolean array, or an array of indices. However, the current snippet does not include any test cases for this function. The task requires finding or creating test cases that specifically test `_estimate_mi` with `discrete_features` set to values other than 'auto', such as arrays of indices or boolean masks.",
            "search_requests": [
              {
                "query": "test cases for _estimate_mi with discrete_features as arrays of indices or boolean masks",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/test/**/*.py",
                "function_names": [
                  "_estimate_mi"
                ]
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 855,
                "span_id": "_estimate_mi",
                "file_path": "sklearn/feature_selection/mutual_info_.py"
              }
            ],
            "search_requests": [
              {
                "query": "test cases for _estimate_mi with discrete_features as arrays of indices or boolean masks",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/test/**/*.py",
                "function_names": [
                  "_estimate_mi"
                ]
              }
            ]
          },
          "input_tokens": 5637,
          "output_tokens": 243,
          "retry_message": null,
          "completion_cost": 0.020555999999999998
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 855,
            "span_id": "_estimate_mi",
            "file_path": "sklearn/feature_selection/mutual_info_.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "I analyzed the reported issue which concerns the comparison in `_estimate_mi` where `discrete_features == 'auto'` but `discrete_features` can also be an array of indices or a boolean mask. This will cause an error in future versions of numpy. Additionally, it seems the function is never tested with `discrete_features != 'auto'`. I checked the provided file context and found the function `_estimate_mi` has handling for `discrete_features`. It sets `discrete_features` to `issparse(X)` if it equals 'auto'. If `discrete_features` is a bool, it creates a mask; otherwise, it converts `discrete_features` into a boolean array. The search results confirm the existence of this function and the handling of `discrete_features`. However, the issue implies that the function lacks testing for the `discrete_features` array case. Therefore, the identified code span directly addresses the comparison and conversion of `discrete_features`.",
            "identified_spans": [
              {
                "span_ids": [
                  "_estimate_mi"
                ],
                "file_path": "sklearn/feature_selection/mutual_info_.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 3626,
          "output_tokens": 278,
          "retry_message": null,
          "completion_cost": 0.015048
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "relevant": true,
            "scratch_pad": "The provided file context includes the '_estimate_mi' function and its dependencies. This function handles the parameter 'discrete_features' which can be set to 'auto', a boolean array, or an array of indices. The code also includes logic to handle these different types of 'discrete_features'. However, the provided context does not include any test cases for this function, which is necessary to confirm the function's behavior with 'discrete_features' set to values other than 'auto', such as arrays of indices or boolean masks.",
            "search_suggestions": "Look for existing test cases for '_estimate_mi' in the project's test files. If not found, consider creating new test cases that specifically test '_estimate_mi' with 'discrete_features' set to arrays of indices and boolean masks, to ensure the function's robustness."
          },
          "output": {},
          "input_tokens": 2638,
          "output_tokens": 206,
          "retry_message": null,
          "completion_cost": 0.011004
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "_estimate_mi",
            "file_path": "sklearn/feature_selection/mutual_info_.py",
            "scratch_pad": "The current implementation of `_estimate_mi` uses `discrete_features == 'auto'` to determine if `discrete_features` is set to 'auto'. This comparison will fail if `discrete_features` is an array or a boolean mask. To fix this, we should change the comparison to check if `discrete_features` is exactly equal to the string 'auto'.",
            "instructions": "Update the comparison in the `_estimate_mi` function to correctly handle the case where `discrete_features` is an array or a boolean mask. Only check for string equality if `discrete_features` is a single value."
          },
          "output": {
            "span_id": "_estimate_mi",
            "file_path": "sklearn/feature_selection/mutual_info_.py",
            "instructions": "Update the comparison in the `_estimate_mi` function to correctly handle the case where `discrete_features` is an array or a boolean mask. Only check for string equality if `discrete_features` is a single value."
          },
          "input_tokens": 2852,
          "output_tokens": 190,
          "retry_message": null,
          "completion_cost": 0.011406
        }
      ]
    },
    {
      "name": "ClarifyCodeChange",
      "state": {
        "model": "deepseek-coder",
        "span_id": "_estimate_mi",
        "end_line": null,
        "file_path": "sklearn/feature_selection/mutual_info_.py",
        "max_tokens": 1000,
        "start_line": null,
        "temperature": 1.6,
        "instructions": "Update the comparison in the `_estimate_mi` function to correctly handle the case where `discrete_features` is an array or a boolean mask. Only check for string equality if `discrete_features` is a single value.\n\nThe code needs to be updated to correctly handle `discrete_features` in all cases. Currently, it only checks for 'auto' and boolean. It should also handle array-like inputs and boolean masks.",
        "max_iterations": null,
        "include_message_history": false,
        "max_tokens_in_edit_prompt": 500
      },
      "actions": [
        {
          "action": {
            "reject": false,
            "end_line": 253,
            "start_line": 250,
            "scratch_pad": "The code needs to be updated to correctly handle `discrete_features` in all cases. Currently, it only checks for 'auto' and boolean. It should also handle array-like inputs and boolean masks."
          },
          "output": {
            "span_id": "_estimate_mi",
            "end_line": 257,
            "file_path": "sklearn/feature_selection/mutual_info_.py",
            "start_line": 246,
            "instructions": "Update the comparison in the `_estimate_mi` function to correctly handle the case where `discrete_features` is an array or a boolean mask. Only check for string equality if `discrete_features` is a single value.\n\nThe code needs to be updated to correctly handle `discrete_features` in all cases. Currently, it only checks for 'auto' and boolean. It should also handle array-like inputs and boolean masks."
          },
          "input_tokens": 1898,
          "output_tokens": 88,
          "retry_message": null,
          "completion_cost": 0.007014
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "_estimate_mi",
        "end_line": 257,
        "file_path": "sklearn/feature_selection/mutual_info_.py",
        "max_tokens": 1000,
        "start_line": 246,
        "temperature": 1.6,
        "instructions": "Update the comparison in the `_estimate_mi` function to correctly handle the case where `discrete_features` is an array or a boolean mask. Only check for string equality if `discrete_features` is a single value.\n\nThe code needs to be updated to correctly handle `discrete_features` in all cases. Currently, it only checks for 'auto' and boolean. It should also handle array-like inputs and boolean masks.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "<replace>\n    \"\"\"\n    X, y = check_X_y(X, y, accept_sparse='csc', y_numeric=not discrete_target)\n    n_samples, n_features = X.shape\n\n    if isinstance(discrete_features, str) and discrete_features == 'auto':\n        discrete_features = issparse(X)\n\n    if isinstance(discrete_features, bool):\n        discrete_mask = np.empty(n_features, dtype=bool)\n        discrete_mask.fill(discrete_features)\n    else:\n        discrete_features = np.asarray(discrete_features)\n</replace>"
          },
          "output": {
            "diff": "--- sklearn/feature_selection/mutual_info_.py\n+++ sklearn/feature_selection/mutual_info_.py\n@@ -247,7 +247,7 @@\n     X, y = check_X_y(X, y, accept_sparse='csc', y_numeric=not discrete_target)\n     n_samples, n_features = X.shape\n \n-    if discrete_features == 'auto':\n+    if isinstance(discrete_features, str) and discrete_features == 'auto':\n         discrete_features = issparse(X)\n \n     if isinstance(discrete_features, bool):\n",
            "message": "Applied the change to sklearn/feature_selection/mutual_info_.py.",
            "verification_errors": []
          },
          "input_tokens": 5332,
          "output_tokens": 147,
          "retry_message": null,
          "completion_cost": 0.018201
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": "--- sklearn/feature_selection/mutual_info_.py\n+++ sklearn/feature_selection/mutual_info_.py\n@@ -247,7 +247,7 @@\n     X, y = check_X_y(X, y, accept_sparse='csc', y_numeric=not discrete_target)\n     n_samples, n_features = X.shape\n \n-    if discrete_features == 'auto':\n+    if isinstance(discrete_features, str) and discrete_features == 'auto':\n         discrete_features = issparse(X)\n \n     if isinstance(discrete_features, bool):\n",
        "model": "deepseek-coder",
        "message": "Applied the change to sklearn/feature_selection/mutual_info_.py.",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": [],
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "finish",
            "finish": "The change was applied correctly, addressing the issue by ensuring that `discrete_features` is only compared to 'auto' if it is a string. This modification prevents errors when `discrete_features` is an array or a boolean mask.",
            "reject": null,
            "span_id": null,
            "file_path": null,
            "scratch_pad": "The initial change was successful, as it properly checks if `discrete_features` is a string and equal to 'auto'. This ensures that array or boolean mask inputs for `discrete_features` are not improperly compared and an error is avoided. No further changes are necessary as the issue has been correctly addressed.",
            "instructions": null
          },
          "output": {
            "message": "The change was applied correctly, addressing the issue by ensuring that `discrete_features` is only compared to 'auto' if it is a string. This modification prevents errors when `discrete_features` is an array or a boolean mask."
          },
          "input_tokens": 3246,
          "output_tokens": 172,
          "retry_message": null,
          "completion_cost": 0.012318
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "model": "gpt-4o",
        "output": {
          "model": "deepseek-coder",
          "temperature": 1.6
        },
        "message": "The change was applied correctly, addressing the issue by ensuring that `discrete_features` is only compared to 'auto' if it is a string. This modification prevents errors when `discrete_features` is an array or a boolean mask.",
        "max_tokens": 1000,
        "temperature": 0.0,
        "max_iterations": null,
        "include_message_history": false
      },
      "actions": []
    }
  ],
  "initial_message": "Comparing string to array in _estimate_mi\nIn ``_estimate_mi`` there is ``discrete_features == 'auto'`` but discrete features can be an array of indices or a boolean mask.\r\nThis will error in future versions of numpy.\r\nAlso this means we never test this function with discrete features != 'auto', it seems?\n"
}