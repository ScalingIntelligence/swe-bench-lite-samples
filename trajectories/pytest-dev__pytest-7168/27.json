{
  "info": {
    "duration": 141.23139333724976,
    "submission": "diff --git a/src/_pytest/runner.py b/src/_pytest/runner.py\nindex f87ccb461..deb8f4069 100644\n--- a/src/_pytest/runner.py\n+++ b/src/_pytest/runner.py\n@@ -282,7 +282,21 @@ class CallInfo:\n \n \n def pytest_runtest_makereport(item, call):\n-    return TestReport.from_item_and_call(item, call)\n+    try:\n+        return TestReport.from_item_and_call(item, call)\n+    except Exception as e:\n+        # Provide a default or safe representation for the object\n+        default_report = TestReport(\n+            nodeid=item.nodeid,\n+            location=item.location,\n+            keywords={},\n+            outcome=\"failed\",\n+            longrepr=f\"Failed to generate report due to exception in __repr__: {str(e)}\",\n+            when=\"call\",\n+            user_properties=None,\n+            duration=call.stop-call.start\n+        )\n+        return default_report\n \n \n def pytest_make_collect_report(collector: Collector) -> CollectReport:\n",
    "total_cost": 0.141369,
    "instance_id": "pytest-dev__pytest-7168",
    "evaluation_name": "run_on_remaining_250_for_july_4_t_1.6"
  },
  "name": "AgenticLoop",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": null,
        "max_search_results": 25,
        "support_test_files": false,
        "initial_context_tokens": 4000,
        "initial_search_results": 50,
        "include_message_history": true,
        "provide_initial_context": true,
        "initial_context_spans_per_file": 5,
        "max_retries_with_any_file_context": 3
      },
      "actions": [
        {
          "action": {
            "complete": false,
            "scratch_pad": "The issue involves an INTERNALERROR due to an exception in __repr__ method, which is triggered when trying to represent an instance of SomeClass. This issue might be due to the specific implementation of __getattribute__ and __repr__ methods in SomeClass. The traceback indicates that the exception occurs within the pytest framework, specifically when trying to create a report for an item. Therefore, focus should be on the pytest files and code related to item representation and exception handling.",
            "search_requests": [
              {
                "query": "repr_failure",
                "class_names": [
                  "Node",
                  "Function",
                  "TestCaseFunction"
                ],
                "code_snippet": null,
                "file_pattern": "**/pytest/**/*.py",
                "function_names": [
                  "pytest_runtest_makereport"
                ]
              },
              {
                "query": "exception in __repr__",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/pytest/**/*.py",
                "function_names": []
              }
            ]
          },
          "output": {
            "complete": false,
            "ranked_spans": [
              {
                "rank": 0,
                "tokens": 32,
                "span_id": "Node",
                "file_path": "src/_pytest/nodes.py"
              },
              {
                "rank": 1,
                "tokens": 41,
                "span_id": "Function",
                "file_path": "src/_pytest/python.py"
              },
              {
                "rank": 2,
                "tokens": 18,
                "span_id": "TestCaseFunction",
                "file_path": "src/_pytest/unittest.py"
              },
              {
                "rank": 0,
                "tokens": 80,
                "span_id": "pytest_runtest_makereport",
                "file_path": "src/_pytest/hookspec.py"
              },
              {
                "rank": 1,
                "tokens": 23,
                "span_id": "pytest_runtest_makereport",
                "file_path": "src/_pytest/runner.py"
              },
              {
                "rank": 2,
                "tokens": 437,
                "span_id": "pytest_runtest_makereport",
                "file_path": "src/_pytest/skipping.py"
              },
              {
                "rank": 3,
                "tokens": 128,
                "span_id": "pytest_runtest_makereport",
                "file_path": "src/_pytest/unittest.py"
              }
            ],
            "search_requests": [
              {
                "query": "repr_failure",
                "class_names": [
                  "Node",
                  "Function",
                  "TestCaseFunction"
                ],
                "code_snippet": null,
                "file_pattern": "**/pytest/**/*.py",
                "function_names": [
                  "pytest_runtest_makereport"
                ]
              },
              {
                "query": "exception in __repr__",
                "class_names": [],
                "code_snippet": null,
                "file_pattern": "**/pytest/**/*.py",
                "function_names": []
              }
            ]
          },
          "input_tokens": 5980,
          "output_tokens": 225,
          "retry_message": null,
          "completion_cost": 0.021315
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "model": "deepseek-coder",
        "query": null,
        "class_name": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "code_snippet": null,
        "file_pattern": null,
        "ranked_spans": [
          {
            "rank": 0,
            "tokens": 32,
            "span_id": "Node",
            "file_path": "src/_pytest/nodes.py"
          },
          {
            "rank": 1,
            "tokens": 41,
            "span_id": "Function",
            "file_path": "src/_pytest/python.py"
          },
          {
            "rank": 2,
            "tokens": 18,
            "span_id": "TestCaseFunction",
            "file_path": "src/_pytest/unittest.py"
          },
          {
            "rank": 0,
            "tokens": 80,
            "span_id": "pytest_runtest_makereport",
            "file_path": "src/_pytest/hookspec.py"
          },
          {
            "rank": 1,
            "tokens": 23,
            "span_id": "pytest_runtest_makereport",
            "file_path": "src/_pytest/runner.py"
          },
          {
            "rank": 2,
            "tokens": 437,
            "span_id": "pytest_runtest_makereport",
            "file_path": "src/_pytest/skipping.py"
          },
          {
            "rank": 3,
            "tokens": 128,
            "span_id": "pytest_runtest_makereport",
            "file_path": "src/_pytest/unittest.py"
          }
        ],
        "function_name": null,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The reported issue is about an INTERNALERROR when an exception occurs in __repr__. The traceback indicates that the error occurs during the pytest_runtest_makereport hook implementation. This hook is responsible for generating the test report after a test has been run. The primary focus should be on the pytest_runtest_makereport implementations in the codebase. \n\nAnalyzing the search results, we find relevant code spans related to the pytest_runtest_makereport hook in multiple files: \n- In `src/_pytest/hookspec.py`, there is a declaration of the `pytest_runtest_makereport` hook.\n- In `src/_pytest/runner.py`, there is an implementation of `pytest_runtest_makereport` that returns a `TestReport`.\n- In `src/_pytest/skipping.py`, there is another implementation of `pytest_runtest_makereport` as a hookwrapper.\n- In `src/_pytest/unittest.py`, there is an implementation that specifically handles `TestCaseFunction` instances.\n\nThese are the core parts of the pytest framework that handle the creation of test reports and could be related to the reported issue. The presence of the hook in multiple files suggests that pytest's hook system is being leveraged extensively, and any issue in these implementations could lead to the `INTERNALERROR` seen in the traceback. \n\nGiven the detailed analysis of the search results, I have identified the relevant files and specific spans of code where the `pytest_runtest_makereport` hook is defined and implemented. This should be sufficient to start investigating and fixing the issue related to the exception in __repr__ causing an INTERNALERROR in the pytest session.",
            "identified_spans": [
              {
                "span_ids": [
                  "pytest_runtest_makereport"
                ],
                "file_path": "src/_pytest/hookspec.py"
              },
              {
                "span_ids": [
                  "pytest_runtest_makereport"
                ],
                "file_path": "src/_pytest/runner.py"
              },
              {
                "span_ids": [
                  "pytest_runtest_makereport"
                ],
                "file_path": "src/_pytest/skipping.py"
              },
              {
                "span_ids": [
                  "pytest_runtest_makereport"
                ],
                "file_path": "src/_pytest/unittest.py"
              }
            ]
          },
          "output": {},
          "input_tokens": 7048,
          "output_tokens": 580,
          "retry_message": null,
          "completion_cost": 0.029844
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "model": "deepseek-coder",
        "max_tokens": 1000,
        "temperature": 1.6,
        "expand_context": true,
        "max_iterations": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": false,
        "finish_after_relevant_count": 2
      },
      "actions": [
        {
          "action": {
            "complete": true,
            "relevant": true,
            "scratch_pad": " The file context provided includes relevant parts of the pytest code base, specifically the hook implementations for pytest_runtest_makereport in '_pytest/hookspec.py', '_pytest/runner.py', '_pytest/skipping.py', and '_pytest/unittest.py'. These files contain the necessary hooks and implementations related to generating test reports, which directly ties into the traceback and the issue described regarding the exception in __repr__ method. Hence, the file context seems appropriate for addressing the issue.",
            "search_suggestions": null
          },
          "output": {},
          "input_tokens": 4812,
          "output_tokens": 143,
          "retry_message": null,
          "completion_cost": 0.016581000000000002
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": null,
        "model": "deepseek-coder",
        "message": null,
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": null,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "repr_instance",
            "file_path": "src/_pytest/_io/saferepr.py",
            "scratch_pad": "The issue is caused by an exception being raised in the `__repr__` method of a class during the test run, which leads to an INTERNALERROR. This can be addressed by handling exceptions within the `repr` function in `_pytest/_io/saferepr.py` to prevent unhandled exceptions from causing internal errors.",
            "instructions": "Modify the `repr_instance` method in `_pytest/_io/saferepr.py` to handle exceptions within the `repr` function more gracefully. Specifically, catch exceptions raised within the `repr` call and provide a safer fallback representation to avoid causing an INTERNALERROR."
          },
          "output": null,
          "input_tokens": 5043,
          "output_tokens": 202,
          "retry_message": "File src/_pytest/_io/saferepr.py is not found in the file context. You can only request changes to files that are in file context:\n * src/_pytest/hookspec.py\n * src/_pytest/runner.py\n * src/_pytest/skipping.py\n * src/_pytest/unittest.py\n",
          "completion_cost": 0.018159
        },
        {
          "action": {
            "action": "modify",
            "finish": null,
            "reject": null,
            "span_id": "pytest_runtest_makereport",
            "file_path": "src/_pytest/runner.py",
            "scratch_pad": "Since the file `src/_pytest/_io/saferepr.py` is not in the provided file context, I need to re-evaluate the approach. The issue is related to exceptions in `__repr__` method causing internal errors during test execution. The possible solution within the scope of the provided files might involve updating how the pytest framework handles test reports when such exceptions occur.",
            "instructions": "Update the `pytest_runtest_makereport` function in `src/_pytest/runner.py` to better handle cases where an exception occurs during the `__repr__` method of an object involved in the test report generation. This might involve catching exceptions and providing a default or safe representation for the object."
          },
          "output": {
            "span_id": "pytest_runtest_makereport",
            "end_line": 285,
            "file_path": "src/_pytest/runner.py",
            "start_line": 284,
            "instructions": "Update the `pytest_runtest_makereport` function in `src/_pytest/runner.py` to better handle cases where an exception occurs during the `__repr__` method of an object involved in the test report generation. This might involve catching exceptions and providing a default or safe representation for the object."
          },
          "input_tokens": 5323,
          "output_tokens": 219,
          "retry_message": null,
          "completion_cost": 0.019254
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "model": "deepseek-coder",
        "verify": true,
        "span_id": "pytest_runtest_makereport",
        "end_line": 285,
        "file_path": "src/_pytest/runner.py",
        "max_tokens": 1000,
        "start_line": 284,
        "temperature": 1.6,
        "instructions": "Update the `pytest_runtest_makereport` function in `src/_pytest/runner.py` to better handle cases where an exception occurs during the `__repr__` method of an object involved in the test report generation. This might involve catching exceptions and providing a default or safe representation for the object.",
        "max_iterations": 8,
        "chain_of_thought": false,
        "show_file_context": true,
        "show_initial_message": true,
        "max_prompt_file_tokens": 4000,
        "include_message_history": true
      },
      "actions": [
        {
          "action": {
            "content": "```xml\n<replace>\ndef pytest_runtest_makereport(item, call):\n    try:\n        return TestReport.from_item_and_call(item, call)\n    except Exception as e:\n        # Provide a default or safe representation for the object\n        default_report = TestReport(\n            nodeid=item.nodeid,\n            location=item.location,\n            keywords={},\n            outcome=\"failed\",\n            longrepr=f\"Failed to generate report due to exception in __repr__: {str(e)}\",\n            when=\"call\",\n            user_properties=None,\n            duration=call.stop-call.start\n        )\n        return default_report\n</replace>"
          },
          "output": {
            "diff": "--- src/_pytest/runner.py\n+++ src/_pytest/runner.py\n@@ -282,7 +282,21 @@\n \n \n def pytest_runtest_makereport(item, call):\n-    return TestReport.from_item_and_call(item, call)\n+    try:\n+        return TestReport.from_item_and_call(item, call)\n+    except Exception as e:\n+        # Provide a default or safe representation for the object\n+        default_report = TestReport(\n+            nodeid=item.nodeid,\n+            location=item.location,\n+            keywords={},\n+            outcome=\"failed\",\n+            longrepr=f\"Failed to generate report due to exception in __repr__: {str(e)}\",\n+            when=\"call\",\n+            user_properties=None,\n+            duration=call.stop-call.start\n+        )\n+        return default_report\n \n \n def pytest_make_collect_report(collector: Collector) -> CollectReport:\n",
            "message": "Applied the change to src/_pytest/runner.py.\n\n<scratch_pad>\n```xml\n</scratch_pad>",
            "verification_errors": []
          },
          "input_tokens": 4743,
          "output_tokens": 163,
          "retry_message": null,
          "completion_cost": 0.016674
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "diff": "--- src/_pytest/runner.py\n+++ src/_pytest/runner.py\n@@ -282,7 +282,21 @@\n \n \n def pytest_runtest_makereport(item, call):\n-    return TestReport.from_item_and_call(item, call)\n+    try:\n+        return TestReport.from_item_and_call(item, call)\n+    except Exception as e:\n+        # Provide a default or safe representation for the object\n+        default_report = TestReport(\n+            nodeid=item.nodeid,\n+            location=item.location,\n+            keywords={},\n+            outcome=\"failed\",\n+            longrepr=f\"Failed to generate report due to exception in __repr__: {str(e)}\",\n+            when=\"call\",\n+            user_properties=None,\n+            duration=call.stop-call.start\n+        )\n+        return default_report\n \n \n def pytest_make_collect_report(collector: Collector) -> CollectReport:\n",
        "model": "deepseek-coder",
        "message": "Applied the change to src/_pytest/runner.py.\n\n<scratch_pad>\n```xml\n</scratch_pad>",
        "max_tokens": 1000,
        "temperature": 1.6,
        "max_iterations": 8,
        "finish_on_review": false,
        "verification_errors": [],
        "max_prompt_file_tokens": 4000,
        "include_message_history": true,
        "allow_hallucinated_spans": false,
        "max_tokens_in_edit_prompt": 500,
        "expand_context_with_related_spans": true
      },
      "actions": [
        {
          "action": {
            "action": "finish",
            "finish": "The changes implemented in `pytest_runtest_makereport` adequately address the issue by providing a fallback mechanism when the `__repr__` method raises an exception, thus ensuring that the test execution can continue without interruption.",
            "reject": null,
            "span_id": null,
            "file_path": null,
            "scratch_pad": "The initial change to handle exceptions during the `__repr__` method seems appropriate. The updated `pytest_runtest_makereport` function now gracefully handles cases where exceptions are raised during the test report generation. This is crucial as it prevents internal errors that could halt the test execution entirely.",
            "instructions": null
          },
          "output": {
            "message": "The changes implemented in `pytest_runtest_makereport` adequately address the issue by providing a fallback mechanism when the `__repr__` method raises an exception, thus ensuring that the test execution can continue without interruption."
          },
          "input_tokens": 5674,
          "output_tokens": 168,
          "retry_message": null,
          "completion_cost": 0.019542
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "model": "gpt-4o",
        "output": {
          "model": "deepseek-coder",
          "temperature": 1.6
        },
        "message": "The changes implemented in `pytest_runtest_makereport` adequately address the issue by providing a fallback mechanism when the `__repr__` method raises an exception, thus ensuring that the test execution can continue without interruption.",
        "max_tokens": 1000,
        "temperature": 0.0,
        "max_iterations": null,
        "include_message_history": false
      },
      "actions": []
    }
  ],
  "initial_message": "INTERNALERROR when exception in __repr__\nMinimal code to reproduce the issue: \r\n```python\r\nclass SomeClass:\r\n    def __getattribute__(self, attr):\r\n        raise\r\n    def __repr__(self):\r\n        raise\r\ndef test():\r\n    SomeClass().attr\r\n```\r\nSession traceback:\r\n```\r\n============================= test session starts ==============================\r\nplatform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1 -- /usr/local/opt/python@3.8/bin/python3.8\r\ncachedir: .pytest_cache\r\nrootdir: ******\r\nplugins: asyncio-0.10.0, mock-3.0.0, cov-2.8.1\r\ncollecting ... collected 1 item\r\n\r\ntest_pytest.py::test \r\nINTERNALERROR> Traceback (most recent call last):\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/main.py\", line 191, in wrap_session\r\nINTERNALERROR>     session.exitstatus = doit(config, session) or 0\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/main.py\", line 247, in _main\r\nINTERNALERROR>     config.hook.pytest_runtestloop(session=session)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/hooks.py\", line 286, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self.get_hookimpls(), kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 84, in <lambda>\r\nINTERNALERROR>     self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 208, in _multicall\r\nINTERNALERROR>     return outcome.get_result()\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 80, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 187, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/main.py\", line 272, in pytest_runtestloop\r\nINTERNALERROR>     item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/hooks.py\", line 286, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self.get_hookimpls(), kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 84, in <lambda>\r\nINTERNALERROR>     self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 208, in _multicall\r\nINTERNALERROR>     return outcome.get_result()\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 80, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 187, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/runner.py\", line 85, in pytest_runtest_protocol\r\nINTERNALERROR>     runtestprotocol(item, nextitem=nextitem)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/runner.py\", line 100, in runtestprotocol\r\nINTERNALERROR>     reports.append(call_and_report(item, \"call\", log))\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/runner.py\", line 188, in call_and_report\r\nINTERNALERROR>     report = hook.pytest_runtest_makereport(item=item, call=call)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/hooks.py\", line 286, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self.get_hookimpls(), kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 84, in <lambda>\r\nINTERNALERROR>     self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 203, in _multicall\r\nINTERNALERROR>     gen.send(outcome)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/skipping.py\", line 129, in pytest_runtest_makereport\r\nINTERNALERROR>     rep = outcome.get_result()\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 80, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 187, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/runner.py\", line 260, in pytest_runtest_makereport\r\nINTERNALERROR>     return TestReport.from_item_and_call(item, call)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/reports.py\", line 294, in from_item_and_call\r\nINTERNALERROR>     longrepr = item.repr_failure(excinfo)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/python.py\", line 1513, in repr_failure\r\nINTERNALERROR>     return self._repr_failure_py(excinfo, style=style)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/nodes.py\", line 355, in _repr_failure_py\r\nINTERNALERROR>     return excinfo.getrepr(\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 634, in getrepr\r\nINTERNALERROR>     return fmt.repr_excinfo(self)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 879, in repr_excinfo\r\nINTERNALERROR>     reprtraceback = self.repr_traceback(excinfo_)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 823, in repr_traceback\r\nINTERNALERROR>     reprentry = self.repr_traceback_entry(entry, einfo)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 784, in repr_traceback_entry\r\nINTERNALERROR>     reprargs = self.repr_args(entry) if not short else None\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 693, in repr_args\r\nINTERNALERROR>     args.append((argname, saferepr(argvalue)))\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 82, in saferepr\r\nINTERNALERROR>     return SafeRepr(maxsize).repr(obj)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 51, in repr\r\nINTERNALERROR>     s = _format_repr_exception(exc, x)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 23, in _format_repr_exception\r\nINTERNALERROR>     exc_info, obj.__class__.__name__, id(obj)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 47, in repr\r\nINTERNALERROR>     s = super().repr(x)\r\nINTERNALERROR>   File \"/usr/local/Cellar/python@3.8/3.8.1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/reprlib.py\", line 52, in repr\r\nINTERNALERROR>     return self.repr1(x, self.maxlevel)\r\nINTERNALERROR>   File \"/usr/local/Cellar/python@3.8/3.8.1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/reprlib.py\", line 62, in repr1\r\nINTERNALERROR>     return self.repr_instance(x, level)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 60, in repr_instance\r\nINTERNALERROR>     s = _format_repr_exception(exc, x)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 23, in _format_repr_exception\r\nINTERNALERROR>     exc_info, obj.__class__.__name__, id(obj)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 56, in repr_instance\r\nINTERNALERROR>     s = repr(x)\r\nINTERNALERROR>   File \"/Users/stiflou/Documents/projets/apischema/tests/test_pytest.py\", line 6, in __repr__\r\nINTERNALERROR>     raise\r\nINTERNALERROR> RuntimeError: No active exception to reraise\r\n\r\n============================ no tests ran in 0.09s ============================\r\n```\n"
}